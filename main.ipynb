{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4c7eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af98dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = loadmat(\"mnist-original.mat\")\n",
    "mnist_data = mnist[\"data\"].T\n",
    "mnist_data = mnist_data / 255\n",
    "mnist_label = mnist[\"label\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad7e6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_data, val_ds_data, train_ds_labels, val_ds_labels = train_test_split(mnist_data, mnist_label, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b039f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30, 10))\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(train_ds_data[i].reshape(28, 28), cmap=\"gray\")\n",
    "    plt.axis('off')    \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79f9671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nll:\n",
    "    def compute_loss(self,predictions,y):\n",
    "        self.predictions = predictions\n",
    "        self.y = y\n",
    "        batch_s = predictions.shape[1]\n",
    "        self.loss = -np.log(predictions[y,np.arange(batch_s)])\n",
    "        return self.loss\n",
    "    def backward(self):\n",
    "        grad = self.predictions.copy()\n",
    "        grad[self.y, np.arange(self.predictions.shape[1])] -= 1\n",
    "        return grad\n",
    "\n",
    "\n",
    "criterion = nll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3bb1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def forward(self,x):\n",
    "        self.x = x\n",
    "        self.output =1/(1+np.exp(-x)) \n",
    "        return self.output\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * self.output * (1-self.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee9ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = x - np.max(x, axis=0, keepdims=True)\n",
    "    return (np.exp(x) / np.sum(np.exp(x),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ca19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self,input_size,activation_function=None,output_size=256, do_softmax = False):\n",
    "\n",
    "\n",
    "        self.learning_rate = 0.01\n",
    "\n",
    "\n",
    "        self.activation = Sigmoid() if activation_function == None else activation_function\n",
    "        self.do_softmax = do_softmax\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "\n",
    "        self.weight =np.random.uniform(-1,1,size=(output_size,input_size))\n",
    "        self.bias = np.zeros((output_size,1))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(-1,1)\n",
    "        self.x_input = x\n",
    "        self.bias_tilde = np.repeat(self.bias,x.shape[1],axis=1)\n",
    "\n",
    "        self.z = np.dot(self.weight,x) + self.bias_tilde\n",
    "        \n",
    "        if self.do_softmax:\n",
    "            self.a = softmax(self.z)\n",
    "        else:\n",
    "            self.a = self.activation.forward(self.z)\n",
    "        return self.a\n",
    "    def backward(self, grad_output):\n",
    "        if self.do_softmax:\n",
    "            delta = grad_output  \n",
    "        else:\n",
    "            delta = grad_output * self.activation.backward(self.z) \n",
    "        \n",
    "        self.dw = np.dot(delta, self.x_input.T) / delta.shape[1]\n",
    "        self.db = np.sum(delta, axis=1, keepdims=True) / delta.shape[1]\n",
    "        \n",
    "        grad_input = np.dot(self.weight.T, delta)\n",
    "        return grad_input\n",
    "\n",
    "    def step(self):\n",
    "\n",
    "        self.weight -= self.learning_rate * self.dw\n",
    "        self.bias -= self.learning_rate * self.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "971c6a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Layer(input_size=train_ds_data[0].size, output_size=256)\n",
    "b = Layer(input_size=a.output_size, output_size=256)\n",
    "c = Layer(input_size=b.output_size, output_size=256)\n",
    "d = Layer(input_size=c.output_size, output_size=10, do_softmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09320cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 0, Loss: 9.0828695188765\n",
      "Epoch: 0, Iteration: 1600, Loss: 5.843276744008526\n",
      "Epoch: 0, Iteration: 3200, Loss: 3.7472749581367384\n",
      "Epoch: 0, Iteration: 4800, Loss: 3.755543307369364\n",
      "Epoch: 0, Iteration: 6400, Loss: 3.5563802311455754\n",
      "Epoch: 0, Iteration: 8000, Loss: 3.6617487808028666\n",
      "Epoch: 0, Iteration: 9600, Loss: 3.284971652869242\n",
      "Epoch: 0, Iteration: 11200, Loss: 3.109856952053434\n",
      "Epoch: 0, Iteration: 12800, Loss: 3.768606972773968\n",
      "Epoch: 0, Iteration: 14400, Loss: 3.2219318601332536\n",
      "Epoch: 0, Iteration: 16000, Loss: 2.957982613424659\n",
      "Epoch: 0, Iteration: 17600, Loss: 3.1445069741706395\n",
      "Epoch: 0, Iteration: 19200, Loss: 2.91986866855136\n",
      "Epoch: 0, Iteration: 20800, Loss: 2.874442476789371\n",
      "Epoch: 0, Iteration: 22400, Loss: 2.741685360571436\n",
      "Epoch: 0, Iteration: 24000, Loss: 2.7103094115434674\n",
      "Epoch: 0, Iteration: 25600, Loss: 3.1932821036513266\n",
      "Epoch: 0, Iteration: 27200, Loss: 2.918993978375116\n",
      "Epoch: 0, Iteration: 28800, Loss: 2.6458561447223232\n",
      "Epoch: 0, Iteration: 30400, Loss: 3.0461084606421016\n",
      "Epoch: 0, Iteration: 32000, Loss: 2.947145945567683\n",
      "Epoch: 0, Iteration: 33600, Loss: 2.8094792516850196\n",
      "Epoch: 0, Iteration: 35200, Loss: 2.668170840259692\n",
      "Epoch: 0, Iteration: 36800, Loss: 2.6758097543107793\n",
      "Epoch: 0, Iteration: 38400, Loss: 2.4343499790074468\n",
      "Epoch: 0, Iteration: 40000, Loss: 2.9405056929059414\n",
      "Epoch: 0, Iteration: 41600, Loss: 2.7859850932601753\n",
      "Epoch: 0, Iteration: 43200, Loss: 2.681054918655696\n",
      "Epoch: 0, Iteration: 44800, Loss: 2.773422160934027\n",
      "Epoch: 0, Iteration: 46400, Loss: 2.7296236775952667\n",
      "Epoch: 0, Iteration: 48000, Loss: 2.6978092149043116\n",
      "Epoch: 0, Iteration: 49600, Loss: 2.4660024920143337\n",
      "Epoch: 0, Iteration: 51200, Loss: 2.537542904652798\n",
      "Epoch: 0, Iteration: 52800, Loss: 2.6168868202197677\n",
      "Epoch: 0, Iteration: 54400, Loss: 2.2844767990613235\n",
      "Epoch: 0, Iteration: 56000, Loss: 2.338938865409734\n",
      "Epoch: 0, Iteration: 57600, Loss: 2.482314591005064\n",
      "Epoch: 0, Iteration: 59200, Loss: 2.328132971256069\n",
      "Epoch: 0, Iteration: 60800, Loss: 2.59899275134154\n",
      "Epoch: 0, Iteration: 62400, Loss: 2.559556394844699\n",
      "Epoch: 1, Iteration: 0, Loss: 2.7267651661734584\n",
      "Epoch: 1, Iteration: 1600, Loss: 2.4022164888611894\n",
      "Epoch: 1, Iteration: 3200, Loss: 2.1480845571854035\n",
      "Epoch: 1, Iteration: 4800, Loss: 2.661011887619912\n",
      "Epoch: 1, Iteration: 6400, Loss: 2.222685975898356\n",
      "Epoch: 1, Iteration: 8000, Loss: 2.3675979512012897\n",
      "Epoch: 1, Iteration: 9600, Loss: 2.267880757114763\n",
      "Epoch: 1, Iteration: 11200, Loss: 2.187686900078003\n",
      "Epoch: 1, Iteration: 12800, Loss: 2.550372599712957\n",
      "Epoch: 1, Iteration: 14400, Loss: 2.125175539212367\n",
      "Epoch: 1, Iteration: 16000, Loss: 2.283830810983053\n",
      "Epoch: 1, Iteration: 17600, Loss: 2.2493972005798986\n",
      "Epoch: 1, Iteration: 19200, Loss: 2.096073924671871\n",
      "Epoch: 1, Iteration: 20800, Loss: 2.308575786618862\n",
      "Epoch: 1, Iteration: 22400, Loss: 2.224018898621958\n",
      "Epoch: 1, Iteration: 24000, Loss: 2.0601499627161637\n",
      "Epoch: 1, Iteration: 25600, Loss: 2.208229167520451\n",
      "Epoch: 1, Iteration: 27200, Loss: 2.313065892553495\n",
      "Epoch: 1, Iteration: 28800, Loss: 2.1278081134732174\n",
      "Epoch: 1, Iteration: 30400, Loss: 2.291605072112474\n",
      "Epoch: 1, Iteration: 32000, Loss: 2.2645011949001512\n",
      "Epoch: 1, Iteration: 33600, Loss: 2.184424539915765\n",
      "Epoch: 1, Iteration: 35200, Loss: 2.087383760128652\n",
      "Epoch: 1, Iteration: 36800, Loss: 2.2312154297114395\n",
      "Epoch: 1, Iteration: 38400, Loss: 1.84723808572386\n",
      "Epoch: 1, Iteration: 40000, Loss: 2.5267220980988094\n",
      "Epoch: 1, Iteration: 41600, Loss: 2.1927664761100485\n",
      "Epoch: 1, Iteration: 43200, Loss: 2.3514110157442607\n",
      "Epoch: 1, Iteration: 44800, Loss: 2.3318370906144565\n",
      "Epoch: 1, Iteration: 46400, Loss: 2.201991135338372\n",
      "Epoch: 1, Iteration: 48000, Loss: 2.296880052303699\n",
      "Epoch: 1, Iteration: 49600, Loss: 2.119687730381885\n",
      "Epoch: 1, Iteration: 51200, Loss: 2.2409468260841456\n",
      "Epoch: 1, Iteration: 52800, Loss: 2.2803797725134727\n",
      "Epoch: 1, Iteration: 54400, Loss: 1.9338412896729515\n",
      "Epoch: 1, Iteration: 56000, Loss: 1.9315092531491391\n",
      "Epoch: 1, Iteration: 57600, Loss: 2.2732698275973484\n",
      "Epoch: 1, Iteration: 59200, Loss: 1.8948630245241362\n",
      "Epoch: 1, Iteration: 60800, Loss: 2.0606328984242106\n",
      "Epoch: 1, Iteration: 62400, Loss: 1.980887592393016\n",
      "Epoch: 2, Iteration: 0, Loss: 2.1135911049819445\n",
      "Epoch: 2, Iteration: 1600, Loss: 2.0217148833201875\n",
      "Epoch: 2, Iteration: 3200, Loss: 1.914905179984867\n",
      "Epoch: 2, Iteration: 4800, Loss: 2.063822733463806\n",
      "Epoch: 2, Iteration: 6400, Loss: 1.9812073336169356\n",
      "Epoch: 2, Iteration: 8000, Loss: 1.950930687503881\n",
      "Epoch: 2, Iteration: 9600, Loss: 1.9435162841630014\n",
      "Epoch: 2, Iteration: 11200, Loss: 2.0405742292514297\n",
      "Epoch: 2, Iteration: 12800, Loss: 2.135131429244372\n",
      "Epoch: 2, Iteration: 14400, Loss: 1.8129441431174\n",
      "Epoch: 2, Iteration: 16000, Loss: 1.908860099568397\n",
      "Epoch: 2, Iteration: 17600, Loss: 1.81713179224501\n",
      "Epoch: 2, Iteration: 19200, Loss: 1.9197504131499321\n",
      "Epoch: 2, Iteration: 20800, Loss: 1.9055136917726492\n",
      "Epoch: 2, Iteration: 22400, Loss: 1.982408277148714\n",
      "Epoch: 2, Iteration: 24000, Loss: 1.8107306817068456\n",
      "Epoch: 2, Iteration: 25600, Loss: 1.9348577461384804\n",
      "Epoch: 2, Iteration: 27200, Loss: 1.916683505441508\n",
      "Epoch: 2, Iteration: 28800, Loss: 1.776283170750336\n",
      "Epoch: 2, Iteration: 30400, Loss: 2.108449310380359\n",
      "Epoch: 2, Iteration: 32000, Loss: 1.9957127445225247\n",
      "Epoch: 2, Iteration: 33600, Loss: 1.7769539292887602\n",
      "Epoch: 2, Iteration: 35200, Loss: 1.8206260036911415\n",
      "Epoch: 2, Iteration: 36800, Loss: 1.8443416646748414\n",
      "Epoch: 2, Iteration: 38400, Loss: 1.6113297022591815\n",
      "Epoch: 2, Iteration: 40000, Loss: 2.198686227162247\n",
      "Epoch: 2, Iteration: 41600, Loss: 1.921036427833108\n",
      "Epoch: 2, Iteration: 43200, Loss: 2.0667857207872085\n",
      "Epoch: 2, Iteration: 44800, Loss: 2.094566508943446\n",
      "Epoch: 2, Iteration: 46400, Loss: 1.849608455331317\n",
      "Epoch: 2, Iteration: 48000, Loss: 1.9024992494657291\n",
      "Epoch: 2, Iteration: 49600, Loss: 1.8524226927067295\n",
      "Epoch: 2, Iteration: 51200, Loss: 2.048950862774326\n",
      "Epoch: 2, Iteration: 52800, Loss: 2.017901205158824\n",
      "Epoch: 2, Iteration: 54400, Loss: 1.6742580045201314\n",
      "Epoch: 2, Iteration: 56000, Loss: 1.659667138743902\n",
      "Epoch: 2, Iteration: 57600, Loss: 2.039521359422682\n",
      "Epoch: 2, Iteration: 59200, Loss: 1.6392725811308926\n",
      "Epoch: 2, Iteration: 60800, Loss: 1.7485585821386138\n",
      "Epoch: 2, Iteration: 62400, Loss: 1.6013272215355099\n",
      "Epoch: 3, Iteration: 0, Loss: 1.7962103810472057\n",
      "Epoch: 3, Iteration: 1600, Loss: 1.8248412654251203\n",
      "Epoch: 3, Iteration: 3200, Loss: 1.6453583362180293\n",
      "Epoch: 3, Iteration: 4800, Loss: 1.7207654168026454\n",
      "Epoch: 3, Iteration: 6400, Loss: 1.7581507676374575\n",
      "Epoch: 3, Iteration: 8000, Loss: 1.8158514002359356\n",
      "Epoch: 3, Iteration: 9600, Loss: 1.7445302312263258\n",
      "Epoch: 3, Iteration: 11200, Loss: 1.8402297940324877\n",
      "Epoch: 3, Iteration: 12800, Loss: 1.9381204314738385\n",
      "Epoch: 3, Iteration: 14400, Loss: 1.6624514234367769\n",
      "Epoch: 3, Iteration: 16000, Loss: 1.6639595125864903\n",
      "Epoch: 3, Iteration: 17600, Loss: 1.4971317234745711\n",
      "Epoch: 3, Iteration: 19200, Loss: 1.724678755612787\n",
      "Epoch: 3, Iteration: 20800, Loss: 1.7023318555709916\n",
      "Epoch: 3, Iteration: 22400, Loss: 1.7893588808120138\n",
      "Epoch: 3, Iteration: 24000, Loss: 1.624063556609019\n",
      "Epoch: 3, Iteration: 25600, Loss: 1.7613047066763965\n",
      "Epoch: 3, Iteration: 27200, Loss: 1.7701396160774865\n",
      "Epoch: 3, Iteration: 28800, Loss: 1.4971991733083352\n",
      "Epoch: 3, Iteration: 30400, Loss: 1.8868360998323075\n",
      "Epoch: 3, Iteration: 32000, Loss: 1.8980201103587702\n",
      "Epoch: 3, Iteration: 33600, Loss: 1.54248357958138\n",
      "Epoch: 3, Iteration: 35200, Loss: 1.6618057363561025\n",
      "Epoch: 3, Iteration: 36800, Loss: 1.6748543442006025\n",
      "Epoch: 3, Iteration: 38400, Loss: 1.538753976042846\n",
      "Epoch: 3, Iteration: 40000, Loss: 1.8513335031909557\n",
      "Epoch: 3, Iteration: 41600, Loss: 1.7463723681907046\n",
      "Epoch: 3, Iteration: 43200, Loss: 1.7843098635288377\n",
      "Epoch: 3, Iteration: 44800, Loss: 1.9705979547221495\n",
      "Epoch: 3, Iteration: 46400, Loss: 1.7614011627099377\n",
      "Epoch: 3, Iteration: 48000, Loss: 1.6143590431885053\n",
      "Epoch: 3, Iteration: 49600, Loss: 1.755991649973395\n",
      "Epoch: 3, Iteration: 51200, Loss: 1.8464613282724147\n",
      "Epoch: 3, Iteration: 52800, Loss: 1.8571172424770384\n",
      "Epoch: 3, Iteration: 54400, Loss: 1.4606198028074806\n",
      "Epoch: 3, Iteration: 56000, Loss: 1.4818107273115744\n",
      "Epoch: 3, Iteration: 57600, Loss: 1.8173271726085591\n",
      "Epoch: 3, Iteration: 59200, Loss: 1.5019288098401598\n",
      "Epoch: 3, Iteration: 60800, Loss: 1.5492814690440015\n",
      "Epoch: 3, Iteration: 62400, Loss: 1.47572016719057\n",
      "Epoch: 4, Iteration: 0, Loss: 1.597907863335636\n",
      "Epoch: 4, Iteration: 1600, Loss: 1.6532695598809186\n",
      "Epoch: 4, Iteration: 3200, Loss: 1.395152596400441\n",
      "Epoch: 4, Iteration: 4800, Loss: 1.5363415829766236\n",
      "Epoch: 4, Iteration: 6400, Loss: 1.617053925763274\n",
      "Epoch: 4, Iteration: 8000, Loss: 1.6864648208574593\n",
      "Epoch: 4, Iteration: 9600, Loss: 1.5769839668998915\n",
      "Epoch: 4, Iteration: 11200, Loss: 1.711250781716383\n",
      "Epoch: 4, Iteration: 12800, Loss: 1.6809917813288169\n",
      "Epoch: 4, Iteration: 14400, Loss: 1.5385292523143588\n",
      "Epoch: 4, Iteration: 16000, Loss: 1.546725376645869\n",
      "Epoch: 4, Iteration: 17600, Loss: 1.3683369811785395\n",
      "Epoch: 4, Iteration: 19200, Loss: 1.5965877567896518\n",
      "Epoch: 4, Iteration: 20800, Loss: 1.5289960209922941\n",
      "Epoch: 4, Iteration: 22400, Loss: 1.639435465237729\n",
      "Epoch: 4, Iteration: 24000, Loss: 1.4558696034949197\n",
      "Epoch: 4, Iteration: 25600, Loss: 1.5523747021444183\n",
      "Epoch: 4, Iteration: 27200, Loss: 1.6344246703776129\n",
      "Epoch: 4, Iteration: 28800, Loss: 1.3943767363701522\n",
      "Epoch: 4, Iteration: 30400, Loss: 1.6401189608498727\n",
      "Epoch: 4, Iteration: 32000, Loss: 1.7811034223884414\n",
      "Epoch: 4, Iteration: 33600, Loss: 1.3474494990054156\n",
      "Epoch: 4, Iteration: 35200, Loss: 1.5826558160996171\n",
      "Epoch: 4, Iteration: 36800, Loss: 1.5157523033702094\n",
      "Epoch: 4, Iteration: 38400, Loss: 1.4382280901682984\n",
      "Epoch: 4, Iteration: 40000, Loss: 1.6217089283148667\n",
      "Epoch: 4, Iteration: 41600, Loss: 1.5626298240357817\n",
      "Epoch: 4, Iteration: 43200, Loss: 1.5513534367374096\n",
      "Epoch: 4, Iteration: 44800, Loss: 1.8990744489912919\n",
      "Epoch: 4, Iteration: 46400, Loss: 1.680429351811458\n",
      "Epoch: 4, Iteration: 48000, Loss: 1.3880623575214903\n",
      "Epoch: 4, Iteration: 49600, Loss: 1.6152428505922063\n",
      "Epoch: 4, Iteration: 51200, Loss: 1.6511261300971096\n",
      "Epoch: 4, Iteration: 52800, Loss: 1.6995918479834013\n",
      "Epoch: 4, Iteration: 54400, Loss: 1.3415860550944165\n",
      "Epoch: 4, Iteration: 56000, Loss: 1.357232208262953\n",
      "Epoch: 4, Iteration: 57600, Loss: 1.5995414792645155\n",
      "Epoch: 4, Iteration: 59200, Loss: 1.3119610224864875\n",
      "Epoch: 4, Iteration: 60800, Loss: 1.420317241521909\n",
      "Epoch: 4, Iteration: 62400, Loss: 1.3853762847537667\n",
      "Epoch: 5, Iteration: 0, Loss: 1.4257745644317341\n",
      "Epoch: 5, Iteration: 1600, Loss: 1.5124294113056274\n",
      "Epoch: 5, Iteration: 3200, Loss: 1.250605767757954\n",
      "Epoch: 5, Iteration: 4800, Loss: 1.3681330603232884\n",
      "Epoch: 5, Iteration: 6400, Loss: 1.4938847180359747\n",
      "Epoch: 5, Iteration: 8000, Loss: 1.549353003804971\n",
      "Epoch: 5, Iteration: 9600, Loss: 1.4163175915229123\n",
      "Epoch: 5, Iteration: 11200, Loss: 1.638990069907476\n",
      "Epoch: 5, Iteration: 12800, Loss: 1.53452046987722\n",
      "Epoch: 5, Iteration: 14400, Loss: 1.37106528674042\n",
      "Epoch: 5, Iteration: 16000, Loss: 1.3927477825635886\n",
      "Epoch: 5, Iteration: 17600, Loss: 1.249979094378755\n",
      "Epoch: 5, Iteration: 19200, Loss: 1.488510720622985\n",
      "Epoch: 5, Iteration: 20800, Loss: 1.3903255783932185\n",
      "Epoch: 5, Iteration: 22400, Loss: 1.515286241614119\n",
      "Epoch: 5, Iteration: 24000, Loss: 1.340258829855424\n",
      "Epoch: 5, Iteration: 25600, Loss: 1.382389976349557\n",
      "Epoch: 5, Iteration: 27200, Loss: 1.4783172782269949\n",
      "Epoch: 5, Iteration: 28800, Loss: 1.3035345646240746\n",
      "Epoch: 5, Iteration: 30400, Loss: 1.4788143800903402\n",
      "Epoch: 5, Iteration: 32000, Loss: 1.6608194213352632\n",
      "Epoch: 5, Iteration: 33600, Loss: 1.132625496285116\n",
      "Epoch: 5, Iteration: 35200, Loss: 1.5102171208592268\n",
      "Epoch: 5, Iteration: 36800, Loss: 1.4164719090939724\n",
      "Epoch: 5, Iteration: 38400, Loss: 1.2936826284822933\n",
      "Epoch: 5, Iteration: 40000, Loss: 1.4578352170451985\n",
      "Epoch: 5, Iteration: 41600, Loss: 1.4501281591567265\n",
      "Epoch: 5, Iteration: 43200, Loss: 1.3597716957658479\n",
      "Epoch: 5, Iteration: 44800, Loss: 1.7475768472426871\n",
      "Epoch: 5, Iteration: 46400, Loss: 1.609681797692615\n",
      "Epoch: 5, Iteration: 48000, Loss: 1.2463610794121607\n",
      "Epoch: 5, Iteration: 49600, Loss: 1.4493030790515775\n",
      "Epoch: 5, Iteration: 51200, Loss: 1.4428579692494239\n",
      "Epoch: 5, Iteration: 52800, Loss: 1.5163599459152217\n",
      "Epoch: 5, Iteration: 54400, Loss: 1.2252686693868489\n",
      "Epoch: 5, Iteration: 56000, Loss: 1.2260468264058524\n",
      "Epoch: 5, Iteration: 57600, Loss: 1.4067583644890016\n",
      "Epoch: 5, Iteration: 59200, Loss: 1.1959677126775718\n",
      "Epoch: 5, Iteration: 60800, Loss: 1.3373305123372363\n",
      "Epoch: 5, Iteration: 62400, Loss: 1.270628653806604\n",
      "Epoch: 6, Iteration: 0, Loss: 1.3086668995409003\n",
      "Epoch: 6, Iteration: 1600, Loss: 1.3418338536558019\n",
      "Epoch: 6, Iteration: 3200, Loss: 1.1556430593090117\n",
      "Epoch: 6, Iteration: 4800, Loss: 1.2128182595317873\n",
      "Epoch: 6, Iteration: 6400, Loss: 1.385917992912986\n",
      "Epoch: 6, Iteration: 8000, Loss: 1.3421734409765897\n",
      "Epoch: 6, Iteration: 9600, Loss: 1.2627772983048515\n",
      "Epoch: 6, Iteration: 11200, Loss: 1.5324484217957313\n",
      "Epoch: 6, Iteration: 12800, Loss: 1.3928805968061608\n",
      "Epoch: 6, Iteration: 14400, Loss: 1.2307924761112128\n",
      "Epoch: 6, Iteration: 16000, Loss: 1.3246842434391122\n",
      "Epoch: 6, Iteration: 17600, Loss: 1.1508711887879914\n",
      "Epoch: 6, Iteration: 19200, Loss: 1.3513838497465067\n",
      "Epoch: 6, Iteration: 20800, Loss: 1.3282818787390764\n",
      "Epoch: 6, Iteration: 22400, Loss: 1.44761969289367\n",
      "Epoch: 6, Iteration: 24000, Loss: 1.2531247636936258\n",
      "Epoch: 6, Iteration: 25600, Loss: 1.2960522222291972\n",
      "Epoch: 6, Iteration: 27200, Loss: 1.39968466689908\n",
      "Epoch: 6, Iteration: 28800, Loss: 1.2215450908576804\n",
      "Epoch: 6, Iteration: 30400, Loss: 1.3766172273810513\n",
      "Epoch: 6, Iteration: 32000, Loss: 1.5797384110242758\n",
      "Epoch: 6, Iteration: 33600, Loss: 1.0597064621315466\n",
      "Epoch: 6, Iteration: 35200, Loss: 1.4074959782125043\n",
      "Epoch: 6, Iteration: 36800, Loss: 1.3150339759984107\n",
      "Epoch: 6, Iteration: 38400, Loss: 1.1713519552908245\n",
      "Epoch: 6, Iteration: 40000, Loss: 1.316334406616059\n",
      "Epoch: 6, Iteration: 41600, Loss: 1.3384008339445037\n",
      "Epoch: 6, Iteration: 43200, Loss: 1.1932414134955778\n",
      "Epoch: 6, Iteration: 44800, Loss: 1.5608461564930587\n",
      "Epoch: 6, Iteration: 46400, Loss: 1.4655753724750156\n",
      "Epoch: 6, Iteration: 48000, Loss: 1.1389216236980202\n",
      "Epoch: 6, Iteration: 49600, Loss: 1.3649469369602312\n",
      "Epoch: 6, Iteration: 51200, Loss: 1.3173381769399877\n",
      "Epoch: 6, Iteration: 52800, Loss: 1.4178945167790606\n",
      "Epoch: 6, Iteration: 54400, Loss: 1.1336910529991928\n",
      "Epoch: 6, Iteration: 56000, Loss: 1.100072677787598\n",
      "Epoch: 6, Iteration: 57600, Loss: 1.2367112022246998\n",
      "Epoch: 6, Iteration: 59200, Loss: 1.0866034517268768\n",
      "Epoch: 6, Iteration: 60800, Loss: 1.2305870618325456\n",
      "Epoch: 6, Iteration: 62400, Loss: 1.167716173905813\n",
      "Epoch: 7, Iteration: 0, Loss: 1.2646827692573483\n",
      "Epoch: 7, Iteration: 1600, Loss: 1.202382689263283\n",
      "Epoch: 7, Iteration: 3200, Loss: 1.0626772648010234\n",
      "Epoch: 7, Iteration: 4800, Loss: 1.1186904184422293\n",
      "Epoch: 7, Iteration: 6400, Loss: 1.306597857758733\n",
      "Epoch: 7, Iteration: 8000, Loss: 1.165825558995452\n",
      "Epoch: 7, Iteration: 9600, Loss: 1.1605068470936353\n",
      "Epoch: 7, Iteration: 11200, Loss: 1.362072865156125\n",
      "Epoch: 7, Iteration: 12800, Loss: 1.2467907279118293\n",
      "Epoch: 7, Iteration: 14400, Loss: 1.1183498383096346\n",
      "Epoch: 7, Iteration: 16000, Loss: 1.2865126469728885\n",
      "Epoch: 7, Iteration: 17600, Loss: 1.0993150863633605\n",
      "Epoch: 7, Iteration: 19200, Loss: 1.2280731203833368\n",
      "Epoch: 7, Iteration: 20800, Loss: 1.2869059857606358\n",
      "Epoch: 7, Iteration: 22400, Loss: 1.3746178558040825\n",
      "Epoch: 7, Iteration: 24000, Loss: 1.119622238689306\n",
      "Epoch: 7, Iteration: 25600, Loss: 1.205697359614342\n",
      "Epoch: 7, Iteration: 27200, Loss: 1.323840635014966\n",
      "Epoch: 7, Iteration: 28800, Loss: 1.1328929987772178\n",
      "Epoch: 7, Iteration: 30400, Loss: 1.321082757901359\n",
      "Epoch: 7, Iteration: 32000, Loss: 1.5008191046210357\n",
      "Epoch: 7, Iteration: 33600, Loss: 1.020700422024567\n",
      "Epoch: 7, Iteration: 35200, Loss: 1.3141771046953963\n",
      "Epoch: 7, Iteration: 36800, Loss: 1.2521600144905187\n",
      "Epoch: 7, Iteration: 38400, Loss: 1.100831853652485\n",
      "Epoch: 7, Iteration: 40000, Loss: 1.1856262500854906\n",
      "Epoch: 7, Iteration: 41600, Loss: 1.2205230467863886\n",
      "Epoch: 7, Iteration: 43200, Loss: 1.0561216886660354\n",
      "Epoch: 7, Iteration: 44800, Loss: 1.3851725000498023\n",
      "Epoch: 7, Iteration: 46400, Loss: 1.3668463288366697\n",
      "Epoch: 7, Iteration: 48000, Loss: 1.0624095344400577\n",
      "Epoch: 7, Iteration: 49600, Loss: 1.3178307537426721\n",
      "Epoch: 7, Iteration: 51200, Loss: 1.2564717149113416\n",
      "Epoch: 7, Iteration: 52800, Loss: 1.372228636806502\n",
      "Epoch: 7, Iteration: 54400, Loss: 1.0749116270898669\n",
      "Epoch: 7, Iteration: 56000, Loss: 1.0178084772570213\n",
      "Epoch: 7, Iteration: 57600, Loss: 1.162035144398072\n",
      "Epoch: 7, Iteration: 59200, Loss: 0.9984393103108161\n",
      "Epoch: 7, Iteration: 60800, Loss: 1.181408271512051\n",
      "Epoch: 7, Iteration: 62400, Loss: 1.1268988981110284\n",
      "Epoch: 8, Iteration: 0, Loss: 1.2059755259862723\n",
      "Epoch: 8, Iteration: 1600, Loss: 1.1043056423850088\n",
      "Epoch: 8, Iteration: 3200, Loss: 0.9806100456507595\n",
      "Epoch: 8, Iteration: 4800, Loss: 1.0686095234729749\n",
      "Epoch: 8, Iteration: 6400, Loss: 1.2750000455669355\n",
      "Epoch: 8, Iteration: 8000, Loss: 1.0952337336233207\n",
      "Epoch: 8, Iteration: 9600, Loss: 1.0922247310333864\n",
      "Epoch: 8, Iteration: 11200, Loss: 1.20355806057841\n",
      "Epoch: 8, Iteration: 12800, Loss: 1.1587103958620615\n",
      "Epoch: 8, Iteration: 14400, Loss: 1.010695739769436\n",
      "Epoch: 8, Iteration: 16000, Loss: 1.2546678747304028\n",
      "Epoch: 8, Iteration: 17600, Loss: 1.0445236177839479\n",
      "Epoch: 8, Iteration: 19200, Loss: 1.1343086486812703\n",
      "Epoch: 8, Iteration: 20800, Loss: 1.2289922858510272\n",
      "Epoch: 8, Iteration: 22400, Loss: 1.3055010033245158\n",
      "Epoch: 8, Iteration: 24000, Loss: 1.009136560452367\n",
      "Epoch: 8, Iteration: 25600, Loss: 1.1839510758288527\n",
      "Epoch: 8, Iteration: 27200, Loss: 1.2287799138996682\n",
      "Epoch: 8, Iteration: 28800, Loss: 1.0466206080275304\n",
      "Epoch: 8, Iteration: 30400, Loss: 1.2756381522788822\n",
      "Epoch: 8, Iteration: 32000, Loss: 1.4291806176424977\n",
      "Epoch: 8, Iteration: 33600, Loss: 1.0011914317596653\n",
      "Epoch: 8, Iteration: 35200, Loss: 1.2348763217739855\n",
      "Epoch: 8, Iteration: 36800, Loss: 1.170676928910585\n",
      "Epoch: 8, Iteration: 38400, Loss: 1.0374413133957927\n",
      "Epoch: 8, Iteration: 40000, Loss: 1.118307917168139\n",
      "Epoch: 8, Iteration: 41600, Loss: 1.1321425878371691\n",
      "Epoch: 8, Iteration: 43200, Loss: 0.962960771362742\n",
      "Epoch: 8, Iteration: 44800, Loss: 1.2524426872932493\n",
      "Epoch: 8, Iteration: 46400, Loss: 1.3072785040142532\n",
      "Epoch: 8, Iteration: 48000, Loss: 1.0165742377554712\n",
      "Epoch: 8, Iteration: 49600, Loss: 1.267963026548975\n",
      "Epoch: 8, Iteration: 51200, Loss: 1.1956508554886414\n",
      "Epoch: 8, Iteration: 52800, Loss: 1.3356405265641222\n",
      "Epoch: 8, Iteration: 54400, Loss: 1.0403389722482608\n",
      "Epoch: 8, Iteration: 56000, Loss: 0.9710568446421484\n",
      "Epoch: 8, Iteration: 57600, Loss: 1.1398583306406516\n",
      "Epoch: 8, Iteration: 59200, Loss: 0.9340325156578317\n",
      "Epoch: 8, Iteration: 60800, Loss: 1.1698655255999966\n",
      "Epoch: 8, Iteration: 62400, Loss: 1.1034125907854897\n",
      "Epoch: 9, Iteration: 0, Loss: 1.113253072171526\n",
      "Epoch: 9, Iteration: 1600, Loss: 1.048785036595973\n",
      "Epoch: 9, Iteration: 3200, Loss: 0.9086359086476419\n",
      "Epoch: 9, Iteration: 4800, Loss: 1.0354555708755355\n",
      "Epoch: 9, Iteration: 6400, Loss: 1.2621281781384417\n",
      "Epoch: 9, Iteration: 8000, Loss: 1.0669671009914268\n",
      "Epoch: 9, Iteration: 9600, Loss: 1.0356769757156101\n",
      "Epoch: 9, Iteration: 11200, Loss: 1.088450656784285\n",
      "Epoch: 9, Iteration: 12800, Loss: 1.0983482026447107\n",
      "Epoch: 9, Iteration: 14400, Loss: 0.9138983220510575\n",
      "Epoch: 9, Iteration: 16000, Loss: 1.2165196275368284\n",
      "Epoch: 9, Iteration: 17600, Loss: 0.9810538314885237\n",
      "Epoch: 9, Iteration: 19200, Loss: 1.075754938280868\n",
      "Epoch: 9, Iteration: 20800, Loss: 1.176481816851444\n",
      "Epoch: 9, Iteration: 22400, Loss: 1.242902814072912\n",
      "Epoch: 9, Iteration: 24000, Loss: 0.9253379755115179\n",
      "Epoch: 9, Iteration: 25600, Loss: 1.1860118124372425\n",
      "Epoch: 9, Iteration: 27200, Loss: 1.1499785169897363\n",
      "Epoch: 9, Iteration: 28800, Loss: 0.974311274252502\n",
      "Epoch: 9, Iteration: 30400, Loss: 1.2244430651814522\n",
      "Epoch: 9, Iteration: 32000, Loss: 1.352952003618527\n",
      "Epoch: 9, Iteration: 33600, Loss: 0.9936553741771842\n",
      "Epoch: 9, Iteration: 35200, Loss: 1.1712156722278724\n",
      "Epoch: 9, Iteration: 36800, Loss: 1.0906626550302585\n",
      "Epoch: 9, Iteration: 38400, Loss: 0.9752482895848296\n",
      "Epoch: 9, Iteration: 40000, Loss: 1.0890720405232663\n",
      "Epoch: 9, Iteration: 41600, Loss: 1.0673936564135886\n",
      "Epoch: 9, Iteration: 43200, Loss: 0.8972077487263928\n",
      "Epoch: 9, Iteration: 44800, Loss: 1.1461371770532995\n",
      "Epoch: 9, Iteration: 46400, Loss: 1.2804748161600392\n",
      "Epoch: 9, Iteration: 48000, Loss: 0.9867747517912115\n",
      "Epoch: 9, Iteration: 49600, Loss: 1.2091537560802832\n",
      "Epoch: 9, Iteration: 51200, Loss: 1.1278151970360872\n",
      "Epoch: 9, Iteration: 52800, Loss: 1.2836518880329408\n",
      "Epoch: 9, Iteration: 54400, Loss: 1.02752083189249\n",
      "Epoch: 9, Iteration: 56000, Loss: 0.9443388949458362\n",
      "Epoch: 9, Iteration: 57600, Loss: 1.1393182343844666\n",
      "Epoch: 9, Iteration: 59200, Loss: 0.8951297393372891\n",
      "Epoch: 9, Iteration: 60800, Loss: 1.1612730391393904\n",
      "Epoch: 9, Iteration: 62400, Loss: 1.0846781151334768\n",
      "Epoch: 10, Iteration: 0, Loss: 1.0080512829690453\n",
      "Epoch: 10, Iteration: 1600, Loss: 1.0258632341911458\n",
      "Epoch: 10, Iteration: 3200, Loss: 0.8663496707404811\n",
      "Epoch: 10, Iteration: 4800, Loss: 0.990389171292315\n",
      "Epoch: 10, Iteration: 6400, Loss: 1.2230121994467429\n",
      "Epoch: 10, Iteration: 8000, Loss: 1.0526599786743684\n",
      "Epoch: 10, Iteration: 9600, Loss: 0.9811550185076838\n",
      "Epoch: 10, Iteration: 11200, Loss: 1.0263950329023137\n",
      "Epoch: 10, Iteration: 12800, Loss: 1.030863350015404\n",
      "Epoch: 10, Iteration: 14400, Loss: 0.8454644487857368\n",
      "Epoch: 10, Iteration: 16000, Loss: 1.1679334273489095\n",
      "Epoch: 10, Iteration: 17600, Loss: 0.9411687715788937\n",
      "Epoch: 10, Iteration: 19200, Loss: 1.0145810662483676\n",
      "Epoch: 10, Iteration: 20800, Loss: 1.1310694759664939\n",
      "Epoch: 10, Iteration: 22400, Loss: 1.1637743053252407\n",
      "Epoch: 10, Iteration: 24000, Loss: 0.863631438159594\n",
      "Epoch: 10, Iteration: 25600, Loss: 1.17469981678952\n",
      "Epoch: 10, Iteration: 27200, Loss: 1.1224545096665381\n",
      "Epoch: 10, Iteration: 28800, Loss: 0.8996071702419246\n",
      "Epoch: 10, Iteration: 30400, Loss: 1.1722709200623598\n",
      "Epoch: 10, Iteration: 32000, Loss: 1.26227906914011\n",
      "Epoch: 10, Iteration: 33600, Loss: 0.9767975285732605\n",
      "Epoch: 10, Iteration: 35200, Loss: 1.1224009007277602\n",
      "Epoch: 10, Iteration: 36800, Loss: 1.0443851216780229\n",
      "Epoch: 10, Iteration: 38400, Loss: 0.9166810650891575\n",
      "Epoch: 10, Iteration: 40000, Loss: 1.076676001625569\n",
      "Epoch: 10, Iteration: 41600, Loss: 1.0112581778499647\n",
      "Epoch: 10, Iteration: 43200, Loss: 0.8448715789622532\n",
      "Epoch: 10, Iteration: 44800, Loss: 1.0828690438109543\n",
      "Epoch: 10, Iteration: 46400, Loss: 1.2670681182197474\n",
      "Epoch: 10, Iteration: 48000, Loss: 0.952088678581203\n",
      "Epoch: 10, Iteration: 49600, Loss: 1.1608104758669944\n",
      "Epoch: 10, Iteration: 51200, Loss: 1.0728473812825665\n",
      "Epoch: 10, Iteration: 52800, Loss: 1.2263951747649886\n",
      "Epoch: 10, Iteration: 54400, Loss: 0.9918475262789281\n",
      "Epoch: 10, Iteration: 56000, Loss: 0.9141477987861629\n",
      "Epoch: 10, Iteration: 57600, Loss: 1.0994860553180632\n",
      "Epoch: 10, Iteration: 59200, Loss: 0.8702939561094856\n",
      "Epoch: 10, Iteration: 60800, Loss: 1.122616071033743\n",
      "Epoch: 10, Iteration: 62400, Loss: 1.043711276101393\n",
      "Epoch: 11, Iteration: 0, Loss: 0.9434641898782581\n",
      "Epoch: 11, Iteration: 1600, Loss: 0.9974139978553324\n",
      "Epoch: 11, Iteration: 3200, Loss: 0.8593061522908704\n",
      "Epoch: 11, Iteration: 4800, Loss: 0.9502666874288477\n",
      "Epoch: 11, Iteration: 6400, Loss: 1.1905570898311257\n",
      "Epoch: 11, Iteration: 8000, Loss: 1.0428479432480358\n",
      "Epoch: 11, Iteration: 9600, Loss: 0.9272534398815477\n",
      "Epoch: 11, Iteration: 11200, Loss: 0.9749982234232399\n",
      "Epoch: 11, Iteration: 12800, Loss: 0.9990580533531653\n",
      "Epoch: 11, Iteration: 14400, Loss: 0.7974994716171844\n",
      "Epoch: 11, Iteration: 16000, Loss: 1.1267356837033344\n",
      "Epoch: 11, Iteration: 17600, Loss: 0.9082387240010454\n",
      "Epoch: 11, Iteration: 19200, Loss: 0.9624175004742324\n",
      "Epoch: 11, Iteration: 20800, Loss: 1.094777213542723\n",
      "Epoch: 11, Iteration: 22400, Loss: 1.1141562319890885\n",
      "Epoch: 11, Iteration: 24000, Loss: 0.8036108650464412\n",
      "Epoch: 11, Iteration: 25600, Loss: 1.138919001351018\n",
      "Epoch: 11, Iteration: 27200, Loss: 1.0814538323301097\n",
      "Epoch: 11, Iteration: 28800, Loss: 0.8377081075535658\n",
      "Epoch: 11, Iteration: 30400, Loss: 1.1272230818628874\n",
      "Epoch: 11, Iteration: 32000, Loss: 1.1608036837301139\n",
      "Epoch: 11, Iteration: 33600, Loss: 0.9558382548067044\n",
      "Epoch: 11, Iteration: 35200, Loss: 1.0758844662738438\n",
      "Epoch: 11, Iteration: 36800, Loss: 1.0086101922371706\n",
      "Epoch: 11, Iteration: 38400, Loss: 0.8553677160774342\n",
      "Epoch: 11, Iteration: 40000, Loss: 1.0685844727884812\n",
      "Epoch: 11, Iteration: 41600, Loss: 0.9882891523903697\n",
      "Epoch: 11, Iteration: 43200, Loss: 0.8191669358821052\n",
      "Epoch: 11, Iteration: 44800, Loss: 1.0267227095810183\n",
      "Epoch: 11, Iteration: 46400, Loss: 1.2336102495974475\n",
      "Epoch: 11, Iteration: 48000, Loss: 0.9039865610099147\n",
      "Epoch: 11, Iteration: 49600, Loss: 1.113959316090258\n",
      "Epoch: 11, Iteration: 51200, Loss: 1.0070840632831797\n",
      "Epoch: 11, Iteration: 52800, Loss: 1.1750949877100512\n",
      "Epoch: 11, Iteration: 54400, Loss: 0.9547489025377477\n",
      "Epoch: 11, Iteration: 56000, Loss: 0.8770256028682238\n",
      "Epoch: 11, Iteration: 57600, Loss: 1.0499017871521756\n",
      "Epoch: 11, Iteration: 59200, Loss: 0.8473977181359521\n",
      "Epoch: 11, Iteration: 60800, Loss: 1.0951678366245194\n",
      "Epoch: 11, Iteration: 62400, Loss: 1.001591552133649\n",
      "Epoch: 12, Iteration: 0, Loss: 0.8845721402659164\n",
      "Epoch: 12, Iteration: 1600, Loss: 0.9636767640160533\n",
      "Epoch: 12, Iteration: 3200, Loss: 0.8477741325006323\n",
      "Epoch: 12, Iteration: 4800, Loss: 0.9146644206479664\n",
      "Epoch: 12, Iteration: 6400, Loss: 1.14329745641927\n",
      "Epoch: 12, Iteration: 8000, Loss: 1.0184797532352945\n",
      "Epoch: 12, Iteration: 9600, Loss: 0.8698753009058742\n",
      "Epoch: 12, Iteration: 11200, Loss: 0.9240457410326639\n",
      "Epoch: 12, Iteration: 12800, Loss: 0.9725395803733698\n",
      "Epoch: 12, Iteration: 14400, Loss: 0.7540986736206112\n",
      "Epoch: 12, Iteration: 16000, Loss: 1.0797239237425649\n",
      "Epoch: 12, Iteration: 17600, Loss: 0.8939027545153184\n",
      "Epoch: 12, Iteration: 19200, Loss: 0.9154807980983335\n",
      "Epoch: 12, Iteration: 20800, Loss: 1.0583170016118268\n",
      "Epoch: 12, Iteration: 22400, Loss: 1.0702335024912721\n",
      "Epoch: 12, Iteration: 24000, Loss: 0.7557244821408136\n",
      "Epoch: 12, Iteration: 25600, Loss: 1.0950402158790125\n",
      "Epoch: 12, Iteration: 27200, Loss: 1.03720973155903\n",
      "Epoch: 12, Iteration: 28800, Loss: 0.7977894595939852\n",
      "Epoch: 12, Iteration: 30400, Loss: 1.091098886915698\n",
      "Epoch: 12, Iteration: 32000, Loss: 1.0787696460023626\n",
      "Epoch: 12, Iteration: 33600, Loss: 0.9329125255766725\n",
      "Epoch: 12, Iteration: 35200, Loss: 1.0249902967877265\n",
      "Epoch: 12, Iteration: 36800, Loss: 0.978636153186311\n",
      "Epoch: 12, Iteration: 38400, Loss: 0.8047308571363517\n",
      "Epoch: 12, Iteration: 40000, Loss: 1.0516011793961382\n",
      "Epoch: 12, Iteration: 41600, Loss: 0.987184441818596\n",
      "Epoch: 12, Iteration: 43200, Loss: 0.7900832893824874\n",
      "Epoch: 12, Iteration: 44800, Loss: 0.9810843786071057\n",
      "Epoch: 12, Iteration: 46400, Loss: 1.1943646786762903\n",
      "Epoch: 12, Iteration: 48000, Loss: 0.858568066268312\n",
      "Epoch: 12, Iteration: 49600, Loss: 1.0759593540260468\n",
      "Epoch: 12, Iteration: 51200, Loss: 0.946934411897367\n",
      "Epoch: 12, Iteration: 52800, Loss: 1.1315161364057078\n",
      "Epoch: 12, Iteration: 54400, Loss: 0.9267563245693\n",
      "Epoch: 12, Iteration: 56000, Loss: 0.8378774691544371\n",
      "Epoch: 12, Iteration: 57600, Loss: 1.0054467268670768\n",
      "Epoch: 12, Iteration: 59200, Loss: 0.8283200236383546\n",
      "Epoch: 12, Iteration: 60800, Loss: 1.0784602764087072\n",
      "Epoch: 12, Iteration: 62400, Loss: 0.9548108174844772\n",
      "Epoch: 13, Iteration: 0, Loss: 0.8251529619793232\n",
      "Epoch: 13, Iteration: 1600, Loss: 0.933385238559277\n",
      "Epoch: 13, Iteration: 3200, Loss: 0.8359013319589006\n",
      "Epoch: 13, Iteration: 4800, Loss: 0.8823765605154036\n",
      "Epoch: 13, Iteration: 6400, Loss: 1.0958896463287005\n",
      "Epoch: 13, Iteration: 8000, Loss: 1.004674404646866\n",
      "Epoch: 13, Iteration: 9600, Loss: 0.8189937499168701\n",
      "Epoch: 13, Iteration: 11200, Loss: 0.8852537932110397\n",
      "Epoch: 13, Iteration: 12800, Loss: 0.9500420040339282\n",
      "Epoch: 13, Iteration: 14400, Loss: 0.7158488261429292\n",
      "Epoch: 13, Iteration: 16000, Loss: 1.0304725449715504\n",
      "Epoch: 13, Iteration: 17600, Loss: 0.895494907725447\n",
      "Epoch: 13, Iteration: 19200, Loss: 0.8720332713472367\n",
      "Epoch: 13, Iteration: 20800, Loss: 1.0213664402755618\n",
      "Epoch: 13, Iteration: 22400, Loss: 1.030199039146023\n",
      "Epoch: 13, Iteration: 24000, Loss: 0.7157521577088334\n",
      "Epoch: 13, Iteration: 25600, Loss: 1.0472626130355172\n",
      "Epoch: 13, Iteration: 27200, Loss: 1.0033744677071874\n",
      "Epoch: 13, Iteration: 28800, Loss: 0.7706438355171722\n",
      "Epoch: 13, Iteration: 30400, Loss: 1.0659955068481588\n",
      "Epoch: 13, Iteration: 32000, Loss: 1.0157176027874049\n",
      "Epoch: 13, Iteration: 33600, Loss: 0.9117718310583279\n",
      "Epoch: 13, Iteration: 35200, Loss: 0.9688602728477699\n",
      "Epoch: 13, Iteration: 36800, Loss: 0.9650179361560554\n",
      "Epoch: 13, Iteration: 38400, Loss: 0.7614347273287063\n",
      "Epoch: 13, Iteration: 40000, Loss: 1.0269231706240576\n",
      "Epoch: 13, Iteration: 41600, Loss: 0.9986561965151939\n",
      "Epoch: 13, Iteration: 43200, Loss: 0.7631512925729323\n",
      "Epoch: 13, Iteration: 44800, Loss: 0.9466743992248849\n",
      "Epoch: 13, Iteration: 46400, Loss: 1.1551777781892367\n",
      "Epoch: 13, Iteration: 48000, Loss: 0.822893253211455\n",
      "Epoch: 13, Iteration: 49600, Loss: 1.0417139300197453\n",
      "Epoch: 13, Iteration: 51200, Loss: 0.8901559976500776\n",
      "Epoch: 13, Iteration: 52800, Loss: 1.0950709839114456\n",
      "Epoch: 13, Iteration: 54400, Loss: 0.9054492741688243\n",
      "Epoch: 13, Iteration: 56000, Loss: 0.8031119296416315\n",
      "Epoch: 13, Iteration: 57600, Loss: 0.9698248385754498\n",
      "Epoch: 13, Iteration: 59200, Loss: 0.8117593874204507\n",
      "Epoch: 13, Iteration: 60800, Loss: 1.0671918077344194\n",
      "Epoch: 13, Iteration: 62400, Loss: 0.9116558547198734\n",
      "Epoch: 14, Iteration: 0, Loss: 0.7749122321862059\n",
      "Epoch: 14, Iteration: 1600, Loss: 0.9145921015828729\n",
      "Epoch: 14, Iteration: 3200, Loss: 0.8169125280320154\n",
      "Epoch: 14, Iteration: 4800, Loss: 0.8614081356898391\n",
      "Epoch: 14, Iteration: 6400, Loss: 1.056984509089144\n",
      "Epoch: 14, Iteration: 8000, Loss: 1.0065266295187973\n",
      "Epoch: 14, Iteration: 9600, Loss: 0.7759830549326702\n",
      "Epoch: 14, Iteration: 11200, Loss: 0.861460345957135\n",
      "Epoch: 14, Iteration: 12800, Loss: 0.9340953586025635\n",
      "Epoch: 14, Iteration: 14400, Loss: 0.6850662280278997\n",
      "Epoch: 14, Iteration: 16000, Loss: 0.9842802945090681\n",
      "Epoch: 14, Iteration: 17600, Loss: 0.9084206314961303\n",
      "Epoch: 14, Iteration: 19200, Loss: 0.834073855466605\n",
      "Epoch: 14, Iteration: 20800, Loss: 0.9856991947399811\n",
      "Epoch: 14, Iteration: 22400, Loss: 1.000071139878596\n",
      "Epoch: 14, Iteration: 24000, Loss: 0.6744025925121395\n",
      "Epoch: 14, Iteration: 25600, Loss: 1.0041814874883965\n",
      "Epoch: 14, Iteration: 27200, Loss: 0.9781395527174865\n",
      "Epoch: 14, Iteration: 28800, Loss: 0.7483245784475308\n",
      "Epoch: 14, Iteration: 30400, Loss: 1.0434907261153326\n",
      "Epoch: 14, Iteration: 32000, Loss: 0.9688306407972829\n",
      "Epoch: 14, Iteration: 33600, Loss: 0.8933830377069685\n",
      "Epoch: 14, Iteration: 35200, Loss: 0.9149236150124449\n",
      "Epoch: 14, Iteration: 36800, Loss: 0.970028549626085\n",
      "Epoch: 14, Iteration: 38400, Loss: 0.724121709106499\n",
      "Epoch: 14, Iteration: 40000, Loss: 1.008255652212531\n",
      "Epoch: 14, Iteration: 41600, Loss: 1.0132038590211752\n",
      "Epoch: 14, Iteration: 43200, Loss: 0.7425533985252448\n",
      "Epoch: 14, Iteration: 44800, Loss: 0.9096262723197623\n",
      "Epoch: 14, Iteration: 46400, Loss: 1.1146470076852437\n",
      "Epoch: 14, Iteration: 48000, Loss: 0.7958764162004812\n",
      "Epoch: 14, Iteration: 49600, Loss: 1.0058506673760659\n",
      "Epoch: 14, Iteration: 51200, Loss: 0.8367458179571399\n",
      "Epoch: 14, Iteration: 52800, Loss: 1.0678001430220332\n",
      "Epoch: 14, Iteration: 54400, Loss: 0.8867140611274242\n",
      "Epoch: 14, Iteration: 56000, Loss: 0.7700805588702604\n",
      "Epoch: 14, Iteration: 57600, Loss: 0.9354624761442588\n",
      "Epoch: 14, Iteration: 59200, Loss: 0.7977504421292045\n",
      "Epoch: 14, Iteration: 60800, Loss: 1.0546207882934664\n",
      "Epoch: 14, Iteration: 62400, Loss: 0.8782269602962856\n",
      "Epoch: 15, Iteration: 0, Loss: 0.7382817168070446\n",
      "Epoch: 15, Iteration: 1600, Loss: 0.9042432394502096\n",
      "Epoch: 15, Iteration: 3200, Loss: 0.7914602594368354\n",
      "Epoch: 15, Iteration: 4800, Loss: 0.844244451310567\n",
      "Epoch: 15, Iteration: 6400, Loss: 1.0175827517410292\n",
      "Epoch: 15, Iteration: 8000, Loss: 1.0048673539653115\n",
      "Epoch: 15, Iteration: 9600, Loss: 0.7351638168691654\n",
      "Epoch: 15, Iteration: 11200, Loss: 0.8478769442975281\n",
      "Epoch: 15, Iteration: 12800, Loss: 0.9214880644461326\n",
      "Epoch: 15, Iteration: 14400, Loss: 0.6645563137504797\n",
      "Epoch: 15, Iteration: 16000, Loss: 0.9405318834346015\n",
      "Epoch: 15, Iteration: 17600, Loss: 0.9196342469335224\n",
      "Epoch: 15, Iteration: 19200, Loss: 0.7983465961224663\n",
      "Epoch: 15, Iteration: 20800, Loss: 0.9519506280503715\n",
      "Epoch: 15, Iteration: 22400, Loss: 0.969106828239881\n",
      "Epoch: 15, Iteration: 24000, Loss: 0.6336837142268988\n",
      "Epoch: 15, Iteration: 25600, Loss: 0.9677467609939236\n",
      "Epoch: 15, Iteration: 27200, Loss: 0.9525459519372851\n",
      "Epoch: 15, Iteration: 28800, Loss: 0.7261493090334556\n",
      "Epoch: 15, Iteration: 30400, Loss: 1.0191703425497094\n",
      "Epoch: 15, Iteration: 32000, Loss: 0.9384405583313329\n",
      "Epoch: 15, Iteration: 33600, Loss: 0.8766645371313581\n",
      "Epoch: 15, Iteration: 35200, Loss: 0.8593643897203154\n",
      "Epoch: 15, Iteration: 36800, Loss: 0.985714266998973\n",
      "Epoch: 15, Iteration: 38400, Loss: 0.6951901633229401\n",
      "Epoch: 15, Iteration: 40000, Loss: 0.9976120334286747\n",
      "Epoch: 15, Iteration: 41600, Loss: 1.0233351199631213\n",
      "Epoch: 15, Iteration: 43200, Loss: 0.7265295856644903\n",
      "Epoch: 15, Iteration: 44800, Loss: 0.8651208527674121\n",
      "Epoch: 15, Iteration: 46400, Loss: 1.0732733104626453\n",
      "Epoch: 15, Iteration: 48000, Loss: 0.7767767589081013\n",
      "Epoch: 15, Iteration: 49600, Loss: 0.971291268906513\n",
      "Epoch: 15, Iteration: 51200, Loss: 0.7849329811289476\n",
      "Epoch: 15, Iteration: 52800, Loss: 1.0475451372855304\n",
      "Epoch: 15, Iteration: 54400, Loss: 0.8702409618875135\n",
      "Epoch: 15, Iteration: 56000, Loss: 0.740377402863619\n",
      "Epoch: 15, Iteration: 57600, Loss: 0.9071569141154621\n",
      "Epoch: 15, Iteration: 59200, Loss: 0.7898113955690702\n",
      "Epoch: 15, Iteration: 60800, Loss: 1.0422417927869732\n",
      "Epoch: 15, Iteration: 62400, Loss: 0.8632667538445534\n",
      "Epoch: 16, Iteration: 0, Loss: 0.7109602198350149\n",
      "Epoch: 16, Iteration: 1600, Loss: 0.8992687099013209\n",
      "Epoch: 16, Iteration: 3200, Loss: 0.7675167650803025\n",
      "Epoch: 16, Iteration: 4800, Loss: 0.8288499629985355\n",
      "Epoch: 16, Iteration: 6400, Loss: 0.9793571514985787\n",
      "Epoch: 16, Iteration: 8000, Loss: 1.0057260619435928\n",
      "Epoch: 16, Iteration: 9600, Loss: 0.6960348626960011\n",
      "Epoch: 16, Iteration: 11200, Loss: 0.839696514382962\n",
      "Epoch: 16, Iteration: 12800, Loss: 0.9049364302834123\n",
      "Epoch: 16, Iteration: 14400, Loss: 0.6515467423614638\n",
      "Epoch: 16, Iteration: 16000, Loss: 0.905395867474241\n",
      "Epoch: 16, Iteration: 17600, Loss: 0.9284483761178944\n",
      "Epoch: 16, Iteration: 19200, Loss: 0.7669964260829494\n",
      "Epoch: 16, Iteration: 20800, Loss: 0.9148955490404654\n",
      "Epoch: 16, Iteration: 22400, Loss: 0.9413634890566065\n",
      "Epoch: 16, Iteration: 24000, Loss: 0.603463971850717\n",
      "Epoch: 16, Iteration: 25600, Loss: 0.9406516854084949\n",
      "Epoch: 16, Iteration: 27200, Loss: 0.9289503606599798\n",
      "Epoch: 16, Iteration: 28800, Loss: 0.7075162694603612\n",
      "Epoch: 16, Iteration: 30400, Loss: 1.0031933952197247\n",
      "Epoch: 16, Iteration: 32000, Loss: 0.9227608911750745\n",
      "Epoch: 16, Iteration: 33600, Loss: 0.8645058382119799\n",
      "Epoch: 16, Iteration: 35200, Loss: 0.8004479892412653\n",
      "Epoch: 16, Iteration: 36800, Loss: 1.0126407935899988\n",
      "Epoch: 16, Iteration: 38400, Loss: 0.6794847308806478\n",
      "Epoch: 16, Iteration: 40000, Loss: 0.989580736191314\n",
      "Epoch: 16, Iteration: 41600, Loss: 1.0228537886632698\n",
      "Epoch: 16, Iteration: 43200, Loss: 0.7180249032663442\n",
      "Epoch: 16, Iteration: 44800, Loss: 0.8229815949886671\n",
      "Epoch: 16, Iteration: 46400, Loss: 1.0425793722949166\n",
      "Epoch: 16, Iteration: 48000, Loss: 0.7599858144264653\n",
      "Epoch: 16, Iteration: 49600, Loss: 0.9432546738506695\n",
      "Epoch: 16, Iteration: 51200, Loss: 0.7415483301982054\n",
      "Epoch: 16, Iteration: 52800, Loss: 1.0299183314765283\n",
      "Epoch: 16, Iteration: 54400, Loss: 0.8656468163378919\n",
      "Epoch: 16, Iteration: 56000, Loss: 0.7189860766756108\n",
      "Epoch: 16, Iteration: 57600, Loss: 0.8951228184692313\n",
      "Epoch: 16, Iteration: 59200, Loss: 0.7982691936567408\n",
      "Epoch: 16, Iteration: 60800, Loss: 1.0435955657937068\n",
      "Epoch: 16, Iteration: 62400, Loss: 0.868107578897541\n",
      "Epoch: 17, Iteration: 0, Loss: 0.6864502203225842\n",
      "Epoch: 17, Iteration: 1600, Loss: 0.9009852361609749\n",
      "Epoch: 17, Iteration: 3200, Loss: 0.7577331379510944\n",
      "Epoch: 17, Iteration: 4800, Loss: 0.8194573169937865\n",
      "Epoch: 17, Iteration: 6400, Loss: 0.9502013561447945\n",
      "Epoch: 17, Iteration: 8000, Loss: 1.0139506484797223\n",
      "Epoch: 17, Iteration: 9600, Loss: 0.6533455347210916\n",
      "Epoch: 17, Iteration: 11200, Loss: 0.8368949589315763\n",
      "Epoch: 17, Iteration: 12800, Loss: 0.8757184010860826\n",
      "Epoch: 17, Iteration: 14400, Loss: 0.6411302501779634\n",
      "Epoch: 17, Iteration: 16000, Loss: 0.8819750050441073\n",
      "Epoch: 17, Iteration: 17600, Loss: 0.9354171924342624\n",
      "Epoch: 17, Iteration: 19200, Loss: 0.7444603281972804\n",
      "Epoch: 17, Iteration: 20800, Loss: 0.8799765180151402\n",
      "Epoch: 17, Iteration: 22400, Loss: 0.9298004321807399\n",
      "Epoch: 17, Iteration: 24000, Loss: 0.57955299086511\n",
      "Epoch: 17, Iteration: 25600, Loss: 0.9347741618474541\n",
      "Epoch: 17, Iteration: 27200, Loss: 0.9235896123716733\n",
      "Epoch: 17, Iteration: 28800, Loss: 0.6900724226340385\n",
      "Epoch: 17, Iteration: 30400, Loss: 1.003886276967096\n",
      "Epoch: 17, Iteration: 32000, Loss: 0.9207532938389252\n",
      "Epoch: 17, Iteration: 33600, Loss: 0.8490944545406619\n",
      "Epoch: 17, Iteration: 35200, Loss: 0.7666176334703398\n",
      "Epoch: 17, Iteration: 36800, Loss: 1.050589024404084\n",
      "Epoch: 17, Iteration: 38400, Loss: 0.6722852126797056\n",
      "Epoch: 17, Iteration: 40000, Loss: 0.9678018958105989\n",
      "Epoch: 17, Iteration: 41600, Loss: 1.0052959493910585\n",
      "Epoch: 17, Iteration: 43200, Loss: 0.7244111798342474\n",
      "Epoch: 17, Iteration: 44800, Loss: 0.7943392970770413\n",
      "Epoch: 17, Iteration: 46400, Loss: 1.021157097455478\n",
      "Epoch: 17, Iteration: 48000, Loss: 0.7663362059512133\n",
      "Epoch: 17, Iteration: 49600, Loss: 0.9231348037297928\n",
      "Epoch: 17, Iteration: 51200, Loss: 0.715872664554402\n",
      "Epoch: 17, Iteration: 52800, Loss: 1.019302368688755\n",
      "Epoch: 17, Iteration: 54400, Loss: 0.880679355598835\n",
      "Epoch: 17, Iteration: 56000, Loss: 0.7228394935757372\n",
      "Epoch: 17, Iteration: 57600, Loss: 0.9204112867290963\n",
      "Epoch: 17, Iteration: 59200, Loss: 0.8202420949769215\n",
      "Epoch: 17, Iteration: 60800, Loss: 1.0827061165093783\n",
      "Epoch: 17, Iteration: 62400, Loss: 0.8675759537575738\n",
      "Epoch: 18, Iteration: 0, Loss: 0.6690276078564981\n",
      "Epoch: 18, Iteration: 1600, Loss: 0.9211922633055413\n",
      "Epoch: 18, Iteration: 3200, Loss: 0.7605919146885687\n",
      "Epoch: 18, Iteration: 4800, Loss: 0.8229219424230022\n",
      "Epoch: 18, Iteration: 6400, Loss: 0.9532388467945268\n",
      "Epoch: 18, Iteration: 8000, Loss: 1.0004901501564705\n",
      "Epoch: 18, Iteration: 9600, Loss: 0.6167347367994052\n",
      "Epoch: 18, Iteration: 11200, Loss: 0.854034735351332\n",
      "Epoch: 18, Iteration: 12800, Loss: 0.8496161041235193\n",
      "Epoch: 18, Iteration: 14400, Loss: 0.620338072283602\n",
      "Epoch: 18, Iteration: 16000, Loss: 0.8816102010845073\n",
      "Epoch: 18, Iteration: 17600, Loss: 0.8786158613068762\n",
      "Epoch: 18, Iteration: 19200, Loss: 0.7368391795039517\n",
      "Epoch: 18, Iteration: 20800, Loss: 0.8747578279707439\n",
      "Epoch: 18, Iteration: 22400, Loss: 0.9002817852622506\n",
      "Epoch: 18, Iteration: 24000, Loss: 0.5642282226909698\n",
      "Epoch: 18, Iteration: 25600, Loss: 0.9118694473279185\n",
      "Epoch: 18, Iteration: 27200, Loss: 0.9330098094590574\n",
      "Epoch: 18, Iteration: 28800, Loss: 0.6540616902878666\n",
      "Epoch: 18, Iteration: 30400, Loss: 1.0016723614258225\n",
      "Epoch: 18, Iteration: 32000, Loss: 0.9139466527651189\n",
      "Epoch: 18, Iteration: 33600, Loss: 0.8309294323625482\n",
      "Epoch: 18, Iteration: 35200, Loss: 0.767625595778832\n",
      "Epoch: 18, Iteration: 36800, Loss: 1.0675106931401626\n",
      "Epoch: 18, Iteration: 38400, Loss: 0.6623890920254688\n",
      "Epoch: 18, Iteration: 40000, Loss: 0.9429062016490113\n",
      "Epoch: 18, Iteration: 41600, Loss: 0.9743982731517559\n",
      "Epoch: 18, Iteration: 43200, Loss: 0.7313808420173776\n",
      "Epoch: 18, Iteration: 44800, Loss: 0.7775851165879732\n",
      "Epoch: 18, Iteration: 46400, Loss: 1.0014969272869845\n",
      "Epoch: 18, Iteration: 48000, Loss: 0.7825562882686987\n",
      "Epoch: 18, Iteration: 49600, Loss: 0.9091983445277928\n",
      "Epoch: 18, Iteration: 51200, Loss: 0.6924499514018132\n",
      "Epoch: 18, Iteration: 52800, Loss: 1.0041392868989438\n",
      "Epoch: 18, Iteration: 54400, Loss: 0.8937788374793068\n",
      "Epoch: 18, Iteration: 56000, Loss: 0.720683878487958\n",
      "Epoch: 18, Iteration: 57600, Loss: 0.9195010694133607\n",
      "Epoch: 18, Iteration: 59200, Loss: 0.8065884049694434\n",
      "Epoch: 18, Iteration: 60800, Loss: 1.0863530455006354\n",
      "Epoch: 18, Iteration: 62400, Loss: 0.867679149515133\n",
      "Epoch: 19, Iteration: 0, Loss: 0.6657837102056721\n",
      "Epoch: 19, Iteration: 1600, Loss: 0.9036421986897908\n",
      "Epoch: 19, Iteration: 3200, Loss: 0.7707429459704296\n",
      "Epoch: 19, Iteration: 4800, Loss: 0.7952182425450933\n",
      "Epoch: 19, Iteration: 6400, Loss: 0.9437245598511637\n",
      "Epoch: 19, Iteration: 8000, Loss: 0.9618685923495395\n",
      "Epoch: 19, Iteration: 9600, Loss: 0.5853495459578731\n",
      "Epoch: 19, Iteration: 11200, Loss: 0.839856215259321\n",
      "Epoch: 19, Iteration: 12800, Loss: 0.8157186164430525\n",
      "Epoch: 19, Iteration: 14400, Loss: 0.5978248912053814\n",
      "Epoch: 19, Iteration: 16000, Loss: 0.8585781937243613\n",
      "Epoch: 19, Iteration: 17600, Loss: 0.8454699667067102\n",
      "Epoch: 19, Iteration: 19200, Loss: 0.7100940172433026\n",
      "Epoch: 19, Iteration: 20800, Loss: 0.846510323834823\n",
      "Epoch: 19, Iteration: 22400, Loss: 0.8696736660256295\n",
      "Epoch: 19, Iteration: 24000, Loss: 0.55085284402245\n",
      "Epoch: 19, Iteration: 25600, Loss: 0.880568336082827\n",
      "Epoch: 19, Iteration: 27200, Loss: 0.9245578715910381\n",
      "Epoch: 19, Iteration: 28800, Loss: 0.6142908222982425\n",
      "Epoch: 19, Iteration: 30400, Loss: 0.9849151319370437\n",
      "Epoch: 19, Iteration: 32000, Loss: 0.8958442472105298\n",
      "Epoch: 19, Iteration: 33600, Loss: 0.7998132247464934\n",
      "Epoch: 19, Iteration: 35200, Loss: 0.7627853108214249\n",
      "Epoch: 19, Iteration: 36800, Loss: 1.0651968413468649\n",
      "Epoch: 19, Iteration: 38400, Loss: 0.6615618338579938\n",
      "Epoch: 19, Iteration: 40000, Loss: 0.912435849985779\n",
      "Epoch: 19, Iteration: 41600, Loss: 0.9414453386115483\n",
      "Epoch: 19, Iteration: 43200, Loss: 0.7302949212785493\n",
      "Epoch: 19, Iteration: 44800, Loss: 0.7540792981671498\n",
      "Epoch: 19, Iteration: 46400, Loss: 0.983535400655982\n",
      "Epoch: 19, Iteration: 48000, Loss: 0.7818521388453804\n",
      "Epoch: 19, Iteration: 49600, Loss: 0.8903572364665182\n",
      "Epoch: 19, Iteration: 51200, Loss: 0.6689156648957993\n",
      "Epoch: 19, Iteration: 52800, Loss: 0.9789586169957203\n",
      "Epoch: 19, Iteration: 54400, Loss: 0.8886457674435394\n",
      "Epoch: 19, Iteration: 56000, Loss: 0.7108642422298863\n",
      "Epoch: 19, Iteration: 57600, Loss: 0.903968285522931\n",
      "Epoch: 19, Iteration: 59200, Loss: 0.7765804673094762\n",
      "Epoch: 19, Iteration: 60800, Loss: 1.0641336509348729\n",
      "Epoch: 19, Iteration: 62400, Loss: 0.8662827451112617\n",
      "Epoch: 20, Iteration: 0, Loss: 0.6654092975219714\n",
      "Epoch: 20, Iteration: 1600, Loss: 0.8685576040228494\n",
      "Epoch: 20, Iteration: 3200, Loss: 0.7775395010425317\n",
      "Epoch: 20, Iteration: 4800, Loss: 0.76991990484837\n",
      "Epoch: 20, Iteration: 6400, Loss: 0.9310356018044628\n",
      "Epoch: 20, Iteration: 8000, Loss: 0.9309339916097167\n",
      "Epoch: 20, Iteration: 9600, Loss: 0.561654532855637\n",
      "Epoch: 20, Iteration: 11200, Loss: 0.8203011423783434\n",
      "Epoch: 20, Iteration: 12800, Loss: 0.7767110138936223\n",
      "Epoch: 20, Iteration: 14400, Loss: 0.5783729225133525\n",
      "Epoch: 20, Iteration: 16000, Loss: 0.8320218640335093\n",
      "Epoch: 20, Iteration: 17600, Loss: 0.8282310705359729\n",
      "Epoch: 20, Iteration: 19200, Loss: 0.6960079602126286\n",
      "Epoch: 20, Iteration: 20800, Loss: 0.8154045844757994\n",
      "Epoch: 20, Iteration: 22400, Loss: 0.8428281417787036\n",
      "Epoch: 20, Iteration: 24000, Loss: 0.5476696841709556\n",
      "Epoch: 20, Iteration: 25600, Loss: 0.8633399471691522\n",
      "Epoch: 20, Iteration: 27200, Loss: 0.9063103787869995\n",
      "Epoch: 20, Iteration: 28800, Loss: 0.5827427701612824\n",
      "Epoch: 20, Iteration: 30400, Loss: 0.9674685462427821\n",
      "Epoch: 20, Iteration: 32000, Loss: 0.8785920064931714\n",
      "Epoch: 20, Iteration: 33600, Loss: 0.7620833953981967\n",
      "Epoch: 20, Iteration: 35200, Loss: 0.762954531190958\n",
      "Epoch: 20, Iteration: 36800, Loss: 1.0594681344031702\n",
      "Epoch: 20, Iteration: 38400, Loss: 0.6694983741878227\n",
      "Epoch: 20, Iteration: 40000, Loss: 0.8866447573396092\n",
      "Epoch: 20, Iteration: 41600, Loss: 0.9174103920119463\n",
      "Epoch: 20, Iteration: 43200, Loss: 0.7308504019998496\n",
      "Epoch: 20, Iteration: 44800, Loss: 0.7279392754390708\n",
      "Epoch: 20, Iteration: 46400, Loss: 0.9730226246217106\n",
      "Epoch: 20, Iteration: 48000, Loss: 0.7767337671122885\n",
      "Epoch: 20, Iteration: 49600, Loss: 0.8696326968380106\n",
      "Epoch: 20, Iteration: 51200, Loss: 0.6504388792064575\n",
      "Epoch: 20, Iteration: 52800, Loss: 0.9566452150042374\n",
      "Epoch: 20, Iteration: 54400, Loss: 0.8760826203422662\n",
      "Epoch: 20, Iteration: 56000, Loss: 0.7018501512711227\n",
      "Epoch: 20, Iteration: 57600, Loss: 0.8899599855427649\n",
      "Epoch: 20, Iteration: 59200, Loss: 0.7367482313702489\n",
      "Epoch: 20, Iteration: 60800, Loss: 1.032345710800127\n",
      "Epoch: 20, Iteration: 62400, Loss: 0.86854903508506\n",
      "Epoch: 21, Iteration: 0, Loss: 0.6681745668583148\n",
      "Epoch: 21, Iteration: 1600, Loss: 0.8373562329853883\n",
      "Epoch: 21, Iteration: 3200, Loss: 0.779712131489651\n",
      "Epoch: 21, Iteration: 4800, Loss: 0.7566394445753217\n",
      "Epoch: 21, Iteration: 6400, Loss: 0.927520945787717\n",
      "Epoch: 21, Iteration: 8000, Loss: 0.9084920218847092\n",
      "Epoch: 21, Iteration: 9600, Loss: 0.5498823688052101\n",
      "Epoch: 21, Iteration: 11200, Loss: 0.8111887252055254\n",
      "Epoch: 21, Iteration: 12800, Loss: 0.7435709495568311\n",
      "Epoch: 21, Iteration: 14400, Loss: 0.5614623452380094\n",
      "Epoch: 21, Iteration: 16000, Loss: 0.8101355245855024\n",
      "Epoch: 21, Iteration: 17600, Loss: 0.8218823518013786\n",
      "Epoch: 21, Iteration: 19200, Loss: 0.6883934807664356\n",
      "Epoch: 21, Iteration: 20800, Loss: 0.7932635389604334\n",
      "Epoch: 21, Iteration: 22400, Loss: 0.8177019948869397\n",
      "Epoch: 21, Iteration: 24000, Loss: 0.5517991873038637\n",
      "Epoch: 21, Iteration: 25600, Loss: 0.8576917536057531\n",
      "Epoch: 21, Iteration: 27200, Loss: 0.8853114398417256\n",
      "Epoch: 21, Iteration: 28800, Loss: 0.561296586561485\n",
      "Epoch: 21, Iteration: 30400, Loss: 0.9478370397491607\n",
      "Epoch: 21, Iteration: 32000, Loss: 0.8612800683349764\n",
      "Epoch: 21, Iteration: 33600, Loss: 0.7249487131778012\n",
      "Epoch: 21, Iteration: 35200, Loss: 0.7636576682169627\n",
      "Epoch: 21, Iteration: 36800, Loss: 1.04941615326682\n",
      "Epoch: 21, Iteration: 38400, Loss: 0.6859122388400412\n",
      "Epoch: 21, Iteration: 40000, Loss: 0.863476148876071\n",
      "Epoch: 21, Iteration: 41600, Loss: 0.9070296625642623\n",
      "Epoch: 21, Iteration: 43200, Loss: 0.7249632653905611\n",
      "Epoch: 21, Iteration: 44800, Loss: 0.7089330769760015\n",
      "Epoch: 21, Iteration: 46400, Loss: 0.972243991311924\n",
      "Epoch: 21, Iteration: 48000, Loss: 0.773331253425531\n",
      "Epoch: 21, Iteration: 49600, Loss: 0.8497324448562424\n",
      "Epoch: 21, Iteration: 51200, Loss: 0.6401975592852926\n",
      "Epoch: 21, Iteration: 52800, Loss: 0.9422104547304953\n",
      "Epoch: 21, Iteration: 54400, Loss: 0.8558574292456849\n",
      "Epoch: 21, Iteration: 56000, Loss: 0.6984543644725872\n",
      "Epoch: 21, Iteration: 57600, Loss: 0.8736441077961796\n",
      "Epoch: 21, Iteration: 59200, Loss: 0.692327697900337\n",
      "Epoch: 21, Iteration: 60800, Loss: 0.9955273622007668\n",
      "Epoch: 21, Iteration: 62400, Loss: 0.8698521786837883\n",
      "Epoch: 22, Iteration: 0, Loss: 0.6728919781948793\n",
      "Epoch: 22, Iteration: 1600, Loss: 0.8024895961732967\n",
      "Epoch: 22, Iteration: 3200, Loss: 0.7772876543264035\n",
      "Epoch: 22, Iteration: 4800, Loss: 0.7590791333601632\n",
      "Epoch: 22, Iteration: 6400, Loss: 0.9327438023730478\n",
      "Epoch: 22, Iteration: 8000, Loss: 0.8935606731354474\n",
      "Epoch: 22, Iteration: 9600, Loss: 0.5450412345350877\n",
      "Epoch: 22, Iteration: 11200, Loss: 0.810096034216939\n",
      "Epoch: 22, Iteration: 12800, Loss: 0.7218383428617807\n",
      "Epoch: 22, Iteration: 14400, Loss: 0.545702610610833\n",
      "Epoch: 22, Iteration: 16000, Loss: 0.7947029282902961\n",
      "Epoch: 22, Iteration: 17600, Loss: 0.8238536274541118\n",
      "Epoch: 22, Iteration: 19200, Loss: 0.677005462734054\n",
      "Epoch: 22, Iteration: 20800, Loss: 0.7878484173406912\n",
      "Epoch: 22, Iteration: 22400, Loss: 0.7911425839386411\n",
      "Epoch: 22, Iteration: 24000, Loss: 0.5599067606214849\n",
      "Epoch: 22, Iteration: 25600, Loss: 0.8473620799615078\n",
      "Epoch: 22, Iteration: 27200, Loss: 0.8582703457366305\n",
      "Epoch: 22, Iteration: 28800, Loss: 0.5440453409020599\n",
      "Epoch: 22, Iteration: 30400, Loss: 0.9208870194878873\n",
      "Epoch: 22, Iteration: 32000, Loss: 0.8456598913898137\n",
      "Epoch: 22, Iteration: 33600, Loss: 0.6930228346171784\n",
      "Epoch: 22, Iteration: 35200, Loss: 0.7617130121300548\n",
      "Epoch: 22, Iteration: 36800, Loss: 1.0252400104542898\n",
      "Epoch: 22, Iteration: 38400, Loss: 0.6976443409431248\n",
      "Epoch: 22, Iteration: 40000, Loss: 0.8548801645094789\n",
      "Epoch: 22, Iteration: 41600, Loss: 0.8945599845575849\n",
      "Epoch: 22, Iteration: 43200, Loss: 0.7064774584211375\n",
      "Epoch: 22, Iteration: 44800, Loss: 0.6953939916709779\n",
      "Epoch: 22, Iteration: 46400, Loss: 0.974940331389838\n",
      "Epoch: 22, Iteration: 48000, Loss: 0.7717633179245094\n",
      "Epoch: 22, Iteration: 49600, Loss: 0.8313291647462286\n",
      "Epoch: 22, Iteration: 51200, Loss: 0.6317880122504316\n",
      "Epoch: 22, Iteration: 52800, Loss: 0.9407760671715987\n",
      "Epoch: 22, Iteration: 54400, Loss: 0.8418028129482562\n",
      "Epoch: 22, Iteration: 56000, Loss: 0.6954146094271384\n",
      "Epoch: 22, Iteration: 57600, Loss: 0.8484768975532742\n",
      "Epoch: 22, Iteration: 59200, Loss: 0.654623968169757\n",
      "Epoch: 22, Iteration: 60800, Loss: 0.9691269418559141\n",
      "Epoch: 22, Iteration: 62400, Loss: 0.8611696059907302\n",
      "Epoch: 23, Iteration: 0, Loss: 0.6786197391616027\n",
      "Epoch: 23, Iteration: 1600, Loss: 0.7697195558095398\n",
      "Epoch: 23, Iteration: 3200, Loss: 0.7756103546052986\n",
      "Epoch: 23, Iteration: 4800, Loss: 0.7648938963594325\n",
      "Epoch: 23, Iteration: 6400, Loss: 0.9292589435065276\n",
      "Epoch: 23, Iteration: 8000, Loss: 0.8786953372391382\n",
      "Epoch: 23, Iteration: 9600, Loss: 0.546507882188626\n",
      "Epoch: 23, Iteration: 11200, Loss: 0.8073399889631372\n",
      "Epoch: 23, Iteration: 12800, Loss: 0.7053335472971183\n",
      "Epoch: 23, Iteration: 14400, Loss: 0.5327873139413187\n",
      "Epoch: 23, Iteration: 16000, Loss: 0.7771832844400166\n",
      "Epoch: 23, Iteration: 17600, Loss: 0.8295565391922671\n",
      "Epoch: 23, Iteration: 19200, Loss: 0.6618705496083777\n",
      "Epoch: 23, Iteration: 20800, Loss: 0.7831338381930689\n",
      "Epoch: 23, Iteration: 22400, Loss: 0.7711147846175759\n",
      "Epoch: 23, Iteration: 24000, Loss: 0.5652346337307217\n",
      "Epoch: 23, Iteration: 25600, Loss: 0.8299866009574517\n",
      "Epoch: 23, Iteration: 27200, Loss: 0.8310137329923389\n",
      "Epoch: 23, Iteration: 28800, Loss: 0.52392032156593\n",
      "Epoch: 23, Iteration: 30400, Loss: 0.9009672803335691\n",
      "Epoch: 23, Iteration: 32000, Loss: 0.8291725651430646\n",
      "Epoch: 23, Iteration: 33600, Loss: 0.6710370361536124\n",
      "Epoch: 23, Iteration: 35200, Loss: 0.7579727993234897\n",
      "Epoch: 23, Iteration: 36800, Loss: 1.0038646528823296\n",
      "Epoch: 23, Iteration: 38400, Loss: 0.6992228669130346\n",
      "Epoch: 23, Iteration: 40000, Loss: 0.8491256765884587\n",
      "Epoch: 23, Iteration: 41600, Loss: 0.8772888301191946\n",
      "Epoch: 23, Iteration: 43200, Loss: 0.6891232044459973\n",
      "Epoch: 23, Iteration: 44800, Loss: 0.680889593908932\n",
      "Epoch: 23, Iteration: 46400, Loss: 0.9775211341513155\n",
      "Epoch: 23, Iteration: 48000, Loss: 0.7642273879005799\n",
      "Epoch: 23, Iteration: 49600, Loss: 0.8171945835472727\n",
      "Epoch: 23, Iteration: 51200, Loss: 0.6189694895942816\n",
      "Epoch: 23, Iteration: 52800, Loss: 0.9423973415174559\n",
      "Epoch: 23, Iteration: 54400, Loss: 0.8331197332011855\n",
      "Epoch: 23, Iteration: 56000, Loss: 0.6932664019192685\n",
      "Epoch: 23, Iteration: 57600, Loss: 0.8243534263720596\n",
      "Epoch: 23, Iteration: 59200, Loss: 0.6224502779663478\n",
      "Epoch: 23, Iteration: 60800, Loss: 0.9497506848225968\n",
      "Epoch: 23, Iteration: 62400, Loss: 0.8494144920832012\n",
      "Epoch: 24, Iteration: 0, Loss: 0.6800756791208624\n",
      "Epoch: 24, Iteration: 1600, Loss: 0.7453660229373711\n",
      "Epoch: 24, Iteration: 3200, Loss: 0.7734959250833039\n",
      "Epoch: 24, Iteration: 4800, Loss: 0.7686218565538618\n",
      "Epoch: 24, Iteration: 6400, Loss: 0.919107523251675\n",
      "Epoch: 24, Iteration: 8000, Loss: 0.8631622622275639\n",
      "Epoch: 24, Iteration: 9600, Loss: 0.550665141622533\n",
      "Epoch: 24, Iteration: 11200, Loss: 0.8010865959865134\n",
      "Epoch: 24, Iteration: 12800, Loss: 0.6972227562456894\n",
      "Epoch: 24, Iteration: 14400, Loss: 0.5245938881120848\n",
      "Epoch: 24, Iteration: 16000, Loss: 0.7577257945656873\n",
      "Epoch: 24, Iteration: 17600, Loss: 0.8340720540191782\n",
      "Epoch: 24, Iteration: 19200, Loss: 0.6502702717504025\n",
      "Epoch: 24, Iteration: 20800, Loss: 0.7762188014478906\n",
      "Epoch: 24, Iteration: 22400, Loss: 0.7567826303252558\n",
      "Epoch: 24, Iteration: 24000, Loss: 0.5645139964493111\n",
      "Epoch: 24, Iteration: 25600, Loss: 0.8166161917826946\n",
      "Epoch: 24, Iteration: 27200, Loss: 0.8074382829062889\n",
      "Epoch: 24, Iteration: 28800, Loss: 0.505870540604578\n",
      "Epoch: 24, Iteration: 30400, Loss: 0.8863747077440309\n",
      "Epoch: 24, Iteration: 32000, Loss: 0.8082265625137366\n",
      "Epoch: 24, Iteration: 33600, Loss: 0.6553200932567008\n",
      "Epoch: 24, Iteration: 35200, Loss: 0.7540593256212783\n",
      "Epoch: 24, Iteration: 36800, Loss: 0.9841882731821533\n",
      "Epoch: 24, Iteration: 38400, Loss: 0.6943862604134136\n",
      "Epoch: 24, Iteration: 40000, Loss: 0.837481821109451\n",
      "Epoch: 24, Iteration: 41600, Loss: 0.8648837934195462\n",
      "Epoch: 24, Iteration: 43200, Loss: 0.6736634304673628\n",
      "Epoch: 24, Iteration: 44800, Loss: 0.6687496247044431\n",
      "Epoch: 24, Iteration: 46400, Loss: 0.9791429161068939\n",
      "Epoch: 24, Iteration: 48000, Loss: 0.7530514610258287\n",
      "Epoch: 24, Iteration: 49600, Loss: 0.8046263718543367\n",
      "Epoch: 24, Iteration: 51200, Loss: 0.6023795262395841\n",
      "Epoch: 24, Iteration: 52800, Loss: 0.943197781000245\n",
      "Epoch: 24, Iteration: 54400, Loss: 0.8286795103826132\n",
      "Epoch: 24, Iteration: 56000, Loss: 0.6919142617841205\n",
      "Epoch: 24, Iteration: 57600, Loss: 0.8037772571380011\n",
      "Epoch: 24, Iteration: 59200, Loss: 0.5946252781815636\n",
      "Epoch: 24, Iteration: 60800, Loss: 0.9326395336070994\n",
      "Epoch: 24, Iteration: 62400, Loss: 0.8385414609732909\n",
      "Epoch: 25, Iteration: 0, Loss: 0.677985583109947\n",
      "Epoch: 25, Iteration: 1600, Loss: 0.7262060283894749\n",
      "Epoch: 25, Iteration: 3200, Loss: 0.7701835303811557\n",
      "Epoch: 25, Iteration: 4800, Loss: 0.7700450325239103\n",
      "Epoch: 25, Iteration: 6400, Loss: 0.9077134027207641\n",
      "Epoch: 25, Iteration: 8000, Loss: 0.8499128321714617\n",
      "Epoch: 25, Iteration: 9600, Loss: 0.554656894217437\n",
      "Epoch: 25, Iteration: 11200, Loss: 0.7928930429866617\n",
      "Epoch: 25, Iteration: 12800, Loss: 0.698965295395322\n",
      "Epoch: 25, Iteration: 14400, Loss: 0.5196697599895803\n",
      "Epoch: 25, Iteration: 16000, Loss: 0.7386271868417201\n",
      "Epoch: 25, Iteration: 17600, Loss: 0.8378371063272299\n",
      "Epoch: 25, Iteration: 19200, Loss: 0.644155694653892\n",
      "Epoch: 25, Iteration: 20800, Loss: 0.7681262701970765\n",
      "Epoch: 25, Iteration: 22400, Loss: 0.7479975670904584\n",
      "Epoch: 25, Iteration: 24000, Loss: 0.5605210328250394\n",
      "Epoch: 25, Iteration: 25600, Loss: 0.8085520370112278\n",
      "Epoch: 25, Iteration: 27200, Loss: 0.788921968010917\n",
      "Epoch: 25, Iteration: 28800, Loss: 0.4925179075870656\n",
      "Epoch: 25, Iteration: 30400, Loss: 0.874857290054045\n",
      "Epoch: 25, Iteration: 32000, Loss: 0.7830242208169058\n",
      "Epoch: 25, Iteration: 33600, Loss: 0.6442694846414471\n",
      "Epoch: 25, Iteration: 35200, Loss: 0.7528321068000182\n",
      "Epoch: 25, Iteration: 36800, Loss: 0.9648710314231045\n",
      "Epoch: 25, Iteration: 38400, Loss: 0.6854624779562974\n",
      "Epoch: 25, Iteration: 40000, Loss: 0.8224294913466729\n",
      "Epoch: 25, Iteration: 41600, Loss: 0.8576810629413517\n",
      "Epoch: 25, Iteration: 43200, Loss: 0.6595121431784169\n",
      "Epoch: 25, Iteration: 44800, Loss: 0.661559773683623\n",
      "Epoch: 25, Iteration: 46400, Loss: 0.9781263036538423\n",
      "Epoch: 25, Iteration: 48000, Loss: 0.7372569714414076\n",
      "Epoch: 25, Iteration: 49600, Loss: 0.7951054664918507\n",
      "Epoch: 25, Iteration: 51200, Loss: 0.5845910892006417\n",
      "Epoch: 25, Iteration: 52800, Loss: 0.9448805986618873\n",
      "Epoch: 25, Iteration: 54400, Loss: 0.8271169313833163\n",
      "Epoch: 25, Iteration: 56000, Loss: 0.6906598151271792\n",
      "Epoch: 25, Iteration: 57600, Loss: 0.7859700420441291\n",
      "Epoch: 25, Iteration: 59200, Loss: 0.572664900190392\n",
      "Epoch: 25, Iteration: 60800, Loss: 0.9167819994693788\n",
      "Epoch: 25, Iteration: 62400, Loss: 0.8292030265586862\n",
      "Epoch: 26, Iteration: 0, Loss: 0.6732543932124506\n",
      "Epoch: 26, Iteration: 1600, Loss: 0.7113375808678415\n",
      "Epoch: 26, Iteration: 3200, Loss: 0.7664794501176054\n",
      "Epoch: 26, Iteration: 4800, Loss: 0.7708634543915103\n",
      "Epoch: 26, Iteration: 6400, Loss: 0.8964186461359559\n",
      "Epoch: 26, Iteration: 8000, Loss: 0.8414117591414841\n",
      "Epoch: 26, Iteration: 9600, Loss: 0.5587759730622287\n",
      "Epoch: 26, Iteration: 11200, Loss: 0.784490678815476\n",
      "Epoch: 26, Iteration: 12800, Loss: 0.71044842305381\n",
      "Epoch: 26, Iteration: 14400, Loss: 0.5171322532516377\n",
      "Epoch: 26, Iteration: 16000, Loss: 0.7220494523213541\n",
      "Epoch: 26, Iteration: 17600, Loss: 0.8421918406849341\n",
      "Epoch: 26, Iteration: 19200, Loss: 0.6439640970294275\n",
      "Epoch: 26, Iteration: 20800, Loss: 0.7601774540001776\n",
      "Epoch: 26, Iteration: 22400, Loss: 0.7462981666003277\n",
      "Epoch: 26, Iteration: 24000, Loss: 0.5538777019307186\n",
      "Epoch: 26, Iteration: 25600, Loss: 0.8054070196811948\n",
      "Epoch: 26, Iteration: 27200, Loss: 0.7783498717116559\n",
      "Epoch: 26, Iteration: 28800, Loss: 0.48704656458924817\n",
      "Epoch: 26, Iteration: 30400, Loss: 0.8648414322158843\n",
      "Epoch: 26, Iteration: 32000, Loss: 0.7556172833029104\n",
      "Epoch: 26, Iteration: 33600, Loss: 0.6405736474601762\n",
      "Epoch: 26, Iteration: 35200, Loss: 0.7561585344161524\n",
      "Epoch: 26, Iteration: 36800, Loss: 0.9477871546593961\n",
      "Epoch: 26, Iteration: 38400, Loss: 0.6749181018516711\n",
      "Epoch: 26, Iteration: 40000, Loss: 0.8067141350796303\n",
      "Epoch: 26, Iteration: 41600, Loss: 0.855347636661659\n",
      "Epoch: 26, Iteration: 43200, Loss: 0.6492129194906486\n",
      "Epoch: 26, Iteration: 44800, Loss: 0.6632431537624109\n",
      "Epoch: 26, Iteration: 46400, Loss: 0.9728431742233657\n",
      "Epoch: 26, Iteration: 48000, Loss: 0.7144366210570858\n",
      "Epoch: 26, Iteration: 49600, Loss: 0.7916691066810809\n",
      "Epoch: 26, Iteration: 51200, Loss: 0.5697662030009589\n",
      "Epoch: 26, Iteration: 52800, Loss: 0.9501666474046304\n",
      "Epoch: 26, Iteration: 54400, Loss: 0.8262215293772607\n",
      "Epoch: 26, Iteration: 56000, Loss: 0.6916738356796219\n",
      "Epoch: 26, Iteration: 57600, Loss: 0.7690518876998609\n",
      "Epoch: 26, Iteration: 59200, Loss: 0.5604381690106564\n",
      "Epoch: 26, Iteration: 60800, Loss: 0.8989660311608164\n",
      "Epoch: 26, Iteration: 62400, Loss: 0.8201896039736676\n",
      "Epoch: 27, Iteration: 0, Loss: 0.6652150833252164\n",
      "Epoch: 27, Iteration: 1600, Loss: 0.7014643479096437\n",
      "Epoch: 27, Iteration: 3200, Loss: 0.7625031389235788\n",
      "Epoch: 27, Iteration: 4800, Loss: 0.7759930942082951\n",
      "Epoch: 27, Iteration: 6400, Loss: 0.8860272887111307\n",
      "Epoch: 27, Iteration: 8000, Loss: 0.8436513307627759\n",
      "Epoch: 27, Iteration: 9600, Loss: 0.5643970245038777\n",
      "Epoch: 27, Iteration: 11200, Loss: 0.7730811209046664\n",
      "Epoch: 27, Iteration: 12800, Loss: 0.7313877519917681\n",
      "Epoch: 27, Iteration: 14400, Loss: 0.5143190981253258\n",
      "Epoch: 27, Iteration: 16000, Loss: 0.7140141090780081\n",
      "Epoch: 27, Iteration: 17600, Loss: 0.850604900981141\n",
      "Epoch: 27, Iteration: 19200, Loss: 0.6473128680959976\n",
      "Epoch: 27, Iteration: 20800, Loss: 0.756311600624503\n",
      "Epoch: 27, Iteration: 22400, Loss: 0.7544639086498721\n",
      "Epoch: 27, Iteration: 24000, Loss: 0.5459727703144942\n",
      "Epoch: 27, Iteration: 25600, Loss: 0.8056950994143268\n",
      "Epoch: 27, Iteration: 27200, Loss: 0.7747240863058349\n",
      "Epoch: 27, Iteration: 28800, Loss: 0.492341170614488\n",
      "Epoch: 27, Iteration: 30400, Loss: 0.8526294282153017\n",
      "Epoch: 27, Iteration: 32000, Loss: 0.729871775008613\n",
      "Epoch: 27, Iteration: 33600, Loss: 0.6492765713238051\n",
      "Epoch: 27, Iteration: 35200, Loss: 0.7674629645904474\n",
      "Epoch: 27, Iteration: 36800, Loss: 0.9351575105598695\n",
      "Epoch: 27, Iteration: 38400, Loss: 0.6685741872093232\n",
      "Epoch: 27, Iteration: 40000, Loss: 0.7901833562982628\n",
      "Epoch: 27, Iteration: 41600, Loss: 0.860376578525314\n",
      "Epoch: 27, Iteration: 43200, Loss: 0.6476500042876814\n",
      "Epoch: 27, Iteration: 44800, Loss: 0.681347099863745\n",
      "Epoch: 27, Iteration: 46400, Loss: 0.9666621703286731\n",
      "Epoch: 27, Iteration: 48000, Loss: 0.6885721147652898\n",
      "Epoch: 27, Iteration: 49600, Loss: 0.7991612909335843\n",
      "Epoch: 27, Iteration: 51200, Loss: 0.5658461394583333\n",
      "Epoch: 27, Iteration: 52800, Loss: 0.96252189054718\n",
      "Epoch: 27, Iteration: 54400, Loss: 0.8245924004557525\n",
      "Epoch: 27, Iteration: 56000, Loss: 0.697811667177094\n",
      "Epoch: 27, Iteration: 57600, Loss: 0.7528569733042758\n",
      "Epoch: 27, Iteration: 59200, Loss: 0.5625936464606158\n",
      "Epoch: 27, Iteration: 60800, Loss: 0.8791359843556936\n",
      "Epoch: 27, Iteration: 62400, Loss: 0.8131243488859875\n",
      "Epoch: 28, Iteration: 0, Loss: 0.6535205299750662\n",
      "Epoch: 28, Iteration: 1600, Loss: 0.7051316739859503\n",
      "Epoch: 28, Iteration: 3200, Loss: 0.7548918370539301\n",
      "Epoch: 28, Iteration: 4800, Loss: 0.7924777127224993\n",
      "Epoch: 28, Iteration: 6400, Loss: 0.8737851465470375\n",
      "Epoch: 28, Iteration: 8000, Loss: 0.8555853969031959\n",
      "Epoch: 28, Iteration: 9600, Loss: 0.5654586043771843\n",
      "Epoch: 28, Iteration: 11200, Loss: 0.7557396306800569\n",
      "Epoch: 28, Iteration: 12800, Loss: 0.7542627554548289\n",
      "Epoch: 28, Iteration: 14400, Loss: 0.5140080070294719\n",
      "Epoch: 28, Iteration: 16000, Loss: 0.7230422978396425\n",
      "Epoch: 28, Iteration: 17600, Loss: 0.8577141221584302\n",
      "Epoch: 28, Iteration: 19200, Loss: 0.6405551471136829\n",
      "Epoch: 28, Iteration: 20800, Loss: 0.7636777357228244\n",
      "Epoch: 28, Iteration: 22400, Loss: 0.7720187870584198\n",
      "Epoch: 28, Iteration: 24000, Loss: 0.5426890240677587\n",
      "Epoch: 28, Iteration: 25600, Loss: 0.8098066861383311\n",
      "Epoch: 28, Iteration: 27200, Loss: 0.7767574865164955\n",
      "Epoch: 28, Iteration: 28800, Loss: 0.4978534719915487\n",
      "Epoch: 28, Iteration: 30400, Loss: 0.8359885919095704\n",
      "Epoch: 28, Iteration: 32000, Loss: 0.7075337566193278\n",
      "Epoch: 28, Iteration: 33600, Loss: 0.6609927632730956\n",
      "Epoch: 28, Iteration: 35200, Loss: 0.7896625923997955\n",
      "Epoch: 28, Iteration: 36800, Loss: 0.9294309874731246\n",
      "Epoch: 28, Iteration: 38400, Loss: 0.669955037803303\n",
      "Epoch: 28, Iteration: 40000, Loss: 0.7732521773160548\n",
      "Epoch: 28, Iteration: 41600, Loss: 0.8694050428550377\n",
      "Epoch: 28, Iteration: 43200, Loss: 0.6418232148204134\n",
      "Epoch: 28, Iteration: 44800, Loss: 0.6989898527105687\n",
      "Epoch: 28, Iteration: 46400, Loss: 0.9666157038278986\n",
      "Epoch: 28, Iteration: 48000, Loss: 0.6779602046726864\n",
      "Epoch: 28, Iteration: 49600, Loss: 0.807199723267147\n",
      "Epoch: 28, Iteration: 51200, Loss: 0.5768035557682545\n",
      "Epoch: 28, Iteration: 52800, Loss: 0.9803677552545641\n",
      "Epoch: 28, Iteration: 54400, Loss: 0.8229860238235797\n",
      "Epoch: 28, Iteration: 56000, Loss: 0.6961012004689384\n",
      "Epoch: 28, Iteration: 57600, Loss: 0.7454851047651461\n",
      "Epoch: 28, Iteration: 59200, Loss: 0.5585124270940615\n",
      "Epoch: 28, Iteration: 60800, Loss: 0.8692105311692524\n",
      "Epoch: 28, Iteration: 62400, Loss: 0.8089113569421499\n",
      "Epoch: 29, Iteration: 0, Loss: 0.6551566749619397\n",
      "Epoch: 29, Iteration: 1600, Loss: 0.7093429644355889\n",
      "Epoch: 29, Iteration: 3200, Loss: 0.7413210369838568\n",
      "Epoch: 29, Iteration: 4800, Loss: 0.8037599051427553\n",
      "Epoch: 29, Iteration: 6400, Loss: 0.858682238647419\n",
      "Epoch: 29, Iteration: 8000, Loss: 0.8519343843851862\n",
      "Epoch: 29, Iteration: 9600, Loss: 0.5538074472603363\n",
      "Epoch: 29, Iteration: 11200, Loss: 0.7472280895926926\n",
      "Epoch: 29, Iteration: 12800, Loss: 0.7673080256457951\n",
      "Epoch: 29, Iteration: 14400, Loss: 0.5196962282825922\n",
      "Epoch: 29, Iteration: 16000, Loss: 0.7263466366745941\n",
      "Epoch: 29, Iteration: 17600, Loss: 0.848977433104848\n",
      "Epoch: 29, Iteration: 19200, Loss: 0.6223704832642181\n",
      "Epoch: 29, Iteration: 20800, Loss: 0.7678457149065059\n",
      "Epoch: 29, Iteration: 22400, Loss: 0.786112870856496\n",
      "Epoch: 29, Iteration: 24000, Loss: 0.5369055948369033\n",
      "Epoch: 29, Iteration: 25600, Loss: 0.8169865971882712\n",
      "Epoch: 29, Iteration: 27200, Loss: 0.7749018513075863\n",
      "Epoch: 29, Iteration: 28800, Loss: 0.49774391320976374\n",
      "Epoch: 29, Iteration: 30400, Loss: 0.8196881063485568\n",
      "Epoch: 29, Iteration: 32000, Loss: 0.683054475177592\n",
      "Epoch: 29, Iteration: 33600, Loss: 0.6631160182605851\n",
      "Epoch: 29, Iteration: 35200, Loss: 0.8004204522251964\n",
      "Epoch: 29, Iteration: 36800, Loss: 0.9297326128955226\n",
      "Epoch: 29, Iteration: 38400, Loss: 0.6702916074665075\n",
      "Epoch: 29, Iteration: 40000, Loss: 0.7529468909151497\n",
      "Epoch: 29, Iteration: 41600, Loss: 0.8724798187618477\n",
      "Epoch: 29, Iteration: 43200, Loss: 0.6276577536736221\n",
      "Epoch: 29, Iteration: 44800, Loss: 0.7087274464074762\n",
      "Epoch: 29, Iteration: 46400, Loss: 0.9663611708953936\n",
      "Epoch: 29, Iteration: 48000, Loss: 0.6714716491823953\n",
      "Epoch: 29, Iteration: 49600, Loss: 0.8059057869598416\n",
      "Epoch: 29, Iteration: 51200, Loss: 0.582981424401364\n",
      "Epoch: 29, Iteration: 52800, Loss: 0.9868835151829496\n",
      "Epoch: 29, Iteration: 54400, Loss: 0.8196232000637221\n",
      "Epoch: 29, Iteration: 56000, Loss: 0.6924507913104669\n",
      "Epoch: 29, Iteration: 57600, Loss: 0.7420266512657442\n",
      "Epoch: 29, Iteration: 59200, Loss: 0.551796096447205\n",
      "Epoch: 29, Iteration: 60800, Loss: 0.8544676435880189\n",
      "Epoch: 29, Iteration: 62400, Loss: 0.8121917074197352\n",
      "Epoch: 30, Iteration: 0, Loss: 0.6592879620565881\n",
      "Epoch: 30, Iteration: 1600, Loss: 0.7052228470814458\n",
      "Epoch: 30, Iteration: 3200, Loss: 0.7271894482223886\n",
      "Epoch: 30, Iteration: 4800, Loss: 0.8005194309011223\n",
      "Epoch: 30, Iteration: 6400, Loss: 0.8510049908687181\n",
      "Epoch: 30, Iteration: 8000, Loss: 0.8445778778211654\n",
      "Epoch: 30, Iteration: 9600, Loss: 0.5410451108920526\n",
      "Epoch: 30, Iteration: 11200, Loss: 0.7431154662546923\n",
      "Epoch: 30, Iteration: 12800, Loss: 0.7802974035448343\n",
      "Epoch: 30, Iteration: 14400, Loss: 0.5211365879713414\n",
      "Epoch: 30, Iteration: 16000, Loss: 0.7213808386369535\n",
      "Epoch: 30, Iteration: 17600, Loss: 0.8367939946243256\n",
      "Epoch: 30, Iteration: 19200, Loss: 0.6048046719091598\n",
      "Epoch: 30, Iteration: 20800, Loss: 0.7626062838651921\n",
      "Epoch: 30, Iteration: 22400, Loss: 0.8020405652797802\n",
      "Epoch: 30, Iteration: 24000, Loss: 0.5291370036292109\n",
      "Epoch: 30, Iteration: 25600, Loss: 0.8200915590311236\n",
      "Epoch: 30, Iteration: 27200, Loss: 0.7658613296809678\n",
      "Epoch: 30, Iteration: 28800, Loss: 0.4938476301770195\n",
      "Epoch: 30, Iteration: 30400, Loss: 0.8024525245799177\n",
      "Epoch: 30, Iteration: 32000, Loss: 0.6656206989776817\n",
      "Epoch: 30, Iteration: 33600, Loss: 0.6551133711829454\n",
      "Epoch: 30, Iteration: 35200, Loss: 0.7980066413406295\n",
      "Epoch: 30, Iteration: 36800, Loss: 0.9339627333993596\n",
      "Epoch: 30, Iteration: 38400, Loss: 0.6686131834499405\n",
      "Epoch: 30, Iteration: 40000, Loss: 0.7353888126980337\n",
      "Epoch: 30, Iteration: 41600, Loss: 0.8783035479698269\n",
      "Epoch: 30, Iteration: 43200, Loss: 0.6184640022266698\n",
      "Epoch: 30, Iteration: 44800, Loss: 0.7193801207995241\n",
      "Epoch: 30, Iteration: 46400, Loss: 0.9636557245808397\n",
      "Epoch: 30, Iteration: 48000, Loss: 0.667917474378806\n",
      "Epoch: 30, Iteration: 49600, Loss: 0.7962595908404431\n",
      "Epoch: 30, Iteration: 51200, Loss: 0.5908549359634003\n",
      "Epoch: 30, Iteration: 52800, Loss: 0.9830730066500952\n",
      "Epoch: 30, Iteration: 54400, Loss: 0.8185495684102968\n",
      "Epoch: 30, Iteration: 56000, Loss: 0.6916132670367454\n",
      "Epoch: 30, Iteration: 57600, Loss: 0.7410171483859556\n",
      "Epoch: 30, Iteration: 59200, Loss: 0.5537771648270431\n",
      "Epoch: 30, Iteration: 60800, Loss: 0.8396599319550733\n",
      "Epoch: 30, Iteration: 62400, Loss: 0.8301829771630027\n",
      "Epoch: 31, Iteration: 0, Loss: 0.6633328899446387\n",
      "Epoch: 31, Iteration: 1600, Loss: 0.6998347231540256\n",
      "Epoch: 31, Iteration: 3200, Loss: 0.7156856293211697\n",
      "Epoch: 31, Iteration: 4800, Loss: 0.7831366535142835\n",
      "Epoch: 31, Iteration: 6400, Loss: 0.8491984726893518\n",
      "Epoch: 31, Iteration: 8000, Loss: 0.8444634841472853\n",
      "Epoch: 31, Iteration: 9600, Loss: 0.5299770169625493\n",
      "Epoch: 31, Iteration: 11200, Loss: 0.742562243863635\n",
      "Epoch: 31, Iteration: 12800, Loss: 0.7954984192820895\n",
      "Epoch: 31, Iteration: 14400, Loss: 0.5230690355435804\n",
      "Epoch: 31, Iteration: 16000, Loss: 0.7195330704399421\n",
      "Epoch: 31, Iteration: 17600, Loss: 0.8242333579224251\n",
      "Epoch: 31, Iteration: 19200, Loss: 0.5928797313414313\n",
      "Epoch: 31, Iteration: 20800, Loss: 0.7499463588821225\n",
      "Epoch: 31, Iteration: 22400, Loss: 0.8219120167769722\n",
      "Epoch: 31, Iteration: 24000, Loss: 0.5298891226319087\n",
      "Epoch: 31, Iteration: 25600, Loss: 0.8189094670363385\n",
      "Epoch: 31, Iteration: 27200, Loss: 0.7528303261043451\n",
      "Epoch: 31, Iteration: 28800, Loss: 0.49031356073641164\n",
      "Epoch: 31, Iteration: 30400, Loss: 0.7827429048517757\n",
      "Epoch: 31, Iteration: 32000, Loss: 0.6534142035066961\n",
      "Epoch: 31, Iteration: 33600, Loss: 0.6387581575783964\n",
      "Epoch: 31, Iteration: 35200, Loss: 0.78678966236474\n",
      "Epoch: 31, Iteration: 36800, Loss: 0.9411317593900934\n",
      "Epoch: 31, Iteration: 38400, Loss: 0.6697093618011278\n",
      "Epoch: 31, Iteration: 40000, Loss: 0.7313467052621003\n",
      "Epoch: 31, Iteration: 41600, Loss: 0.8882001446839232\n",
      "Epoch: 31, Iteration: 43200, Loss: 0.6211292055675097\n",
      "Epoch: 31, Iteration: 44800, Loss: 0.7290075198630928\n",
      "Epoch: 31, Iteration: 46400, Loss: 0.954606751183024\n",
      "Epoch: 31, Iteration: 48000, Loss: 0.6678201065712319\n",
      "Epoch: 31, Iteration: 49600, Loss: 0.7832771663406639\n",
      "Epoch: 31, Iteration: 51200, Loss: 0.6124244492585917\n",
      "Epoch: 31, Iteration: 52800, Loss: 0.9813777309069511\n",
      "Epoch: 31, Iteration: 54400, Loss: 0.8224814806712457\n",
      "Epoch: 31, Iteration: 56000, Loss: 0.6972532250935196\n",
      "Epoch: 31, Iteration: 57600, Loss: 0.7404278362197032\n",
      "Epoch: 31, Iteration: 59200, Loss: 0.5601360952635652\n",
      "Epoch: 31, Iteration: 60800, Loss: 0.8172645675589569\n",
      "Epoch: 31, Iteration: 62400, Loss: 0.8587020928642154\n",
      "Epoch: 32, Iteration: 0, Loss: 0.6776385090724215\n",
      "Epoch: 32, Iteration: 1600, Loss: 0.6930653136031792\n",
      "Epoch: 32, Iteration: 3200, Loss: 0.7114180144003529\n",
      "Epoch: 32, Iteration: 4800, Loss: 0.7556448409474206\n",
      "Epoch: 32, Iteration: 6400, Loss: 0.8489473539792054\n",
      "Epoch: 32, Iteration: 8000, Loss: 0.8524979607778997\n",
      "Epoch: 32, Iteration: 9600, Loss: 0.5236804521253977\n",
      "Epoch: 32, Iteration: 11200, Loss: 0.752650407674492\n",
      "Epoch: 32, Iteration: 12800, Loss: 0.8073504868249016\n",
      "Epoch: 32, Iteration: 14400, Loss: 0.5372641993858452\n",
      "Epoch: 32, Iteration: 16000, Loss: 0.7253361562987356\n",
      "Epoch: 32, Iteration: 17600, Loss: 0.812132706825944\n",
      "Epoch: 32, Iteration: 19200, Loss: 0.5961584252090235\n",
      "Epoch: 32, Iteration: 20800, Loss: 0.7318460628516865\n",
      "Epoch: 32, Iteration: 22400, Loss: 0.8282044988372494\n",
      "Epoch: 32, Iteration: 24000, Loss: 0.5487996032000928\n",
      "Epoch: 32, Iteration: 25600, Loss: 0.8205753548194703\n",
      "Epoch: 32, Iteration: 27200, Loss: 0.7377746004420689\n",
      "Epoch: 32, Iteration: 28800, Loss: 0.4885507425896543\n",
      "Epoch: 32, Iteration: 30400, Loss: 0.7677229661115446\n",
      "Epoch: 32, Iteration: 32000, Loss: 0.6369801623550699\n",
      "Epoch: 32, Iteration: 33600, Loss: 0.6207320140788435\n",
      "Epoch: 32, Iteration: 35200, Loss: 0.7836577666012849\n",
      "Epoch: 32, Iteration: 36800, Loss: 0.9490755181379893\n",
      "Epoch: 32, Iteration: 38400, Loss: 0.6579062768385622\n",
      "Epoch: 32, Iteration: 40000, Loss: 0.7391671221903692\n",
      "Epoch: 32, Iteration: 41600, Loss: 0.8942673366989282\n",
      "Epoch: 32, Iteration: 43200, Loss: 0.6468967615673896\n",
      "Epoch: 32, Iteration: 44800, Loss: 0.7325400144611895\n",
      "Epoch: 32, Iteration: 46400, Loss: 0.9565350239416126\n",
      "Epoch: 32, Iteration: 48000, Loss: 0.6738502583529946\n",
      "Epoch: 32, Iteration: 49600, Loss: 0.7746063377974066\n",
      "Epoch: 32, Iteration: 51200, Loss: 0.63734471499901\n",
      "Epoch: 32, Iteration: 52800, Loss: 0.9943977312293586\n",
      "Epoch: 32, Iteration: 54400, Loss: 0.8401578845848212\n",
      "Epoch: 32, Iteration: 56000, Loss: 0.7110174831766372\n",
      "Epoch: 32, Iteration: 57600, Loss: 0.7434727513942889\n",
      "Epoch: 32, Iteration: 59200, Loss: 0.5685759057611097\n",
      "Epoch: 32, Iteration: 60800, Loss: 0.8146108269619711\n",
      "Epoch: 32, Iteration: 62400, Loss: 0.8702063798990569\n",
      "Epoch: 33, Iteration: 0, Loss: 0.7154051751599402\n",
      "Epoch: 33, Iteration: 1600, Loss: 0.6966750843625515\n",
      "Epoch: 33, Iteration: 3200, Loss: 0.7283521345816841\n",
      "Epoch: 33, Iteration: 4800, Loss: 0.739720953913491\n",
      "Epoch: 33, Iteration: 6400, Loss: 0.8611293072416217\n",
      "Epoch: 33, Iteration: 8000, Loss: 0.8494092957141687\n",
      "Epoch: 33, Iteration: 9600, Loss: 0.5352393788620983\n",
      "Epoch: 33, Iteration: 11200, Loss: 0.7610493904155307\n",
      "Epoch: 33, Iteration: 12800, Loss: 0.8255268201250104\n",
      "Epoch: 33, Iteration: 14400, Loss: 0.561430106189748\n",
      "Epoch: 33, Iteration: 16000, Loss: 0.7406194951349638\n",
      "Epoch: 33, Iteration: 17600, Loss: 0.8241758582502355\n",
      "Epoch: 33, Iteration: 19200, Loss: 0.6215722223945397\n",
      "Epoch: 33, Iteration: 20800, Loss: 0.7295694014986953\n",
      "Epoch: 33, Iteration: 22400, Loss: 0.8277189495499999\n",
      "Epoch: 33, Iteration: 24000, Loss: 0.5761255619044926\n",
      "Epoch: 33, Iteration: 25600, Loss: 0.8377614803934812\n",
      "Epoch: 33, Iteration: 27200, Loss: 0.7317948451345434\n",
      "Epoch: 33, Iteration: 28800, Loss: 0.5095458447380904\n",
      "Epoch: 33, Iteration: 30400, Loss: 0.7564030160417683\n",
      "Epoch: 33, Iteration: 32000, Loss: 0.6451363880701566\n",
      "Epoch: 33, Iteration: 33600, Loss: 0.6130648198536905\n",
      "Epoch: 33, Iteration: 35200, Loss: 0.7955874642902928\n",
      "Epoch: 33, Iteration: 36800, Loss: 0.9466656626004994\n",
      "Epoch: 33, Iteration: 38400, Loss: 0.6432344520646424\n",
      "Epoch: 33, Iteration: 40000, Loss: 0.7524350008616508\n",
      "Epoch: 33, Iteration: 41600, Loss: 0.8977665050024672\n",
      "Epoch: 33, Iteration: 43200, Loss: 0.6752860488856338\n",
      "Epoch: 33, Iteration: 44800, Loss: 0.7445600371321188\n",
      "Epoch: 33, Iteration: 46400, Loss: 0.9748226927943521\n",
      "Epoch: 33, Iteration: 48000, Loss: 0.7082114361419394\n",
      "Epoch: 33, Iteration: 49600, Loss: 0.7766725169811681\n",
      "Epoch: 33, Iteration: 51200, Loss: 0.6473678478019895\n",
      "Epoch: 33, Iteration: 52800, Loss: 1.0123028877556348\n",
      "Epoch: 33, Iteration: 54400, Loss: 0.8603769769480889\n",
      "Epoch: 33, Iteration: 56000, Loss: 0.7270225312517333\n",
      "Epoch: 33, Iteration: 57600, Loss: 0.757379940024473\n",
      "Epoch: 33, Iteration: 59200, Loss: 0.5857808419310836\n",
      "Epoch: 33, Iteration: 60800, Loss: 0.8566626120030865\n",
      "Epoch: 33, Iteration: 62400, Loss: 0.8821527873326488\n",
      "Epoch: 34, Iteration: 0, Loss: 0.7476253958278889\n",
      "Epoch: 34, Iteration: 1600, Loss: 0.7135567160355369\n",
      "Epoch: 34, Iteration: 3200, Loss: 0.7698547385973913\n",
      "Epoch: 34, Iteration: 4800, Loss: 0.7524790507113243\n",
      "Epoch: 34, Iteration: 6400, Loss: 0.8837197724985388\n",
      "Epoch: 34, Iteration: 8000, Loss: 0.8432756802685055\n",
      "Epoch: 34, Iteration: 9600, Loss: 0.5638194634437559\n",
      "Epoch: 34, Iteration: 11200, Loss: 0.7690142053437142\n",
      "Epoch: 34, Iteration: 12800, Loss: 0.8569856676830672\n",
      "Epoch: 34, Iteration: 14400, Loss: 0.5920238054431675\n",
      "Epoch: 34, Iteration: 16000, Loss: 0.7465409867989315\n",
      "Epoch: 34, Iteration: 17600, Loss: 0.8545150647778466\n",
      "Epoch: 34, Iteration: 19200, Loss: 0.6386216104297084\n",
      "Epoch: 34, Iteration: 20800, Loss: 0.7401491465392003\n",
      "Epoch: 34, Iteration: 22400, Loss: 0.8424957387403803\n",
      "Epoch: 34, Iteration: 24000, Loss: 0.5906978735837549\n",
      "Epoch: 34, Iteration: 25600, Loss: 0.8580271347313686\n",
      "Epoch: 34, Iteration: 27200, Loss: 0.7272820796432264\n",
      "Epoch: 34, Iteration: 28800, Loss: 0.534362160697497\n",
      "Epoch: 34, Iteration: 30400, Loss: 0.7566533174985893\n",
      "Epoch: 34, Iteration: 32000, Loss: 0.6639520001595904\n",
      "Epoch: 34, Iteration: 33600, Loss: 0.636436777805395\n",
      "Epoch: 34, Iteration: 35200, Loss: 0.8082495603902018\n",
      "Epoch: 34, Iteration: 36800, Loss: 0.9500552543812548\n",
      "Epoch: 34, Iteration: 38400, Loss: 0.6340412468782368\n",
      "Epoch: 34, Iteration: 40000, Loss: 0.7534742804790938\n",
      "Epoch: 34, Iteration: 41600, Loss: 0.8895817870449318\n",
      "Epoch: 34, Iteration: 43200, Loss: 0.6915141951960901\n",
      "Epoch: 34, Iteration: 44800, Loss: 0.7626180522188601\n",
      "Epoch: 34, Iteration: 46400, Loss: 1.000614755732216\n",
      "Epoch: 34, Iteration: 48000, Loss: 0.7307930410775193\n",
      "Epoch: 34, Iteration: 49600, Loss: 0.778843008187484\n",
      "Epoch: 34, Iteration: 51200, Loss: 0.646305704867052\n",
      "Epoch: 34, Iteration: 52800, Loss: 1.018294255947179\n",
      "Epoch: 34, Iteration: 54400, Loss: 0.8638121868363575\n",
      "Epoch: 34, Iteration: 56000, Loss: 0.7295568447337449\n",
      "Epoch: 34, Iteration: 57600, Loss: 0.7637573573871264\n",
      "Epoch: 34, Iteration: 59200, Loss: 0.5887710980542628\n",
      "Epoch: 34, Iteration: 60800, Loss: 0.88600029266015\n",
      "Epoch: 34, Iteration: 62400, Loss: 0.8921850078471925\n",
      "Epoch: 35, Iteration: 0, Loss: 0.7555455979545269\n",
      "Epoch: 35, Iteration: 1600, Loss: 0.7363292393143558\n",
      "Epoch: 35, Iteration: 3200, Loss: 0.7712459689278098\n",
      "Epoch: 35, Iteration: 4800, Loss: 0.7590103178385904\n",
      "Epoch: 35, Iteration: 6400, Loss: 0.892774571438936\n",
      "Epoch: 35, Iteration: 8000, Loss: 0.8350645876100358\n",
      "Epoch: 35, Iteration: 9600, Loss: 0.5776244655624309\n",
      "Epoch: 35, Iteration: 11200, Loss: 0.7721609028971201\n",
      "Epoch: 35, Iteration: 12800, Loss: 0.8669047660892625\n",
      "Epoch: 35, Iteration: 14400, Loss: 0.5976081561922449\n",
      "Epoch: 35, Iteration: 16000, Loss: 0.7331921988356687\n",
      "Epoch: 35, Iteration: 17600, Loss: 0.8580067656503776\n",
      "Epoch: 35, Iteration: 19200, Loss: 0.6479060387579678\n",
      "Epoch: 35, Iteration: 20800, Loss: 0.7349343561362858\n",
      "Epoch: 35, Iteration: 22400, Loss: 0.8487695722626138\n",
      "Epoch: 35, Iteration: 24000, Loss: 0.5924911716494818\n",
      "Epoch: 35, Iteration: 25600, Loss: 0.8599640312258922\n",
      "Epoch: 35, Iteration: 27200, Loss: 0.7097102613767924\n",
      "Epoch: 35, Iteration: 28800, Loss: 0.5465206691918113\n",
      "Epoch: 35, Iteration: 30400, Loss: 0.7608781974861138\n",
      "Epoch: 35, Iteration: 32000, Loss: 0.6638338610403388\n",
      "Epoch: 35, Iteration: 33600, Loss: 0.6574083229306698\n",
      "Epoch: 35, Iteration: 35200, Loss: 0.8199393395010213\n",
      "Epoch: 35, Iteration: 36800, Loss: 0.9536147760817988\n",
      "Epoch: 35, Iteration: 38400, Loss: 0.6233327770523633\n",
      "Epoch: 35, Iteration: 40000, Loss: 0.7413072050072693\n",
      "Epoch: 35, Iteration: 41600, Loss: 0.884193007140554\n",
      "Epoch: 35, Iteration: 43200, Loss: 0.691575470710662\n",
      "Epoch: 35, Iteration: 44800, Loss: 0.767023032185877\n",
      "Epoch: 35, Iteration: 46400, Loss: 1.0198349223341703\n",
      "Epoch: 35, Iteration: 48000, Loss: 0.7281582736638462\n",
      "Epoch: 35, Iteration: 49600, Loss: 0.7698299164568461\n",
      "Epoch: 35, Iteration: 51200, Loss: 0.6400376319883244\n",
      "Epoch: 35, Iteration: 52800, Loss: 1.009293330156046\n",
      "Epoch: 35, Iteration: 54400, Loss: 0.8618188860299013\n",
      "Epoch: 35, Iteration: 56000, Loss: 0.7254558026996205\n",
      "Epoch: 35, Iteration: 57600, Loss: 0.7619669211658773\n",
      "Epoch: 35, Iteration: 59200, Loss: 0.5824322057130779\n",
      "Epoch: 35, Iteration: 60800, Loss: 0.8966996565499581\n",
      "Epoch: 35, Iteration: 62400, Loss: 0.8909271713517408\n",
      "Epoch: 36, Iteration: 0, Loss: 0.7535131411935037\n",
      "Epoch: 36, Iteration: 1600, Loss: 0.750598341269998\n",
      "Epoch: 36, Iteration: 3200, Loss: 0.7526383940309108\n",
      "Epoch: 36, Iteration: 4800, Loss: 0.7492485518123357\n",
      "Epoch: 36, Iteration: 6400, Loss: 0.8967877764139112\n",
      "Epoch: 36, Iteration: 8000, Loss: 0.8301408377513483\n",
      "Epoch: 36, Iteration: 9600, Loss: 0.5876422350525233\n",
      "Epoch: 36, Iteration: 11200, Loss: 0.7699925480355734\n",
      "Epoch: 36, Iteration: 12800, Loss: 0.8583655345416775\n",
      "Epoch: 36, Iteration: 14400, Loss: 0.5930516951583031\n",
      "Epoch: 36, Iteration: 16000, Loss: 0.721164647313972\n",
      "Epoch: 36, Iteration: 17600, Loss: 0.8421029105586302\n",
      "Epoch: 36, Iteration: 19200, Loss: 0.6561601526634163\n",
      "Epoch: 36, Iteration: 20800, Loss: 0.7277402362716145\n",
      "Epoch: 36, Iteration: 22400, Loss: 0.854029864476114\n",
      "Epoch: 36, Iteration: 24000, Loss: 0.5895012960058301\n",
      "Epoch: 36, Iteration: 25600, Loss: 0.8532219518241557\n",
      "Epoch: 36, Iteration: 27200, Loss: 0.691129247370952\n",
      "Epoch: 36, Iteration: 28800, Loss: 0.5549134132322804\n",
      "Epoch: 36, Iteration: 30400, Loss: 0.7639101610326744\n",
      "Epoch: 36, Iteration: 32000, Loss: 0.6598262330974759\n",
      "Epoch: 36, Iteration: 33600, Loss: 0.6718612016963397\n",
      "Epoch: 36, Iteration: 35200, Loss: 0.8377773125112131\n",
      "Epoch: 36, Iteration: 36800, Loss: 0.9649047909134173\n",
      "Epoch: 36, Iteration: 38400, Loss: 0.6161044327694538\n",
      "Epoch: 36, Iteration: 40000, Loss: 0.7330019265724271\n",
      "Epoch: 36, Iteration: 41600, Loss: 0.8720717954095099\n",
      "Epoch: 36, Iteration: 43200, Loss: 0.6902858050543035\n",
      "Epoch: 36, Iteration: 44800, Loss: 0.7628064522470531\n",
      "Epoch: 36, Iteration: 46400, Loss: 1.03132534590402\n",
      "Epoch: 36, Iteration: 48000, Loss: 0.7139849596772817\n",
      "Epoch: 36, Iteration: 49600, Loss: 0.7596849333261427\n",
      "Epoch: 36, Iteration: 51200, Loss: 0.6329046650938475\n",
      "Epoch: 36, Iteration: 52800, Loss: 1.0020719789378578\n",
      "Epoch: 36, Iteration: 54400, Loss: 0.8631149145716365\n",
      "Epoch: 36, Iteration: 56000, Loss: 0.722845097405725\n",
      "Epoch: 36, Iteration: 57600, Loss: 0.7556232731460153\n",
      "Epoch: 36, Iteration: 59200, Loss: 0.5770026930736506\n",
      "Epoch: 36, Iteration: 60800, Loss: 0.9012772678029036\n",
      "Epoch: 36, Iteration: 62400, Loss: 0.8800434042295164\n",
      "Epoch: 37, Iteration: 0, Loss: 0.7384002697049616\n",
      "Epoch: 37, Iteration: 1600, Loss: 0.7548801674765864\n",
      "Epoch: 37, Iteration: 3200, Loss: 0.7329222530794909\n",
      "Epoch: 37, Iteration: 4800, Loss: 0.7374361120246873\n",
      "Epoch: 37, Iteration: 6400, Loss: 0.8938314855858414\n",
      "Epoch: 37, Iteration: 8000, Loss: 0.8333358003512201\n",
      "Epoch: 37, Iteration: 9600, Loss: 0.6019028965190267\n",
      "Epoch: 37, Iteration: 11200, Loss: 0.7707154013061576\n",
      "Epoch: 37, Iteration: 12800, Loss: 0.8459998070593071\n",
      "Epoch: 37, Iteration: 14400, Loss: 0.5968425896063165\n",
      "Epoch: 37, Iteration: 16000, Loss: 0.7156237085591017\n",
      "Epoch: 37, Iteration: 17600, Loss: 0.8283576687859695\n",
      "Epoch: 37, Iteration: 19200, Loss: 0.6589881077532738\n",
      "Epoch: 37, Iteration: 20800, Loss: 0.7267740027479808\n",
      "Epoch: 37, Iteration: 22400, Loss: 0.860847820938806\n",
      "Epoch: 37, Iteration: 24000, Loss: 0.587364566822052\n",
      "Epoch: 37, Iteration: 25600, Loss: 0.8466282231442108\n",
      "Epoch: 37, Iteration: 27200, Loss: 0.6811200276698504\n",
      "Epoch: 37, Iteration: 28800, Loss: 0.5566085002360337\n",
      "Epoch: 37, Iteration: 30400, Loss: 0.7639845276406616\n",
      "Epoch: 37, Iteration: 32000, Loss: 0.6522979631275737\n",
      "Epoch: 37, Iteration: 33600, Loss: 0.6891379302465575\n",
      "Epoch: 37, Iteration: 35200, Loss: 0.8631312343366379\n",
      "Epoch: 37, Iteration: 36800, Loss: 0.9818210686795097\n",
      "Epoch: 37, Iteration: 38400, Loss: 0.6110547796295632\n",
      "Epoch: 37, Iteration: 40000, Loss: 0.7354130868022387\n",
      "Epoch: 37, Iteration: 41600, Loss: 0.8573080282578267\n",
      "Epoch: 37, Iteration: 43200, Loss: 0.6927013406918636\n",
      "Epoch: 37, Iteration: 44800, Loss: 0.7538059658501821\n",
      "Epoch: 37, Iteration: 46400, Loss: 1.03447417838131\n",
      "Epoch: 37, Iteration: 48000, Loss: 0.6897063266912468\n",
      "Epoch: 37, Iteration: 49600, Loss: 0.7613228817203457\n",
      "Epoch: 37, Iteration: 51200, Loss: 0.6333571560499249\n",
      "Epoch: 37, Iteration: 52800, Loss: 0.9996032294931003\n",
      "Epoch: 37, Iteration: 54400, Loss: 0.8623572596083868\n",
      "Epoch: 37, Iteration: 56000, Loss: 0.7206834514789021\n",
      "Epoch: 37, Iteration: 57600, Loss: 0.7589228809733428\n",
      "Epoch: 37, Iteration: 59200, Loss: 0.564800860590348\n",
      "Epoch: 37, Iteration: 60800, Loss: 0.902683354418225\n",
      "Epoch: 37, Iteration: 62400, Loss: 0.859997982577571\n",
      "Epoch: 38, Iteration: 0, Loss: 0.7169560362357107\n",
      "Epoch: 38, Iteration: 1600, Loss: 0.7542333378880287\n",
      "Epoch: 38, Iteration: 3200, Loss: 0.7187790909436826\n",
      "Epoch: 38, Iteration: 4800, Loss: 0.7223213085383463\n",
      "Epoch: 38, Iteration: 6400, Loss: 0.888828567371307\n",
      "Epoch: 38, Iteration: 8000, Loss: 0.8390554076084803\n",
      "Epoch: 38, Iteration: 9600, Loss: 0.6167698079081037\n",
      "Epoch: 38, Iteration: 11200, Loss: 0.7717376244927772\n",
      "Epoch: 38, Iteration: 12800, Loss: 0.8348596744082696\n",
      "Epoch: 38, Iteration: 14400, Loss: 0.6061972340605541\n",
      "Epoch: 38, Iteration: 16000, Loss: 0.709729796516708\n",
      "Epoch: 38, Iteration: 17600, Loss: 0.8196155964485601\n",
      "Epoch: 38, Iteration: 19200, Loss: 0.655090525426589\n",
      "Epoch: 38, Iteration: 20800, Loss: 0.7303620210032026\n",
      "Epoch: 38, Iteration: 22400, Loss: 0.8672949026564061\n",
      "Epoch: 38, Iteration: 24000, Loss: 0.585829641770318\n",
      "Epoch: 38, Iteration: 25600, Loss: 0.8443396148513562\n",
      "Epoch: 38, Iteration: 27200, Loss: 0.6772280678148055\n",
      "Epoch: 38, Iteration: 28800, Loss: 0.5544083269829355\n",
      "Epoch: 38, Iteration: 30400, Loss: 0.763151315031068\n",
      "Epoch: 38, Iteration: 32000, Loss: 0.6490513188525026\n",
      "Epoch: 38, Iteration: 33600, Loss: 0.698930434004511\n",
      "Epoch: 38, Iteration: 35200, Loss: 0.8854899249197592\n",
      "Epoch: 38, Iteration: 36800, Loss: 0.9930838837154352\n",
      "Epoch: 38, Iteration: 38400, Loss: 0.6018712484670425\n",
      "Epoch: 38, Iteration: 40000, Loss: 0.7381265746350327\n",
      "Epoch: 38, Iteration: 41600, Loss: 0.8393252132077347\n",
      "Epoch: 38, Iteration: 43200, Loss: 0.6973028663147751\n",
      "Epoch: 38, Iteration: 44800, Loss: 0.7425619987978829\n",
      "Epoch: 38, Iteration: 46400, Loss: 1.0198079562523041\n",
      "Epoch: 38, Iteration: 48000, Loss: 0.6688476762254021\n",
      "Epoch: 38, Iteration: 49600, Loss: 0.7715319262242737\n",
      "Epoch: 38, Iteration: 51200, Loss: 0.6388162005373902\n",
      "Epoch: 38, Iteration: 52800, Loss: 0.9977306093155803\n",
      "Epoch: 38, Iteration: 54400, Loss: 0.8538474371234245\n",
      "Epoch: 38, Iteration: 56000, Loss: 0.7149915172452574\n",
      "Epoch: 38, Iteration: 57600, Loss: 0.7636028642060722\n",
      "Epoch: 38, Iteration: 59200, Loss: 0.5499770446612178\n",
      "Epoch: 38, Iteration: 60800, Loss: 0.8974656439605947\n",
      "Epoch: 38, Iteration: 62400, Loss: 0.8425111640100602\n",
      "Epoch: 39, Iteration: 0, Loss: 0.6957692478829088\n",
      "Epoch: 39, Iteration: 1600, Loss: 0.7540212500958927\n",
      "Epoch: 39, Iteration: 3200, Loss: 0.7123234361738806\n",
      "Epoch: 39, Iteration: 4800, Loss: 0.7103267800083011\n",
      "Epoch: 39, Iteration: 6400, Loss: 0.8884256244014423\n",
      "Epoch: 39, Iteration: 8000, Loss: 0.8406582646240153\n",
      "Epoch: 39, Iteration: 9600, Loss: 0.6279558475392882\n",
      "Epoch: 39, Iteration: 11200, Loss: 0.776384663061994\n",
      "Epoch: 39, Iteration: 12800, Loss: 0.8253064202363183\n",
      "Epoch: 39, Iteration: 14400, Loss: 0.609905521399511\n",
      "Epoch: 39, Iteration: 16000, Loss: 0.7016533645418115\n",
      "Epoch: 39, Iteration: 17600, Loss: 0.8162616701410075\n",
      "Epoch: 39, Iteration: 19200, Loss: 0.6504805072797716\n",
      "Epoch: 39, Iteration: 20800, Loss: 0.7323663219063092\n",
      "Epoch: 39, Iteration: 22400, Loss: 0.870950806129905\n",
      "Epoch: 39, Iteration: 24000, Loss: 0.5841012670258104\n",
      "Epoch: 39, Iteration: 25600, Loss: 0.8547803772325453\n",
      "Epoch: 39, Iteration: 27200, Loss: 0.676876358538754\n",
      "Epoch: 39, Iteration: 28800, Loss: 0.5459417894135599\n",
      "Epoch: 39, Iteration: 30400, Loss: 0.7729620935926325\n",
      "Epoch: 39, Iteration: 32000, Loss: 0.6570244655474333\n",
      "Epoch: 39, Iteration: 33600, Loss: 0.7137776721473427\n",
      "Epoch: 39, Iteration: 35200, Loss: 0.9059057619035387\n",
      "Epoch: 39, Iteration: 36800, Loss: 0.9969354479036752\n",
      "Epoch: 39, Iteration: 38400, Loss: 0.5880222763906127\n",
      "Epoch: 39, Iteration: 40000, Loss: 0.7273081110570647\n",
      "Epoch: 39, Iteration: 41600, Loss: 0.8021737574487406\n",
      "Epoch: 39, Iteration: 43200, Loss: 0.7019182256416722\n",
      "Epoch: 39, Iteration: 44800, Loss: 0.7319311048446185\n",
      "Epoch: 39, Iteration: 46400, Loss: 0.9981678333722251\n",
      "Epoch: 39, Iteration: 48000, Loss: 0.6504643232869365\n",
      "Epoch: 39, Iteration: 49600, Loss: 0.7841872851239743\n",
      "Epoch: 39, Iteration: 51200, Loss: 0.6560952028451378\n",
      "Epoch: 39, Iteration: 52800, Loss: 1.0188995028346755\n",
      "Epoch: 39, Iteration: 54400, Loss: 0.8380659421606504\n",
      "Epoch: 39, Iteration: 56000, Loss: 0.7054111116448043\n",
      "Epoch: 39, Iteration: 57600, Loss: 0.7699062757982299\n",
      "Epoch: 39, Iteration: 59200, Loss: 0.5434946473539215\n",
      "Epoch: 39, Iteration: 60800, Loss: 0.8947423293494348\n",
      "Epoch: 39, Iteration: 62400, Loss: 0.8393017835900141\n",
      "Epoch: 40, Iteration: 0, Loss: 0.6753423086184458\n",
      "Epoch: 40, Iteration: 1600, Loss: 0.7514494926602957\n",
      "Epoch: 40, Iteration: 3200, Loss: 0.7137152693469737\n",
      "Epoch: 40, Iteration: 4800, Loss: 0.7031053762969701\n",
      "Epoch: 40, Iteration: 6400, Loss: 0.8667189640984787\n",
      "Epoch: 40, Iteration: 8000, Loss: 0.858817712746935\n",
      "Epoch: 40, Iteration: 9600, Loss: 0.6324531109272\n",
      "Epoch: 40, Iteration: 11200, Loss: 0.7789497980442677\n",
      "Epoch: 40, Iteration: 12800, Loss: 0.8033350973446953\n",
      "Epoch: 40, Iteration: 14400, Loss: 0.6114250720747322\n",
      "Epoch: 40, Iteration: 16000, Loss: 0.696674820565822\n",
      "Epoch: 40, Iteration: 17600, Loss: 0.8187929002704867\n",
      "Epoch: 40, Iteration: 19200, Loss: 0.6542930659867489\n",
      "Epoch: 40, Iteration: 20800, Loss: 0.7424743436458168\n",
      "Epoch: 40, Iteration: 22400, Loss: 0.8542009145388159\n",
      "Epoch: 40, Iteration: 24000, Loss: 0.5888511356137324\n",
      "Epoch: 40, Iteration: 25600, Loss: 0.8652219056910524\n",
      "Epoch: 40, Iteration: 27200, Loss: 0.6878649486291933\n",
      "Epoch: 40, Iteration: 28800, Loss: 0.540689379433313\n",
      "Epoch: 40, Iteration: 30400, Loss: 0.7943105178935165\n",
      "Epoch: 40, Iteration: 32000, Loss: 0.6739075591190844\n",
      "Epoch: 40, Iteration: 33600, Loss: 0.7563702472591998\n",
      "Epoch: 40, Iteration: 35200, Loss: 0.9358965308404696\n",
      "Epoch: 40, Iteration: 36800, Loss: 1.004888836052146\n",
      "Epoch: 40, Iteration: 38400, Loss: 0.580412538840553\n",
      "Epoch: 40, Iteration: 40000, Loss: 0.7054311772395571\n",
      "Epoch: 40, Iteration: 41600, Loss: 0.7509081995528943\n",
      "Epoch: 40, Iteration: 43200, Loss: 0.7138233563957904\n",
      "Epoch: 40, Iteration: 44800, Loss: 0.748576908859651\n",
      "Epoch: 40, Iteration: 46400, Loss: 1.0413043650080631\n",
      "Epoch: 40, Iteration: 48000, Loss: 0.6542681549954351\n",
      "Epoch: 40, Iteration: 49600, Loss: 0.8029224232782356\n",
      "Epoch: 40, Iteration: 51200, Loss: 0.6597071454593636\n",
      "Epoch: 40, Iteration: 52800, Loss: 1.0163976567015245\n",
      "Epoch: 40, Iteration: 54400, Loss: 0.8773714711822789\n",
      "Epoch: 40, Iteration: 56000, Loss: 0.697418451757592\n",
      "Epoch: 40, Iteration: 57600, Loss: 0.7880529677082793\n",
      "Epoch: 40, Iteration: 59200, Loss: 0.5578608608019996\n",
      "Epoch: 40, Iteration: 60800, Loss: 0.9111041653361853\n",
      "Epoch: 40, Iteration: 62400, Loss: 0.848330940997982\n",
      "Epoch: 41, Iteration: 0, Loss: 0.6997158960470671\n",
      "Epoch: 41, Iteration: 1600, Loss: 0.7103512034668502\n",
      "Epoch: 41, Iteration: 3200, Loss: 0.7052173647435023\n",
      "Epoch: 41, Iteration: 4800, Loss: 0.7056091906850416\n",
      "Epoch: 41, Iteration: 6400, Loss: 0.83956210384865\n",
      "Epoch: 41, Iteration: 8000, Loss: 0.8619133184174955\n",
      "Epoch: 41, Iteration: 9600, Loss: 0.6395052341381918\n",
      "Epoch: 41, Iteration: 11200, Loss: 0.7563614182628124\n",
      "Epoch: 41, Iteration: 12800, Loss: 0.7877130653179819\n",
      "Epoch: 41, Iteration: 14400, Loss: 0.6069687902364114\n",
      "Epoch: 41, Iteration: 16000, Loss: 0.6868853274344419\n",
      "Epoch: 41, Iteration: 17600, Loss: 0.8177734805977587\n",
      "Epoch: 41, Iteration: 19200, Loss: 0.6584903763866488\n",
      "Epoch: 41, Iteration: 20800, Loss: 0.7500370886243553\n",
      "Epoch: 41, Iteration: 22400, Loss: 0.835232092850572\n",
      "Epoch: 41, Iteration: 24000, Loss: 0.5728729038239229\n",
      "Epoch: 41, Iteration: 25600, Loss: 0.8533528485935957\n",
      "Epoch: 41, Iteration: 27200, Loss: 0.7015484848810298\n",
      "Epoch: 41, Iteration: 28800, Loss: 0.5464719007434569\n",
      "Epoch: 41, Iteration: 30400, Loss: 0.7986753789379947\n",
      "Epoch: 41, Iteration: 32000, Loss: 0.6810560568887815\n",
      "Epoch: 41, Iteration: 33600, Loss: 0.7539846228285003\n",
      "Epoch: 41, Iteration: 35200, Loss: 0.9319376638659138\n",
      "Epoch: 41, Iteration: 36800, Loss: 0.9997904838131095\n",
      "Epoch: 41, Iteration: 38400, Loss: 0.5702994795254617\n",
      "Epoch: 41, Iteration: 40000, Loss: 0.7118526651317658\n",
      "Epoch: 41, Iteration: 41600, Loss: 0.7568560396263639\n",
      "Epoch: 41, Iteration: 43200, Loss: 0.7178174160371589\n",
      "Epoch: 41, Iteration: 44800, Loss: 0.7454261609681841\n",
      "Epoch: 41, Iteration: 46400, Loss: 1.0482267305703985\n",
      "Epoch: 41, Iteration: 48000, Loss: 0.6568405967643824\n",
      "Epoch: 41, Iteration: 49600, Loss: 0.7901249053201373\n",
      "Epoch: 41, Iteration: 51200, Loss: 0.653872709411989\n",
      "Epoch: 41, Iteration: 52800, Loss: 0.9987136818590614\n",
      "Epoch: 41, Iteration: 54400, Loss: 0.8876889341389038\n",
      "Epoch: 41, Iteration: 56000, Loss: 0.6895068734366085\n",
      "Epoch: 41, Iteration: 57600, Loss: 0.7923741379215659\n",
      "Epoch: 41, Iteration: 59200, Loss: 0.5577882397583691\n",
      "Epoch: 41, Iteration: 60800, Loss: 0.9106143919534084\n",
      "Epoch: 41, Iteration: 62400, Loss: 0.8388754344697658\n",
      "Epoch: 42, Iteration: 0, Loss: 0.7056867047007025\n",
      "Epoch: 42, Iteration: 1600, Loss: 0.6921030052940453\n",
      "Epoch: 42, Iteration: 3200, Loss: 0.6941118021834365\n",
      "Epoch: 42, Iteration: 4800, Loss: 0.6962225247695455\n",
      "Epoch: 42, Iteration: 6400, Loss: 0.8263915482913821\n",
      "Epoch: 42, Iteration: 8000, Loss: 0.8551313528717553\n",
      "Epoch: 42, Iteration: 9600, Loss: 0.6374382633192424\n",
      "Epoch: 42, Iteration: 11200, Loss: 0.7551337044240307\n",
      "Epoch: 42, Iteration: 12800, Loss: 0.7707603120724421\n",
      "Epoch: 42, Iteration: 14400, Loss: 0.5976780539419705\n",
      "Epoch: 42, Iteration: 16000, Loss: 0.6726573895828846\n",
      "Epoch: 42, Iteration: 17600, Loss: 0.8123545984192733\n",
      "Epoch: 42, Iteration: 19200, Loss: 0.6559032299674699\n",
      "Epoch: 42, Iteration: 20800, Loss: 0.7443747896832689\n",
      "Epoch: 42, Iteration: 22400, Loss: 0.8261818650082088\n",
      "Epoch: 42, Iteration: 24000, Loss: 0.5585720505599049\n",
      "Epoch: 42, Iteration: 25600, Loss: 0.8507111263972595\n",
      "Epoch: 42, Iteration: 27200, Loss: 0.6940747432839389\n",
      "Epoch: 42, Iteration: 28800, Loss: 0.5438540390060576\n",
      "Epoch: 42, Iteration: 30400, Loss: 0.7998637649684274\n",
      "Epoch: 42, Iteration: 32000, Loss: 0.6777708757094809\n",
      "Epoch: 42, Iteration: 33600, Loss: 0.7505816899939621\n",
      "Epoch: 42, Iteration: 35200, Loss: 0.9272611620314037\n",
      "Epoch: 42, Iteration: 36800, Loss: 0.9828318081364862\n",
      "Epoch: 42, Iteration: 38400, Loss: 0.5586952313006615\n",
      "Epoch: 42, Iteration: 40000, Loss: 0.7155981013754238\n",
      "Epoch: 42, Iteration: 41600, Loss: 0.7563924091123133\n",
      "Epoch: 42, Iteration: 43200, Loss: 0.7151623699863179\n",
      "Epoch: 42, Iteration: 44800, Loss: 0.7392701961450546\n",
      "Epoch: 42, Iteration: 46400, Loss: 1.0404263204444655\n",
      "Epoch: 42, Iteration: 48000, Loss: 0.6536212515470349\n",
      "Epoch: 42, Iteration: 49600, Loss: 0.7822479308416282\n",
      "Epoch: 42, Iteration: 51200, Loss: 0.6509501271155222\n",
      "Epoch: 42, Iteration: 52800, Loss: 0.9916827252784396\n",
      "Epoch: 42, Iteration: 54400, Loss: 0.8855904681792282\n",
      "Epoch: 42, Iteration: 56000, Loss: 0.6775620938185369\n",
      "Epoch: 42, Iteration: 57600, Loss: 0.7877029481812146\n",
      "Epoch: 42, Iteration: 59200, Loss: 0.5547605699227939\n",
      "Epoch: 42, Iteration: 60800, Loss: 0.9081839219687264\n",
      "Epoch: 42, Iteration: 62400, Loss: 0.8303372381101568\n",
      "Epoch: 43, Iteration: 0, Loss: 0.7075058309711301\n",
      "Epoch: 43, Iteration: 1600, Loss: 0.6834714193664244\n",
      "Epoch: 43, Iteration: 3200, Loss: 0.6853348047046317\n",
      "Epoch: 43, Iteration: 4800, Loss: 0.6908197939493984\n",
      "Epoch: 43, Iteration: 6400, Loss: 0.8119286298161623\n",
      "Epoch: 43, Iteration: 8000, Loss: 0.848742482778273\n",
      "Epoch: 43, Iteration: 9600, Loss: 0.6320672256823194\n",
      "Epoch: 43, Iteration: 11200, Loss: 0.7582555203978699\n",
      "Epoch: 43, Iteration: 12800, Loss: 0.75529999114278\n",
      "Epoch: 43, Iteration: 14400, Loss: 0.5914919097814806\n",
      "Epoch: 43, Iteration: 16000, Loss: 0.6656162168861482\n",
      "Epoch: 43, Iteration: 17600, Loss: 0.8054796144726839\n",
      "Epoch: 43, Iteration: 19200, Loss: 0.6508710052289006\n",
      "Epoch: 43, Iteration: 20800, Loss: 0.7387211923765123\n",
      "Epoch: 43, Iteration: 22400, Loss: 0.8183300027611862\n",
      "Epoch: 43, Iteration: 24000, Loss: 0.5463859626517068\n",
      "Epoch: 43, Iteration: 25600, Loss: 0.8511836770475214\n",
      "Epoch: 43, Iteration: 27200, Loss: 0.6855133762257171\n",
      "Epoch: 43, Iteration: 28800, Loss: 0.5412372797752674\n",
      "Epoch: 43, Iteration: 30400, Loss: 0.7983931731961555\n",
      "Epoch: 43, Iteration: 32000, Loss: 0.6750420848286476\n",
      "Epoch: 43, Iteration: 33600, Loss: 0.7479171704370587\n",
      "Epoch: 43, Iteration: 35200, Loss: 0.9217187756730454\n",
      "Epoch: 43, Iteration: 36800, Loss: 0.965546280724161\n",
      "Epoch: 43, Iteration: 38400, Loss: 0.5498978514123588\n",
      "Epoch: 43, Iteration: 40000, Loss: 0.716010778044222\n",
      "Epoch: 43, Iteration: 41600, Loss: 0.7544170224440059\n",
      "Epoch: 43, Iteration: 43200, Loss: 0.7118840012364616\n",
      "Epoch: 43, Iteration: 44800, Loss: 0.732710494301952\n",
      "Epoch: 43, Iteration: 46400, Loss: 1.0311899739708212\n",
      "Epoch: 43, Iteration: 48000, Loss: 0.6528934284708353\n",
      "Epoch: 43, Iteration: 49600, Loss: 0.7780195831166439\n",
      "Epoch: 43, Iteration: 51200, Loss: 0.6490422465851982\n",
      "Epoch: 43, Iteration: 52800, Loss: 0.9865946026593553\n",
      "Epoch: 43, Iteration: 54400, Loss: 0.8810585278652767\n",
      "Epoch: 43, Iteration: 56000, Loss: 0.6648423790370328\n",
      "Epoch: 43, Iteration: 57600, Loss: 0.7793015897910267\n",
      "Epoch: 43, Iteration: 59200, Loss: 0.5536368286094633\n",
      "Epoch: 43, Iteration: 60800, Loss: 0.9047910546214732\n",
      "Epoch: 43, Iteration: 62400, Loss: 0.8246657439886934\n",
      "Epoch: 44, Iteration: 0, Loss: 0.707831894734873\n",
      "Epoch: 44, Iteration: 1600, Loss: 0.6765262684759241\n",
      "Epoch: 44, Iteration: 3200, Loss: 0.680841319926482\n",
      "Epoch: 44, Iteration: 4800, Loss: 0.6877524017612386\n",
      "Epoch: 44, Iteration: 6400, Loss: 0.7982669187866059\n",
      "Epoch: 44, Iteration: 8000, Loss: 0.8421893555690432\n",
      "Epoch: 44, Iteration: 9600, Loss: 0.6265445418502318\n",
      "Epoch: 44, Iteration: 11200, Loss: 0.7614734584864353\n",
      "Epoch: 44, Iteration: 12800, Loss: 0.7434849685780262\n",
      "Epoch: 44, Iteration: 14400, Loss: 0.5870384112104972\n",
      "Epoch: 44, Iteration: 16000, Loss: 0.6645324448797387\n",
      "Epoch: 44, Iteration: 17600, Loss: 0.7972897632761675\n",
      "Epoch: 44, Iteration: 19200, Loss: 0.64360766414789\n",
      "Epoch: 44, Iteration: 20800, Loss: 0.7339294538727874\n",
      "Epoch: 44, Iteration: 22400, Loss: 0.8127841725986307\n",
      "Epoch: 44, Iteration: 24000, Loss: 0.5350892076582098\n",
      "Epoch: 44, Iteration: 25600, Loss: 0.8528369315836865\n",
      "Epoch: 44, Iteration: 27200, Loss: 0.6788132449269101\n",
      "Epoch: 44, Iteration: 28800, Loss: 0.5402767594460302\n",
      "Epoch: 44, Iteration: 30400, Loss: 0.7938636025054189\n",
      "Epoch: 44, Iteration: 32000, Loss: 0.6743944431247255\n",
      "Epoch: 44, Iteration: 33600, Loss: 0.746333717906893\n",
      "Epoch: 44, Iteration: 35200, Loss: 0.9145284476728759\n",
      "Epoch: 44, Iteration: 36800, Loss: 0.9516495137615789\n",
      "Epoch: 44, Iteration: 38400, Loss: 0.5440072743753782\n",
      "Epoch: 44, Iteration: 40000, Loss: 0.7133894262377978\n",
      "Epoch: 44, Iteration: 41600, Loss: 0.752498390157974\n",
      "Epoch: 44, Iteration: 43200, Loss: 0.710153480146197\n",
      "Epoch: 44, Iteration: 44800, Loss: 0.7248679515324009\n",
      "Epoch: 44, Iteration: 46400, Loss: 1.0238979574030287\n",
      "Epoch: 44, Iteration: 48000, Loss: 0.6553010478536994\n",
      "Epoch: 44, Iteration: 49600, Loss: 0.7762368541416912\n",
      "Epoch: 44, Iteration: 51200, Loss: 0.6475362286738217\n",
      "Epoch: 44, Iteration: 52800, Loss: 0.9829744907890527\n",
      "Epoch: 44, Iteration: 54400, Loss: 0.876088236737409\n",
      "Epoch: 44, Iteration: 56000, Loss: 0.6530975249672544\n",
      "Epoch: 44, Iteration: 57600, Loss: 0.7700268884702854\n",
      "Epoch: 44, Iteration: 59200, Loss: 0.5552072880387571\n",
      "Epoch: 44, Iteration: 60800, Loss: 0.9004472494823944\n",
      "Epoch: 44, Iteration: 62400, Loss: 0.8213315848846522\n",
      "Epoch: 45, Iteration: 0, Loss: 0.7064718808586459\n",
      "Epoch: 45, Iteration: 1600, Loss: 0.6693634323201398\n",
      "Epoch: 45, Iteration: 3200, Loss: 0.680154473304927\n",
      "Epoch: 45, Iteration: 4800, Loss: 0.6861681369183807\n",
      "Epoch: 45, Iteration: 6400, Loss: 0.7861918216025632\n",
      "Epoch: 45, Iteration: 8000, Loss: 0.8356178563303763\n",
      "Epoch: 45, Iteration: 9600, Loss: 0.6221892498943306\n",
      "Epoch: 45, Iteration: 11200, Loss: 0.7640737923104438\n",
      "Epoch: 45, Iteration: 12800, Loss: 0.7340348767810045\n",
      "Epoch: 45, Iteration: 14400, Loss: 0.5841556302979942\n",
      "Epoch: 45, Iteration: 16000, Loss: 0.6680727029034405\n",
      "Epoch: 45, Iteration: 17600, Loss: 0.7870949463778139\n",
      "Epoch: 45, Iteration: 19200, Loss: 0.6341863146070779\n",
      "Epoch: 45, Iteration: 20800, Loss: 0.7304377952204856\n",
      "Epoch: 45, Iteration: 22400, Loss: 0.8100319118178655\n",
      "Epoch: 45, Iteration: 24000, Loss: 0.5244706988786533\n",
      "Epoch: 45, Iteration: 25600, Loss: 0.855116185856776\n",
      "Epoch: 45, Iteration: 27200, Loss: 0.6751470145906644\n",
      "Epoch: 45, Iteration: 28800, Loss: 0.5427369274363149\n",
      "Epoch: 45, Iteration: 30400, Loss: 0.7862618239682758\n",
      "Epoch: 45, Iteration: 32000, Loss: 0.6748911118910282\n",
      "Epoch: 45, Iteration: 33600, Loss: 0.7446934312583668\n",
      "Epoch: 45, Iteration: 35200, Loss: 0.9061903036092115\n",
      "Epoch: 45, Iteration: 36800, Loss: 0.942304721950947\n",
      "Epoch: 45, Iteration: 38400, Loss: 0.5406587194890564\n",
      "Epoch: 45, Iteration: 40000, Loss: 0.708976818706577\n",
      "Epoch: 45, Iteration: 41600, Loss: 0.7507298352502778\n",
      "Epoch: 45, Iteration: 43200, Loss: 0.7110271022188384\n",
      "Epoch: 45, Iteration: 44800, Loss: 0.7141771739700911\n",
      "Epoch: 45, Iteration: 46400, Loss: 1.0201443725727237\n",
      "Epoch: 45, Iteration: 48000, Loss: 0.6606231430848013\n",
      "Epoch: 45, Iteration: 49600, Loss: 0.7766342160848922\n",
      "Epoch: 45, Iteration: 51200, Loss: 0.6456358435668512\n",
      "Epoch: 45, Iteration: 52800, Loss: 0.9805823644487118\n",
      "Epoch: 45, Iteration: 54400, Loss: 0.8722614744726387\n",
      "Epoch: 45, Iteration: 56000, Loss: 0.6422989016489125\n",
      "Epoch: 45, Iteration: 57600, Loss: 0.7608488060991111\n",
      "Epoch: 45, Iteration: 59200, Loss: 0.5598613153911672\n",
      "Epoch: 45, Iteration: 60800, Loss: 0.8957786570267582\n",
      "Epoch: 45, Iteration: 62400, Loss: 0.820270184385635\n",
      "Epoch: 46, Iteration: 0, Loss: 0.7040533400185764\n",
      "Epoch: 46, Iteration: 1600, Loss: 0.6616980300485449\n",
      "Epoch: 46, Iteration: 3200, Loss: 0.6821052441841342\n",
      "Epoch: 46, Iteration: 4800, Loss: 0.6863646944697804\n",
      "Epoch: 46, Iteration: 6400, Loss: 0.7761837107509997\n",
      "Epoch: 46, Iteration: 8000, Loss: 0.8289810794942114\n",
      "Epoch: 46, Iteration: 9600, Loss: 0.6190495320990663\n",
      "Epoch: 46, Iteration: 11200, Loss: 0.7656867326928449\n",
      "Epoch: 46, Iteration: 12800, Loss: 0.7240060403278823\n",
      "Epoch: 46, Iteration: 14400, Loss: 0.5840125212750062\n",
      "Epoch: 46, Iteration: 16000, Loss: 0.6762541434747797\n",
      "Epoch: 46, Iteration: 17600, Loss: 0.7742196979340163\n",
      "Epoch: 46, Iteration: 19200, Loss: 0.6226288193472032\n",
      "Epoch: 46, Iteration: 20800, Loss: 0.7301703012493631\n",
      "Epoch: 46, Iteration: 22400, Loss: 0.8102883174395229\n",
      "Epoch: 46, Iteration: 24000, Loss: 0.513687283679431\n",
      "Epoch: 46, Iteration: 25600, Loss: 0.8592528247297551\n",
      "Epoch: 46, Iteration: 27200, Loss: 0.6749905612627007\n",
      "Epoch: 46, Iteration: 28800, Loss: 0.5517126707999602\n",
      "Epoch: 46, Iteration: 30400, Loss: 0.775734924674182\n",
      "Epoch: 46, Iteration: 32000, Loss: 0.6770926443456625\n",
      "Epoch: 46, Iteration: 33600, Loss: 0.7400544493321652\n",
      "Epoch: 46, Iteration: 35200, Loss: 0.8995535609255625\n",
      "Epoch: 46, Iteration: 36800, Loss: 0.9381025256363467\n",
      "Epoch: 46, Iteration: 38400, Loss: 0.5395937112437689\n",
      "Epoch: 46, Iteration: 40000, Loss: 0.7061256805815703\n",
      "Epoch: 46, Iteration: 41600, Loss: 0.7493351648491092\n",
      "Epoch: 46, Iteration: 43200, Loss: 0.7152750105336307\n",
      "Epoch: 46, Iteration: 44800, Loss: 0.6981819618166849\n",
      "Epoch: 46, Iteration: 46400, Loss: 1.02066810590216\n",
      "Epoch: 46, Iteration: 48000, Loss: 0.6691325139198643\n",
      "Epoch: 46, Iteration: 49600, Loss: 0.7798381495323732\n",
      "Epoch: 46, Iteration: 51200, Loss: 0.6422550414808876\n",
      "Epoch: 46, Iteration: 52800, Loss: 0.9783710381890949\n",
      "Epoch: 46, Iteration: 54400, Loss: 0.8740512433389263\n",
      "Epoch: 46, Iteration: 56000, Loss: 0.6308664147650334\n",
      "Epoch: 46, Iteration: 57600, Loss: 0.7534806174139506\n",
      "Epoch: 46, Iteration: 59200, Loss: 0.5681761887072548\n",
      "Epoch: 46, Iteration: 60800, Loss: 0.8911735337166196\n",
      "Epoch: 46, Iteration: 62400, Loss: 0.8244357332291707\n",
      "Epoch: 47, Iteration: 0, Loss: 0.7020325198691579\n",
      "Epoch: 47, Iteration: 1600, Loss: 0.6500046711364422\n",
      "Epoch: 47, Iteration: 3200, Loss: 0.6855561434722865\n",
      "Epoch: 47, Iteration: 4800, Loss: 0.688829631866787\n",
      "Epoch: 47, Iteration: 6400, Loss: 0.7705479595305997\n",
      "Epoch: 47, Iteration: 8000, Loss: 0.8209532727166988\n",
      "Epoch: 47, Iteration: 9600, Loss: 0.6156850456030489\n",
      "Epoch: 47, Iteration: 11200, Loss: 0.7703809088088616\n",
      "Epoch: 47, Iteration: 12800, Loss: 0.710665901051652\n",
      "Epoch: 47, Iteration: 14400, Loss: 0.586912161743448\n",
      "Epoch: 47, Iteration: 16000, Loss: 0.6903437061547575\n",
      "Epoch: 47, Iteration: 17600, Loss: 0.7603366557064397\n",
      "Epoch: 47, Iteration: 19200, Loss: 0.6094324820233228\n",
      "Epoch: 47, Iteration: 20800, Loss: 0.734249426775569\n",
      "Epoch: 47, Iteration: 22400, Loss: 0.8137902855197331\n",
      "Epoch: 47, Iteration: 24000, Loss: 0.5046046525389543\n",
      "Epoch: 47, Iteration: 25600, Loss: 0.8611212544171216\n",
      "Epoch: 47, Iteration: 27200, Loss: 0.6777669850771757\n",
      "Epoch: 47, Iteration: 28800, Loss: 0.570535179978954\n",
      "Epoch: 47, Iteration: 30400, Loss: 0.766450298116194\n",
      "Epoch: 47, Iteration: 32000, Loss: 0.6825063035231642\n",
      "Epoch: 47, Iteration: 33600, Loss: 0.7224899229943319\n",
      "Epoch: 47, Iteration: 35200, Loss: 0.8990383621218854\n",
      "Epoch: 47, Iteration: 36800, Loss: 0.9411981748558824\n",
      "Epoch: 47, Iteration: 38400, Loss: 0.5394035371874634\n",
      "Epoch: 47, Iteration: 40000, Loss: 0.7119129763782448\n",
      "Epoch: 47, Iteration: 41600, Loss: 0.7516530712956664\n",
      "Epoch: 47, Iteration: 43200, Loss: 0.7214110348086293\n",
      "Epoch: 47, Iteration: 44800, Loss: 0.6812643064266843\n",
      "Epoch: 47, Iteration: 46400, Loss: 1.022382285375572\n",
      "Epoch: 47, Iteration: 48000, Loss: 0.6783802879800727\n",
      "Epoch: 47, Iteration: 49600, Loss: 0.7878216363869277\n",
      "Epoch: 47, Iteration: 51200, Loss: 0.6372978285393888\n",
      "Epoch: 47, Iteration: 52800, Loss: 0.9743763916118122\n",
      "Epoch: 47, Iteration: 54400, Loss: 0.8875863409665794\n",
      "Epoch: 47, Iteration: 56000, Loss: 0.6184313849552996\n",
      "Epoch: 47, Iteration: 57600, Loss: 0.752317682138351\n",
      "Epoch: 47, Iteration: 59200, Loss: 0.5758251499649776\n",
      "Epoch: 47, Iteration: 60800, Loss: 0.8853791605814211\n",
      "Epoch: 47, Iteration: 62400, Loss: 0.8337268543659918\n",
      "Epoch: 48, Iteration: 0, Loss: 0.698456698070899\n",
      "Epoch: 48, Iteration: 1600, Loss: 0.6341689290581691\n",
      "Epoch: 48, Iteration: 3200, Loss: 0.6876378976544919\n",
      "Epoch: 48, Iteration: 4800, Loss: 0.688314262282095\n",
      "Epoch: 48, Iteration: 6400, Loss: 0.7720020630048076\n",
      "Epoch: 48, Iteration: 8000, Loss: 0.8101303709614169\n",
      "Epoch: 48, Iteration: 9600, Loss: 0.611020015174876\n",
      "Epoch: 48, Iteration: 11200, Loss: 0.7830437431251979\n",
      "Epoch: 48, Iteration: 12800, Loss: 0.6998354607932176\n",
      "Epoch: 48, Iteration: 14400, Loss: 0.58610597238045\n",
      "Epoch: 48, Iteration: 16000, Loss: 0.7047292825778512\n",
      "Epoch: 48, Iteration: 17600, Loss: 0.7526455540582828\n",
      "Epoch: 48, Iteration: 19200, Loss: 0.6023642624751191\n",
      "Epoch: 48, Iteration: 20800, Loss: 0.7348424807594336\n",
      "Epoch: 48, Iteration: 22400, Loss: 0.8177933402540023\n",
      "Epoch: 48, Iteration: 24000, Loss: 0.5038676509641312\n",
      "Epoch: 48, Iteration: 25600, Loss: 0.8501934281146515\n",
      "Epoch: 48, Iteration: 27200, Loss: 0.6791595727922058\n",
      "Epoch: 48, Iteration: 28800, Loss: 0.5822435787929054\n",
      "Epoch: 48, Iteration: 30400, Loss: 0.7622565292198709\n",
      "Epoch: 48, Iteration: 32000, Loss: 0.6803249841167747\n",
      "Epoch: 48, Iteration: 33600, Loss: 0.7015002752333933\n",
      "Epoch: 48, Iteration: 35200, Loss: 0.9020647558392931\n",
      "Epoch: 48, Iteration: 36800, Loss: 0.9454986791506633\n",
      "Epoch: 48, Iteration: 38400, Loss: 0.53847979914513\n",
      "Epoch: 48, Iteration: 40000, Loss: 0.7184245252681603\n",
      "Epoch: 48, Iteration: 41600, Loss: 0.7521440980991507\n",
      "Epoch: 48, Iteration: 43200, Loss: 0.7214602818092059\n",
      "Epoch: 48, Iteration: 44800, Loss: 0.6729912175561128\n",
      "Epoch: 48, Iteration: 46400, Loss: 1.0139748081996638\n",
      "Epoch: 48, Iteration: 48000, Loss: 0.6843581497506785\n",
      "Epoch: 48, Iteration: 49600, Loss: 0.7931200910422262\n",
      "Epoch: 48, Iteration: 51200, Loss: 0.6324540918914268\n",
      "Epoch: 48, Iteration: 52800, Loss: 0.9637051805468682\n",
      "Epoch: 48, Iteration: 54400, Loss: 0.8947616841660815\n",
      "Epoch: 48, Iteration: 56000, Loss: 0.6079440440306118\n",
      "Epoch: 48, Iteration: 57600, Loss: 0.7494926404913351\n",
      "Epoch: 48, Iteration: 59200, Loss: 0.5813065150980669\n",
      "Epoch: 48, Iteration: 60800, Loss: 0.8802493032461531\n",
      "Epoch: 48, Iteration: 62400, Loss: 0.8366446812582657\n",
      "Epoch: 49, Iteration: 0, Loss: 0.692250094072163\n",
      "Epoch: 49, Iteration: 1600, Loss: 0.6303737721441609\n",
      "Epoch: 49, Iteration: 3200, Loss: 0.6868875281658102\n",
      "Epoch: 49, Iteration: 4800, Loss: 0.6846838684345969\n",
      "Epoch: 49, Iteration: 6400, Loss: 0.7698245428723796\n",
      "Epoch: 49, Iteration: 8000, Loss: 0.7989809014205327\n",
      "Epoch: 49, Iteration: 9600, Loss: 0.6057051324119487\n",
      "Epoch: 49, Iteration: 11200, Loss: 0.7896559607544382\n",
      "Epoch: 49, Iteration: 12800, Loss: 0.6917987228794719\n",
      "Epoch: 49, Iteration: 14400, Loss: 0.5806308915850523\n",
      "Epoch: 49, Iteration: 16000, Loss: 0.7149612798928264\n",
      "Epoch: 49, Iteration: 17600, Loss: 0.7432682986499414\n",
      "Epoch: 49, Iteration: 19200, Loss: 0.5988016662919626\n",
      "Epoch: 49, Iteration: 20800, Loss: 0.7286167567245894\n",
      "Epoch: 49, Iteration: 22400, Loss: 0.819141414505588\n",
      "Epoch: 49, Iteration: 24000, Loss: 0.505017288687874\n",
      "Epoch: 49, Iteration: 25600, Loss: 0.8404183856434011\n",
      "Epoch: 49, Iteration: 27200, Loss: 0.6772075044824635\n",
      "Epoch: 49, Iteration: 28800, Loss: 0.585240804246876\n",
      "Epoch: 49, Iteration: 30400, Loss: 0.7540762200627699\n",
      "Epoch: 49, Iteration: 32000, Loss: 0.6756111844855799\n",
      "Epoch: 49, Iteration: 33600, Loss: 0.6936435366685365\n",
      "Epoch: 49, Iteration: 35200, Loss: 0.9041969014570079\n",
      "Epoch: 49, Iteration: 36800, Loss: 0.945644856543932\n",
      "Epoch: 49, Iteration: 38400, Loss: 0.5373859204441855\n",
      "Epoch: 49, Iteration: 40000, Loss: 0.717759383229591\n",
      "Epoch: 49, Iteration: 41600, Loss: 0.7447076464798789\n",
      "Epoch: 49, Iteration: 43200, Loss: 0.7169042020470822\n",
      "Epoch: 49, Iteration: 44800, Loss: 0.6657662784996411\n",
      "Epoch: 49, Iteration: 46400, Loss: 0.9989610278793186\n",
      "Epoch: 49, Iteration: 48000, Loss: 0.6931612671214848\n",
      "Epoch: 49, Iteration: 49600, Loss: 0.7952053509874044\n",
      "Epoch: 49, Iteration: 51200, Loss: 0.6246577898107097\n",
      "Epoch: 49, Iteration: 52800, Loss: 0.9444138324165812\n",
      "Epoch: 49, Iteration: 54400, Loss: 0.8922151628460289\n",
      "Epoch: 49, Iteration: 56000, Loss: 0.5987285478089909\n",
      "Epoch: 49, Iteration: 57600, Loss: 0.7468509730055148\n",
      "Epoch: 49, Iteration: 59200, Loss: 0.5853431290792404\n",
      "Epoch: 49, Iteration: 60800, Loss: 0.8765305178606307\n",
      "Epoch: 49, Iteration: 62400, Loss: 0.8395540031223359\n",
      "Epoch: 50, Iteration: 0, Loss: 0.6853752404634452\n",
      "Epoch: 50, Iteration: 1600, Loss: 0.6310508568257949\n",
      "Epoch: 50, Iteration: 3200, Loss: 0.6829927757914981\n",
      "Epoch: 50, Iteration: 4800, Loss: 0.6813959958353641\n",
      "Epoch: 50, Iteration: 6400, Loss: 0.7646711859107591\n",
      "Epoch: 50, Iteration: 8000, Loss: 0.7864287706748022\n",
      "Epoch: 50, Iteration: 9600, Loss: 0.6002551902574369\n",
      "Epoch: 50, Iteration: 11200, Loss: 0.7936852472989959\n",
      "Epoch: 50, Iteration: 12800, Loss: 0.6836575124309323\n",
      "Epoch: 50, Iteration: 14400, Loss: 0.5749166662649804\n",
      "Epoch: 50, Iteration: 16000, Loss: 0.7185381668447438\n",
      "Epoch: 50, Iteration: 17600, Loss: 0.7314210087758739\n",
      "Epoch: 50, Iteration: 19200, Loss: 0.5960087441089419\n",
      "Epoch: 50, Iteration: 20800, Loss: 0.7219704576631948\n",
      "Epoch: 50, Iteration: 22400, Loss: 0.8193490020061822\n",
      "Epoch: 50, Iteration: 24000, Loss: 0.5087790199622263\n",
      "Epoch: 50, Iteration: 25600, Loss: 0.8339227173916022\n",
      "Epoch: 50, Iteration: 27200, Loss: 0.6756146231477772\n",
      "Epoch: 50, Iteration: 28800, Loss: 0.5838574699153386\n",
      "Epoch: 50, Iteration: 30400, Loss: 0.7413579219301178\n",
      "Epoch: 50, Iteration: 32000, Loss: 0.6724338277377624\n",
      "Epoch: 50, Iteration: 33600, Loss: 0.6919843224660849\n",
      "Epoch: 50, Iteration: 35200, Loss: 0.9037548957003797\n",
      "Epoch: 50, Iteration: 36800, Loss: 0.9465108090853704\n",
      "Epoch: 50, Iteration: 38400, Loss: 0.5347431056925106\n",
      "Epoch: 50, Iteration: 40000, Loss: 0.7136029952222647\n",
      "Epoch: 50, Iteration: 41600, Loss: 0.73389020754596\n",
      "Epoch: 50, Iteration: 43200, Loss: 0.712569404159613\n",
      "Epoch: 50, Iteration: 44800, Loss: 0.6603187742243881\n",
      "Epoch: 50, Iteration: 46400, Loss: 0.9817960737542896\n",
      "Epoch: 50, Iteration: 48000, Loss: 0.7077284478996225\n",
      "Epoch: 50, Iteration: 49600, Loss: 0.798735103583195\n",
      "Epoch: 50, Iteration: 51200, Loss: 0.6157704329907745\n",
      "Epoch: 50, Iteration: 52800, Loss: 0.9223187950605569\n",
      "Epoch: 50, Iteration: 54400, Loss: 0.8831147727308317\n",
      "Epoch: 50, Iteration: 56000, Loss: 0.5952964524210945\n",
      "Epoch: 50, Iteration: 57600, Loss: 0.750789991494903\n",
      "Epoch: 50, Iteration: 59200, Loss: 0.5896505565901781\n",
      "Epoch: 50, Iteration: 60800, Loss: 0.8791028186803285\n",
      "Epoch: 50, Iteration: 62400, Loss: 0.8464812590120923\n",
      "Epoch: 51, Iteration: 0, Loss: 0.6776257230134755\n",
      "Epoch: 51, Iteration: 1600, Loss: 0.6338075351540684\n",
      "Epoch: 51, Iteration: 3200, Loss: 0.676512594367976\n",
      "Epoch: 51, Iteration: 4800, Loss: 0.680884518297767\n",
      "Epoch: 51, Iteration: 6400, Loss: 0.763214422418536\n",
      "Epoch: 51, Iteration: 8000, Loss: 0.7717422238623657\n",
      "Epoch: 51, Iteration: 9600, Loss: 0.5954812027101226\n",
      "Epoch: 51, Iteration: 11200, Loss: 0.7992208993007754\n",
      "Epoch: 51, Iteration: 12800, Loss: 0.6752860100863486\n",
      "Epoch: 51, Iteration: 14400, Loss: 0.5723420022485167\n",
      "Epoch: 51, Iteration: 16000, Loss: 0.7149040079544401\n",
      "Epoch: 51, Iteration: 17600, Loss: 0.7188023963653304\n",
      "Epoch: 51, Iteration: 19200, Loss: 0.6017904799253919\n",
      "Epoch: 51, Iteration: 20800, Loss: 0.7228374630247167\n",
      "Epoch: 51, Iteration: 22400, Loss: 0.8264016471333582\n",
      "Epoch: 51, Iteration: 24000, Loss: 0.5218432973435938\n",
      "Epoch: 51, Iteration: 25600, Loss: 0.8472698401070782\n",
      "Epoch: 51, Iteration: 27200, Loss: 0.6891956108400976\n",
      "Epoch: 51, Iteration: 28800, Loss: 0.5693164027783637\n",
      "Epoch: 51, Iteration: 30400, Loss: 0.7231281213950065\n",
      "Epoch: 51, Iteration: 32000, Loss: 0.6807629589431821\n",
      "Epoch: 51, Iteration: 33600, Loss: 0.7072945011974053\n",
      "Epoch: 51, Iteration: 35200, Loss: 0.8952793572544308\n",
      "Epoch: 51, Iteration: 36800, Loss: 0.9545086851711367\n",
      "Epoch: 51, Iteration: 38400, Loss: 0.5273792298050295\n",
      "Epoch: 51, Iteration: 40000, Loss: 0.7092080574389006\n",
      "Epoch: 51, Iteration: 41600, Loss: 0.7309345744755924\n",
      "Epoch: 51, Iteration: 43200, Loss: 0.7233628170167762\n",
      "Epoch: 51, Iteration: 44800, Loss: 0.6626462215500108\n",
      "Epoch: 51, Iteration: 46400, Loss: 0.9632382892642515\n",
      "Epoch: 51, Iteration: 48000, Loss: 0.7369700526380938\n",
      "Epoch: 51, Iteration: 49600, Loss: 0.8089472309422101\n",
      "Epoch: 51, Iteration: 51200, Loss: 0.611493021871884\n",
      "Epoch: 51, Iteration: 52800, Loss: 0.9088035117084519\n",
      "Epoch: 51, Iteration: 54400, Loss: 0.8741018706705819\n",
      "Epoch: 51, Iteration: 56000, Loss: 0.608250591404615\n",
      "Epoch: 51, Iteration: 57600, Loss: 0.7762535656337617\n",
      "Epoch: 51, Iteration: 59200, Loss: 0.6031932204505872\n",
      "Epoch: 51, Iteration: 60800, Loss: 0.898780357308738\n",
      "Epoch: 51, Iteration: 62400, Loss: 0.8512417248196369\n",
      "Epoch: 52, Iteration: 0, Loss: 0.6728587461171753\n",
      "Epoch: 52, Iteration: 1600, Loss: 0.6510523962386419\n",
      "Epoch: 52, Iteration: 3200, Loss: 0.6730882583764362\n",
      "Epoch: 52, Iteration: 4800, Loss: 0.6912415386571543\n",
      "Epoch: 52, Iteration: 6400, Loss: 0.774559815741753\n",
      "Epoch: 52, Iteration: 8000, Loss: 0.7718438623690873\n",
      "Epoch: 52, Iteration: 9600, Loss: 0.5896863281385396\n",
      "Epoch: 52, Iteration: 11200, Loss: 0.8155209771143572\n",
      "Epoch: 52, Iteration: 12800, Loss: 0.6663503961711832\n",
      "Epoch: 52, Iteration: 14400, Loss: 0.5886071565117725\n",
      "Epoch: 52, Iteration: 16000, Loss: 0.7168983178014617\n",
      "Epoch: 52, Iteration: 17600, Loss: 0.7180933562940448\n",
      "Epoch: 52, Iteration: 19200, Loss: 0.6318453102334969\n",
      "Epoch: 52, Iteration: 20800, Loss: 0.7499295293330752\n",
      "Epoch: 52, Iteration: 22400, Loss: 0.8401454498694789\n",
      "Epoch: 52, Iteration: 24000, Loss: 0.5365487814547025\n",
      "Epoch: 52, Iteration: 25600, Loss: 0.8796583739350075\n",
      "Epoch: 52, Iteration: 27200, Loss: 0.7144866529464733\n",
      "Epoch: 52, Iteration: 28800, Loss: 0.5564240858265018\n",
      "Epoch: 52, Iteration: 30400, Loss: 0.7229029034321677\n",
      "Epoch: 52, Iteration: 32000, Loss: 0.683035598734132\n",
      "Epoch: 52, Iteration: 33600, Loss: 0.7300873048655656\n",
      "Epoch: 52, Iteration: 35200, Loss: 0.8826811281301101\n",
      "Epoch: 52, Iteration: 36800, Loss: 0.9674477450001735\n",
      "Epoch: 52, Iteration: 38400, Loss: 0.5235778095205796\n",
      "Epoch: 52, Iteration: 40000, Loss: 0.7179013563538097\n",
      "Epoch: 52, Iteration: 41600, Loss: 0.746918045712468\n",
      "Epoch: 52, Iteration: 43200, Loss: 0.7267190065702287\n",
      "Epoch: 52, Iteration: 44800, Loss: 0.6609344056985547\n",
      "Epoch: 52, Iteration: 46400, Loss: 0.9595893147215591\n",
      "Epoch: 52, Iteration: 48000, Loss: 0.7598867515211141\n",
      "Epoch: 52, Iteration: 49600, Loss: 0.8080555801755169\n",
      "Epoch: 52, Iteration: 51200, Loss: 0.6008623478713262\n",
      "Epoch: 52, Iteration: 52800, Loss: 0.9126148142300639\n",
      "Epoch: 52, Iteration: 54400, Loss: 0.8741488983184789\n",
      "Epoch: 52, Iteration: 56000, Loss: 0.5995080141695752\n",
      "Epoch: 52, Iteration: 57600, Loss: 0.7750657663067368\n",
      "Epoch: 52, Iteration: 59200, Loss: 0.603732458555637\n",
      "Epoch: 52, Iteration: 60800, Loss: 0.9083407146419125\n",
      "Epoch: 52, Iteration: 62400, Loss: 0.8483404549580713\n",
      "Epoch: 53, Iteration: 0, Loss: 0.6703833567209633\n",
      "Epoch: 53, Iteration: 1600, Loss: 0.6517515106484311\n",
      "Epoch: 53, Iteration: 3200, Loss: 0.6624156501050038\n",
      "Epoch: 53, Iteration: 4800, Loss: 0.6937781803703755\n",
      "Epoch: 53, Iteration: 6400, Loss: 0.7771686384876029\n",
      "Epoch: 53, Iteration: 8000, Loss: 0.771564502531382\n",
      "Epoch: 53, Iteration: 9600, Loss: 0.5872873168080928\n",
      "Epoch: 53, Iteration: 11200, Loss: 0.8156687202424111\n",
      "Epoch: 53, Iteration: 12800, Loss: 0.6546209952980151\n",
      "Epoch: 53, Iteration: 14400, Loss: 0.580310712549418\n",
      "Epoch: 53, Iteration: 16000, Loss: 0.7188525890238016\n",
      "Epoch: 53, Iteration: 17600, Loss: 0.7156699172867239\n",
      "Epoch: 53, Iteration: 19200, Loss: 0.6255669309661805\n",
      "Epoch: 53, Iteration: 20800, Loss: 0.7543445386822081\n",
      "Epoch: 53, Iteration: 22400, Loss: 0.8294006285354811\n",
      "Epoch: 53, Iteration: 24000, Loss: 0.5345687832259427\n",
      "Epoch: 53, Iteration: 25600, Loss: 0.8817943301945029\n",
      "Epoch: 53, Iteration: 27200, Loss: 0.7151574011510038\n",
      "Epoch: 53, Iteration: 28800, Loss: 0.5487236454084026\n",
      "Epoch: 53, Iteration: 30400, Loss: 0.7116441469697621\n",
      "Epoch: 53, Iteration: 32000, Loss: 0.6783141930066899\n",
      "Epoch: 53, Iteration: 33600, Loss: 0.7268233176549668\n",
      "Epoch: 53, Iteration: 35200, Loss: 0.8709788278634392\n",
      "Epoch: 53, Iteration: 36800, Loss: 0.9609585729543448\n",
      "Epoch: 53, Iteration: 38400, Loss: 0.5232339053373654\n",
      "Epoch: 53, Iteration: 40000, Loss: 0.7187769559337488\n",
      "Epoch: 53, Iteration: 41600, Loss: 0.7468763378737686\n",
      "Epoch: 53, Iteration: 43200, Loss: 0.7168745222771437\n",
      "Epoch: 53, Iteration: 44800, Loss: 0.663437796782985\n",
      "Epoch: 53, Iteration: 46400, Loss: 0.9567311892068133\n",
      "Epoch: 53, Iteration: 48000, Loss: 0.7647008948580529\n",
      "Epoch: 53, Iteration: 49600, Loss: 0.7993287903218153\n",
      "Epoch: 53, Iteration: 51200, Loss: 0.5855646111174351\n",
      "Epoch: 53, Iteration: 52800, Loss: 0.9135435068243354\n",
      "Epoch: 53, Iteration: 54400, Loss: 0.8696661177074658\n",
      "Epoch: 53, Iteration: 56000, Loss: 0.5858400772230874\n",
      "Epoch: 53, Iteration: 57600, Loss: 0.7619318046547832\n",
      "Epoch: 53, Iteration: 59200, Loss: 0.600920419711576\n",
      "Epoch: 53, Iteration: 60800, Loss: 0.9111731404012413\n",
      "Epoch: 53, Iteration: 62400, Loss: 0.8423061836685641\n",
      "Epoch: 54, Iteration: 0, Loss: 0.6592533549553936\n",
      "Epoch: 54, Iteration: 1600, Loss: 0.6472027652505378\n",
      "Epoch: 54, Iteration: 3200, Loss: 0.6501733340389377\n",
      "Epoch: 54, Iteration: 4800, Loss: 0.6917820958267646\n",
      "Epoch: 54, Iteration: 6400, Loss: 0.7681694450917301\n",
      "Epoch: 54, Iteration: 8000, Loss: 0.7648744884717289\n",
      "Epoch: 54, Iteration: 9600, Loss: 0.5835181181417176\n",
      "Epoch: 54, Iteration: 11200, Loss: 0.8096344060761421\n",
      "Epoch: 54, Iteration: 12800, Loss: 0.6413736151976197\n",
      "Epoch: 54, Iteration: 14400, Loss: 0.5686431932786828\n",
      "Epoch: 54, Iteration: 16000, Loss: 0.7178533159308352\n",
      "Epoch: 54, Iteration: 17600, Loss: 0.7086087673501194\n",
      "Epoch: 54, Iteration: 19200, Loss: 0.6155183276531337\n",
      "Epoch: 54, Iteration: 20800, Loss: 0.7582986591931835\n",
      "Epoch: 54, Iteration: 22400, Loss: 0.8189865951956878\n",
      "Epoch: 54, Iteration: 24000, Loss: 0.532125524223908\n",
      "Epoch: 54, Iteration: 25600, Loss: 0.8794246131246751\n",
      "Epoch: 54, Iteration: 27200, Loss: 0.7115434723284109\n",
      "Epoch: 54, Iteration: 28800, Loss: 0.5426107782492327\n",
      "Epoch: 54, Iteration: 30400, Loss: 0.6996881563795891\n",
      "Epoch: 54, Iteration: 32000, Loss: 0.6777984098915175\n",
      "Epoch: 54, Iteration: 33600, Loss: 0.7221721419847997\n",
      "Epoch: 54, Iteration: 35200, Loss: 0.8591654246835742\n",
      "Epoch: 54, Iteration: 36800, Loss: 0.9523644162496216\n",
      "Epoch: 54, Iteration: 38400, Loss: 0.524083189879715\n",
      "Epoch: 54, Iteration: 40000, Loss: 0.7200882550853648\n",
      "Epoch: 54, Iteration: 41600, Loss: 0.7474531892845936\n",
      "Epoch: 54, Iteration: 43200, Loss: 0.707715106308948\n",
      "Epoch: 54, Iteration: 44800, Loss: 0.6661240625648293\n",
      "Epoch: 54, Iteration: 46400, Loss: 0.9506067686117836\n",
      "Epoch: 54, Iteration: 48000, Loss: 0.7667074246523933\n",
      "Epoch: 54, Iteration: 49600, Loss: 0.7920723038208677\n",
      "Epoch: 54, Iteration: 51200, Loss: 0.5706859303685807\n",
      "Epoch: 54, Iteration: 52800, Loss: 0.9152074633033629\n",
      "Epoch: 54, Iteration: 54400, Loss: 0.8631923608494787\n",
      "Epoch: 54, Iteration: 56000, Loss: 0.5721867709083981\n",
      "Epoch: 54, Iteration: 57600, Loss: 0.7482330472943546\n",
      "Epoch: 54, Iteration: 59200, Loss: 0.5990879814692431\n",
      "Epoch: 54, Iteration: 60800, Loss: 0.9124365824128996\n",
      "Epoch: 54, Iteration: 62400, Loss: 0.8356765468859826\n",
      "Epoch: 55, Iteration: 0, Loss: 0.6439786403806924\n",
      "Epoch: 55, Iteration: 1600, Loss: 0.6434693122101545\n",
      "Epoch: 55, Iteration: 3200, Loss: 0.6364308792061213\n",
      "Epoch: 55, Iteration: 4800, Loss: 0.688977406787688\n",
      "Epoch: 55, Iteration: 6400, Loss: 0.7560831234290245\n",
      "Epoch: 55, Iteration: 8000, Loss: 0.7562555556673988\n",
      "Epoch: 55, Iteration: 9600, Loss: 0.5811856659838904\n",
      "Epoch: 55, Iteration: 11200, Loss: 0.8040978652987046\n",
      "Epoch: 55, Iteration: 12800, Loss: 0.6284533040028657\n",
      "Epoch: 55, Iteration: 14400, Loss: 0.5585788559529309\n",
      "Epoch: 55, Iteration: 16000, Loss: 0.7167820980060344\n",
      "Epoch: 55, Iteration: 17600, Loss: 0.7002723133620229\n",
      "Epoch: 55, Iteration: 19200, Loss: 0.607292326581616\n",
      "Epoch: 55, Iteration: 20800, Loss: 0.7644917912368596\n",
      "Epoch: 55, Iteration: 22400, Loss: 0.8099142774432091\n",
      "Epoch: 55, Iteration: 24000, Loss: 0.5296842439486441\n",
      "Epoch: 55, Iteration: 25600, Loss: 0.8749542395338114\n",
      "Epoch: 55, Iteration: 27200, Loss: 0.7059640812042303\n",
      "Epoch: 55, Iteration: 28800, Loss: 0.5380804319322313\n",
      "Epoch: 55, Iteration: 30400, Loss: 0.6901338245090907\n",
      "Epoch: 55, Iteration: 32000, Loss: 0.676865394569903\n",
      "Epoch: 55, Iteration: 33600, Loss: 0.7189198269201356\n",
      "Epoch: 55, Iteration: 35200, Loss: 0.8491084799389041\n",
      "Epoch: 55, Iteration: 36800, Loss: 0.9440266736895169\n",
      "Epoch: 55, Iteration: 38400, Loss: 0.5249131063474284\n",
      "Epoch: 55, Iteration: 40000, Loss: 0.7222531790366019\n",
      "Epoch: 55, Iteration: 41600, Loss: 0.7507527337378141\n",
      "Epoch: 55, Iteration: 43200, Loss: 0.7006681479018053\n",
      "Epoch: 55, Iteration: 44800, Loss: 0.6681572333822581\n",
      "Epoch: 55, Iteration: 46400, Loss: 0.9424354642482395\n",
      "Epoch: 55, Iteration: 48000, Loss: 0.766316504387926\n",
      "Epoch: 55, Iteration: 49600, Loss: 0.7865390747036343\n",
      "Epoch: 55, Iteration: 51200, Loss: 0.5567244437965673\n",
      "Epoch: 55, Iteration: 52800, Loss: 0.9179887365938824\n",
      "Epoch: 55, Iteration: 54400, Loss: 0.8563510455579334\n",
      "Epoch: 55, Iteration: 56000, Loss: 0.5581838476791205\n",
      "Epoch: 55, Iteration: 57600, Loss: 0.7364066800339292\n",
      "Epoch: 55, Iteration: 59200, Loss: 0.6000019267006971\n",
      "Epoch: 55, Iteration: 60800, Loss: 0.9139303620279184\n",
      "Epoch: 55, Iteration: 62400, Loss: 0.8272335821355246\n",
      "Epoch: 56, Iteration: 0, Loss: 0.6254121532867465\n",
      "Epoch: 56, Iteration: 1600, Loss: 0.6398348874075348\n",
      "Epoch: 56, Iteration: 3200, Loss: 0.6216767702370308\n",
      "Epoch: 56, Iteration: 4800, Loss: 0.6862225205131942\n",
      "Epoch: 56, Iteration: 6400, Loss: 0.7436061738080124\n",
      "Epoch: 56, Iteration: 8000, Loss: 0.7449180925205078\n",
      "Epoch: 56, Iteration: 9600, Loss: 0.580289933008328\n",
      "Epoch: 56, Iteration: 11200, Loss: 0.7994321794454265\n",
      "Epoch: 56, Iteration: 12800, Loss: 0.6173155756272444\n",
      "Epoch: 56, Iteration: 14400, Loss: 0.551249796444473\n",
      "Epoch: 56, Iteration: 16000, Loss: 0.7178873098506431\n",
      "Epoch: 56, Iteration: 17600, Loss: 0.6917914953446213\n",
      "Epoch: 56, Iteration: 19200, Loss: 0.6033043897843212\n",
      "Epoch: 56, Iteration: 20800, Loss: 0.7727387041153133\n",
      "Epoch: 56, Iteration: 22400, Loss: 0.8018322472889428\n",
      "Epoch: 56, Iteration: 24000, Loss: 0.5270753719657164\n",
      "Epoch: 56, Iteration: 25600, Loss: 0.86829040740861\n",
      "Epoch: 56, Iteration: 27200, Loss: 0.6996135918682074\n",
      "Epoch: 56, Iteration: 28800, Loss: 0.5354076979688707\n",
      "Epoch: 56, Iteration: 30400, Loss: 0.6831264235821322\n",
      "Epoch: 56, Iteration: 32000, Loss: 0.674026420684218\n",
      "Epoch: 56, Iteration: 33600, Loss: 0.7175136733836688\n",
      "Epoch: 56, Iteration: 35200, Loss: 0.841076339863725\n",
      "Epoch: 56, Iteration: 36800, Loss: 0.9364258775675017\n",
      "Epoch: 56, Iteration: 38400, Loss: 0.5255582127282312\n",
      "Epoch: 56, Iteration: 40000, Loss: 0.7247300365837258\n",
      "Epoch: 56, Iteration: 41600, Loss: 0.7581508410250213\n",
      "Epoch: 56, Iteration: 43200, Loss: 0.6972248113357652\n",
      "Epoch: 56, Iteration: 44800, Loss: 0.669674158773518\n",
      "Epoch: 56, Iteration: 46400, Loss: 0.9324290393706854\n",
      "Epoch: 56, Iteration: 48000, Loss: 0.7632887234592958\n",
      "Epoch: 56, Iteration: 49600, Loss: 0.7830288918215773\n",
      "Epoch: 56, Iteration: 51200, Loss: 0.5446244982049206\n",
      "Epoch: 56, Iteration: 52800, Loss: 0.9225914852499173\n",
      "Epoch: 56, Iteration: 54400, Loss: 0.8518950067629127\n",
      "Epoch: 56, Iteration: 56000, Loss: 0.5447897206601007\n",
      "Epoch: 56, Iteration: 57600, Loss: 0.7283501109799417\n",
      "Epoch: 56, Iteration: 59200, Loss: 0.6058906205355394\n",
      "Epoch: 56, Iteration: 60800, Loss: 0.9175598653839174\n",
      "Epoch: 56, Iteration: 62400, Loss: 0.8164427296136296\n",
      "Epoch: 57, Iteration: 0, Loss: 0.604772277604683\n",
      "Epoch: 57, Iteration: 1600, Loss: 0.6356504858849282\n",
      "Epoch: 57, Iteration: 3200, Loss: 0.6072291485873327\n",
      "Epoch: 57, Iteration: 4800, Loss: 0.685233541957533\n",
      "Epoch: 57, Iteration: 6400, Loss: 0.7317511172351525\n",
      "Epoch: 57, Iteration: 8000, Loss: 0.7305115830426457\n",
      "Epoch: 57, Iteration: 9600, Loss: 0.5814900752822261\n",
      "Epoch: 57, Iteration: 11200, Loss: 0.7959365813039115\n",
      "Epoch: 57, Iteration: 12800, Loss: 0.6114767028699799\n",
      "Epoch: 57, Iteration: 14400, Loss: 0.5476293583401703\n",
      "Epoch: 57, Iteration: 16000, Loss: 0.724861190802464\n",
      "Epoch: 57, Iteration: 17600, Loss: 0.684912207705336\n",
      "Epoch: 57, Iteration: 19200, Loss: 0.6061788382806119\n",
      "Epoch: 57, Iteration: 20800, Loss: 0.7831298705569238\n",
      "Epoch: 57, Iteration: 22400, Loss: 0.7946474648729195\n",
      "Epoch: 57, Iteration: 24000, Loss: 0.5261609950175248\n",
      "Epoch: 57, Iteration: 25600, Loss: 0.8596943553359044\n",
      "Epoch: 57, Iteration: 27200, Loss: 0.6942370662360619\n",
      "Epoch: 57, Iteration: 28800, Loss: 0.5350198193715516\n",
      "Epoch: 57, Iteration: 30400, Loss: 0.679905255400991\n",
      "Epoch: 57, Iteration: 32000, Loss: 0.6684682210006356\n",
      "Epoch: 57, Iteration: 33600, Loss: 0.7199598525846433\n",
      "Epoch: 57, Iteration: 35200, Loss: 0.8349253746205215\n",
      "Epoch: 57, Iteration: 36800, Loss: 0.9302073681543145\n",
      "Epoch: 57, Iteration: 38400, Loss: 0.5278143235822146\n",
      "Epoch: 57, Iteration: 40000, Loss: 0.7298617295196863\n",
      "Epoch: 57, Iteration: 41600, Loss: 0.7730613257419061\n",
      "Epoch: 57, Iteration: 43200, Loss: 0.7004521343265109\n",
      "Epoch: 57, Iteration: 44800, Loss: 0.6727997431547437\n",
      "Epoch: 57, Iteration: 46400, Loss: 0.9189934317705777\n",
      "Epoch: 57, Iteration: 48000, Loss: 0.7607147954922102\n",
      "Epoch: 57, Iteration: 49600, Loss: 0.7833754257880159\n",
      "Epoch: 57, Iteration: 51200, Loss: 0.5361481910674739\n",
      "Epoch: 57, Iteration: 52800, Loss: 0.932024291156152\n",
      "Epoch: 57, Iteration: 54400, Loss: 0.8584305992884032\n",
      "Epoch: 57, Iteration: 56000, Loss: 0.535339974995025\n",
      "Epoch: 57, Iteration: 57600, Loss: 0.7281190611624719\n",
      "Epoch: 57, Iteration: 59200, Loss: 0.6208288256260215\n",
      "Epoch: 57, Iteration: 60800, Loss: 0.9270554068389634\n",
      "Epoch: 57, Iteration: 62400, Loss: 0.8039044840505347\n",
      "Epoch: 58, Iteration: 0, Loss: 0.5834700266668119\n",
      "Epoch: 58, Iteration: 1600, Loss: 0.634383593211073\n",
      "Epoch: 58, Iteration: 3200, Loss: 0.5964745966824434\n",
      "Epoch: 58, Iteration: 4800, Loss: 0.6870300212245248\n",
      "Epoch: 58, Iteration: 6400, Loss: 0.7228344560918162\n",
      "Epoch: 58, Iteration: 8000, Loss: 0.7184338711535779\n",
      "Epoch: 58, Iteration: 9600, Loss: 0.5882125597988258\n",
      "Epoch: 58, Iteration: 11200, Loss: 0.7959879740674727\n",
      "Epoch: 58, Iteration: 12800, Loss: 0.6193301140097741\n",
      "Epoch: 58, Iteration: 14400, Loss: 0.5505977861591422\n",
      "Epoch: 58, Iteration: 16000, Loss: 0.7437034089747401\n",
      "Epoch: 58, Iteration: 17600, Loss: 0.6820003793902624\n",
      "Epoch: 58, Iteration: 19200, Loss: 0.6199752243097824\n",
      "Epoch: 58, Iteration: 20800, Loss: 0.7972675438054508\n",
      "Epoch: 58, Iteration: 22400, Loss: 0.7922061885232967\n",
      "Epoch: 58, Iteration: 24000, Loss: 0.5306713963958458\n",
      "Epoch: 58, Iteration: 25600, Loss: 0.8523143328422214\n",
      "Epoch: 58, Iteration: 27200, Loss: 0.693729703150895\n",
      "Epoch: 58, Iteration: 28800, Loss: 0.5370078851258284\n",
      "Epoch: 58, Iteration: 30400, Loss: 0.6868747291746096\n",
      "Epoch: 58, Iteration: 32000, Loss: 0.6634429025344994\n",
      "Epoch: 58, Iteration: 33600, Loss: 0.7281480162033489\n",
      "Epoch: 58, Iteration: 35200, Loss: 0.8281915614171931\n",
      "Epoch: 58, Iteration: 36800, Loss: 0.9275209972265419\n",
      "Epoch: 58, Iteration: 38400, Loss: 0.5334793112201885\n",
      "Epoch: 58, Iteration: 40000, Loss: 0.7454073626051152\n",
      "Epoch: 58, Iteration: 41600, Loss: 0.7871302355209635\n",
      "Epoch: 58, Iteration: 43200, Loss: 0.7127287884028863\n",
      "Epoch: 58, Iteration: 44800, Loss: 0.6791957862437286\n",
      "Epoch: 58, Iteration: 46400, Loss: 0.8976713733292464\n",
      "Epoch: 58, Iteration: 48000, Loss: 0.763943663597873\n",
      "Epoch: 58, Iteration: 49600, Loss: 0.7934211401108762\n",
      "Epoch: 58, Iteration: 51200, Loss: 0.5316968902816649\n",
      "Epoch: 58, Iteration: 52800, Loss: 0.9443557834346018\n",
      "Epoch: 58, Iteration: 54400, Loss: 0.8860172261073556\n",
      "Epoch: 58, Iteration: 56000, Loss: 0.5318253356944322\n",
      "Epoch: 58, Iteration: 57600, Loss: 0.7340270674097438\n",
      "Epoch: 58, Iteration: 59200, Loss: 0.6363171810999382\n",
      "Epoch: 58, Iteration: 60800, Loss: 0.9318265081508105\n",
      "Epoch: 58, Iteration: 62400, Loss: 0.7909315457904873\n",
      "Epoch: 59, Iteration: 0, Loss: 0.5685840549668306\n",
      "Epoch: 59, Iteration: 1600, Loss: 0.6333592405661239\n",
      "Epoch: 59, Iteration: 3200, Loss: 0.5941189377636807\n",
      "Epoch: 59, Iteration: 4800, Loss: 0.6825791585503457\n",
      "Epoch: 59, Iteration: 6400, Loss: 0.7204168058861528\n",
      "Epoch: 59, Iteration: 8000, Loss: 0.709431872513606\n",
      "Epoch: 59, Iteration: 9600, Loss: 0.5914774636472215\n",
      "Epoch: 59, Iteration: 11200, Loss: 0.7973539286974893\n",
      "Epoch: 59, Iteration: 12800, Loss: 0.6326556587087272\n",
      "Epoch: 59, Iteration: 14400, Loss: 0.5595974176290321\n",
      "Epoch: 59, Iteration: 16000, Loss: 0.7512942692404736\n",
      "Epoch: 59, Iteration: 17600, Loss: 0.6809937895895184\n",
      "Epoch: 59, Iteration: 19200, Loss: 0.6320498623439457\n",
      "Epoch: 59, Iteration: 20800, Loss: 0.805925525228182\n",
      "Epoch: 59, Iteration: 22400, Loss: 0.789110879459828\n",
      "Epoch: 59, Iteration: 24000, Loss: 0.5309523677953335\n",
      "Epoch: 59, Iteration: 25600, Loss: 0.847200989119331\n",
      "Epoch: 59, Iteration: 27200, Loss: 0.6986514221865996\n",
      "Epoch: 59, Iteration: 28800, Loss: 0.5338674511434971\n",
      "Epoch: 59, Iteration: 30400, Loss: 0.6936320945588013\n",
      "Epoch: 59, Iteration: 32000, Loss: 0.6612621989939866\n",
      "Epoch: 59, Iteration: 33600, Loss: 0.7275580791163377\n",
      "Epoch: 59, Iteration: 35200, Loss: 0.817277803537255\n",
      "Epoch: 59, Iteration: 36800, Loss: 0.9214579352518238\n",
      "Epoch: 59, Iteration: 38400, Loss: 0.5338203761006098\n",
      "Epoch: 59, Iteration: 40000, Loss: 0.7518444868689765\n",
      "Epoch: 59, Iteration: 41600, Loss: 0.7891776456705382\n",
      "Epoch: 59, Iteration: 43200, Loss: 0.7148770671814321\n",
      "Epoch: 59, Iteration: 44800, Loss: 0.679000126725807\n",
      "Epoch: 59, Iteration: 46400, Loss: 0.8818269374136044\n",
      "Epoch: 59, Iteration: 48000, Loss: 0.760342634018119\n",
      "Epoch: 59, Iteration: 49600, Loss: 0.80198539851791\n",
      "Epoch: 59, Iteration: 51200, Loss: 0.5270158554673392\n",
      "Epoch: 59, Iteration: 52800, Loss: 0.9447765701456216\n",
      "Epoch: 59, Iteration: 54400, Loss: 0.8977779151562528\n",
      "Epoch: 59, Iteration: 56000, Loss: 0.5270289396309024\n",
      "Epoch: 59, Iteration: 57600, Loss: 0.7333497171025254\n",
      "Epoch: 59, Iteration: 59200, Loss: 0.6452185140790856\n",
      "Epoch: 59, Iteration: 60800, Loss: 0.9311489628258457\n",
      "Epoch: 59, Iteration: 62400, Loss: 0.7773169460480739\n",
      "Epoch: 60, Iteration: 0, Loss: 0.5574867383047031\n",
      "Epoch: 60, Iteration: 1600, Loss: 0.629374661386704\n",
      "Epoch: 60, Iteration: 3200, Loss: 0.5929001680105216\n",
      "Epoch: 60, Iteration: 4800, Loss: 0.6706559859014882\n",
      "Epoch: 60, Iteration: 6400, Loss: 0.7197740796204813\n",
      "Epoch: 60, Iteration: 8000, Loss: 0.6942911712452255\n",
      "Epoch: 60, Iteration: 9600, Loss: 0.5914719906358243\n",
      "Epoch: 60, Iteration: 11200, Loss: 0.793425686436542\n",
      "Epoch: 60, Iteration: 12800, Loss: 0.6357716426644954\n",
      "Epoch: 60, Iteration: 14400, Loss: 0.567620053239546\n",
      "Epoch: 60, Iteration: 16000, Loss: 0.7480154797924853\n",
      "Epoch: 60, Iteration: 17600, Loss: 0.6785783866740523\n",
      "Epoch: 60, Iteration: 19200, Loss: 0.6343361321067879\n",
      "Epoch: 60, Iteration: 20800, Loss: 0.8102483276749786\n",
      "Epoch: 60, Iteration: 22400, Loss: 0.7820284764386165\n",
      "Epoch: 60, Iteration: 24000, Loss: 0.5320828762759257\n",
      "Epoch: 60, Iteration: 25600, Loss: 0.8433105848465594\n",
      "Epoch: 60, Iteration: 27200, Loss: 0.7014981504009692\n",
      "Epoch: 60, Iteration: 28800, Loss: 0.5252985370802794\n",
      "Epoch: 60, Iteration: 30400, Loss: 0.6965760811236088\n",
      "Epoch: 60, Iteration: 32000, Loss: 0.6585025855359292\n",
      "Epoch: 60, Iteration: 33600, Loss: 0.7218135379622325\n",
      "Epoch: 60, Iteration: 35200, Loss: 0.8078198787151079\n",
      "Epoch: 60, Iteration: 36800, Loss: 0.9122144956906886\n",
      "Epoch: 60, Iteration: 38400, Loss: 0.5326547522695617\n",
      "Epoch: 60, Iteration: 40000, Loss: 0.7539946596810194\n",
      "Epoch: 60, Iteration: 41600, Loss: 0.7923933825180698\n",
      "Epoch: 60, Iteration: 43200, Loss: 0.7082561951003927\n",
      "Epoch: 60, Iteration: 44800, Loss: 0.6737367569398466\n",
      "Epoch: 60, Iteration: 46400, Loss: 0.8672055425408767\n",
      "Epoch: 60, Iteration: 48000, Loss: 0.754118167377443\n",
      "Epoch: 60, Iteration: 49600, Loss: 0.8069017098356281\n",
      "Epoch: 60, Iteration: 51200, Loss: 0.5230160961657122\n",
      "Epoch: 60, Iteration: 52800, Loss: 0.9418053771821133\n",
      "Epoch: 60, Iteration: 54400, Loss: 0.9008905597006156\n",
      "Epoch: 60, Iteration: 56000, Loss: 0.5242765855699401\n",
      "Epoch: 60, Iteration: 57600, Loss: 0.7314475813161709\n",
      "Epoch: 60, Iteration: 59200, Loss: 0.6538753039096649\n",
      "Epoch: 60, Iteration: 60800, Loss: 0.9273784404288462\n",
      "Epoch: 60, Iteration: 62400, Loss: 0.7662136860966416\n",
      "Epoch: 61, Iteration: 0, Loss: 0.549763819759789\n",
      "Epoch: 61, Iteration: 1600, Loss: 0.6265874243236005\n",
      "Epoch: 61, Iteration: 3200, Loss: 0.590533315703345\n",
      "Epoch: 61, Iteration: 4800, Loss: 0.6593762114778217\n",
      "Epoch: 61, Iteration: 6400, Loss: 0.7194306171532743\n",
      "Epoch: 61, Iteration: 8000, Loss: 0.6816790037666676\n",
      "Epoch: 61, Iteration: 9600, Loss: 0.5934292179333351\n",
      "Epoch: 61, Iteration: 11200, Loss: 0.7888403478058901\n",
      "Epoch: 61, Iteration: 12800, Loss: 0.6418328156684536\n",
      "Epoch: 61, Iteration: 14400, Loss: 0.5806886159555829\n",
      "Epoch: 61, Iteration: 16000, Loss: 0.7443150967222477\n",
      "Epoch: 61, Iteration: 17600, Loss: 0.676555023784179\n",
      "Epoch: 61, Iteration: 19200, Loss: 0.6357941532223432\n",
      "Epoch: 61, Iteration: 20800, Loss: 0.8115780815740468\n",
      "Epoch: 61, Iteration: 22400, Loss: 0.778748271050633\n",
      "Epoch: 61, Iteration: 24000, Loss: 0.5383306404926667\n",
      "Epoch: 61, Iteration: 25600, Loss: 0.8409971566905678\n",
      "Epoch: 61, Iteration: 27200, Loss: 0.7035218574215711\n",
      "Epoch: 61, Iteration: 28800, Loss: 0.5130649581280256\n",
      "Epoch: 61, Iteration: 30400, Loss: 0.6998072051345218\n",
      "Epoch: 61, Iteration: 32000, Loss: 0.6598389955022319\n",
      "Epoch: 61, Iteration: 33600, Loss: 0.7158318424789214\n",
      "Epoch: 61, Iteration: 35200, Loss: 0.8006016649382217\n",
      "Epoch: 61, Iteration: 36800, Loss: 0.8985598786836373\n",
      "Epoch: 61, Iteration: 38400, Loss: 0.5340997802358454\n",
      "Epoch: 61, Iteration: 40000, Loss: 0.7635137398857741\n",
      "Epoch: 61, Iteration: 41600, Loss: 0.8016313855930385\n",
      "Epoch: 61, Iteration: 43200, Loss: 0.6973741496517901\n",
      "Epoch: 61, Iteration: 44800, Loss: 0.6655751622056556\n",
      "Epoch: 61, Iteration: 46400, Loss: 0.8543997125432476\n",
      "Epoch: 61, Iteration: 48000, Loss: 0.7505020708965213\n",
      "Epoch: 61, Iteration: 49600, Loss: 0.8101180528645248\n",
      "Epoch: 61, Iteration: 51200, Loss: 0.5196854319882417\n",
      "Epoch: 61, Iteration: 52800, Loss: 0.9415005342844608\n",
      "Epoch: 61, Iteration: 54400, Loss: 0.9065140421403726\n",
      "Epoch: 61, Iteration: 56000, Loss: 0.5275342774627985\n",
      "Epoch: 61, Iteration: 57600, Loss: 0.7327380250329554\n",
      "Epoch: 61, Iteration: 59200, Loss: 0.6666729401193321\n",
      "Epoch: 61, Iteration: 60800, Loss: 0.9198098770045808\n",
      "Epoch: 61, Iteration: 62400, Loss: 0.7635429569864834\n",
      "Epoch: 62, Iteration: 0, Loss: 0.5533639202639272\n",
      "Epoch: 62, Iteration: 1600, Loss: 0.6248387374950664\n",
      "Epoch: 62, Iteration: 3200, Loss: 0.5916154014779302\n",
      "Epoch: 62, Iteration: 4800, Loss: 0.6570801839714535\n",
      "Epoch: 62, Iteration: 6400, Loss: 0.7219970616770925\n",
      "Epoch: 62, Iteration: 8000, Loss: 0.6717524694742285\n",
      "Epoch: 62, Iteration: 9600, Loss: 0.5969177352683219\n",
      "Epoch: 62, Iteration: 11200, Loss: 0.7813532779998082\n",
      "Epoch: 62, Iteration: 12800, Loss: 0.6652651798449762\n",
      "Epoch: 62, Iteration: 14400, Loss: 0.6062823205843972\n",
      "Epoch: 62, Iteration: 16000, Loss: 0.7460662681054651\n",
      "Epoch: 62, Iteration: 17600, Loss: 0.67784871175118\n",
      "Epoch: 62, Iteration: 19200, Loss: 0.6394647940659324\n",
      "Epoch: 62, Iteration: 20800, Loss: 0.8099363501825955\n",
      "Epoch: 62, Iteration: 22400, Loss: 0.7874054204323058\n",
      "Epoch: 62, Iteration: 24000, Loss: 0.551947181788655\n",
      "Epoch: 62, Iteration: 25600, Loss: 0.8422284510418918\n",
      "Epoch: 62, Iteration: 27200, Loss: 0.7119315418808674\n",
      "Epoch: 62, Iteration: 28800, Loss: 0.5051867936581138\n",
      "Epoch: 62, Iteration: 30400, Loss: 0.7059756365686066\n",
      "Epoch: 62, Iteration: 32000, Loss: 0.6672225940752465\n",
      "Epoch: 62, Iteration: 33600, Loss: 0.7119869833557765\n",
      "Epoch: 62, Iteration: 35200, Loss: 0.7948880104470197\n",
      "Epoch: 62, Iteration: 36800, Loss: 0.8788009552663287\n",
      "Epoch: 62, Iteration: 38400, Loss: 0.5417285964335012\n",
      "Epoch: 62, Iteration: 40000, Loss: 0.7738775489218614\n",
      "Epoch: 62, Iteration: 41600, Loss: 0.818179380538562\n",
      "Epoch: 62, Iteration: 43200, Loss: 0.6907458471508408\n",
      "Epoch: 62, Iteration: 44800, Loss: 0.6596261813026145\n",
      "Epoch: 62, Iteration: 46400, Loss: 0.8496932906664072\n",
      "Epoch: 62, Iteration: 48000, Loss: 0.7515315563042146\n",
      "Epoch: 62, Iteration: 49600, Loss: 0.8168911702547582\n",
      "Epoch: 62, Iteration: 51200, Loss: 0.5204573684224922\n",
      "Epoch: 62, Iteration: 52800, Loss: 0.9467938905723277\n",
      "Epoch: 62, Iteration: 54400, Loss: 0.913790757243938\n",
      "Epoch: 62, Iteration: 56000, Loss: 0.534380336411054\n",
      "Epoch: 62, Iteration: 57600, Loss: 0.7384183919765281\n",
      "Epoch: 62, Iteration: 59200, Loss: 0.6789410530686686\n",
      "Epoch: 62, Iteration: 60800, Loss: 0.9128283184310393\n",
      "Epoch: 62, Iteration: 62400, Loss: 0.7717839367573712\n",
      "Epoch: 63, Iteration: 0, Loss: 0.5743387434225973\n",
      "Epoch: 63, Iteration: 1600, Loss: 0.6240653173998817\n",
      "Epoch: 63, Iteration: 3200, Loss: 0.6005304871138601\n",
      "Epoch: 63, Iteration: 4800, Loss: 0.6672811215620273\n",
      "Epoch: 63, Iteration: 6400, Loss: 0.7205716019782601\n",
      "Epoch: 63, Iteration: 8000, Loss: 0.6702050185981039\n",
      "Epoch: 63, Iteration: 9600, Loss: 0.6025084227085529\n",
      "Epoch: 63, Iteration: 11200, Loss: 0.7680198084393416\n",
      "Epoch: 63, Iteration: 12800, Loss: 0.6962343075832883\n",
      "Epoch: 63, Iteration: 14400, Loss: 0.6343261081094552\n",
      "Epoch: 63, Iteration: 16000, Loss: 0.7462123081028638\n",
      "Epoch: 63, Iteration: 17600, Loss: 0.6845409801871172\n",
      "Epoch: 63, Iteration: 19200, Loss: 0.6457215078696943\n",
      "Epoch: 63, Iteration: 20800, Loss: 0.7950463753134625\n",
      "Epoch: 63, Iteration: 22400, Loss: 0.8049815814419725\n",
      "Epoch: 63, Iteration: 24000, Loss: 0.5656899112705108\n",
      "Epoch: 63, Iteration: 25600, Loss: 0.8462432486533719\n",
      "Epoch: 63, Iteration: 27200, Loss: 0.7317927325078386\n",
      "Epoch: 63, Iteration: 28800, Loss: 0.49993760967719747\n",
      "Epoch: 63, Iteration: 30400, Loss: 0.7174632424983141\n",
      "Epoch: 63, Iteration: 32000, Loss: 0.6661835087622618\n",
      "Epoch: 63, Iteration: 33600, Loss: 0.7024184623996454\n",
      "Epoch: 63, Iteration: 35200, Loss: 0.7955650271513522\n",
      "Epoch: 63, Iteration: 36800, Loss: 0.8674922928080129\n",
      "Epoch: 63, Iteration: 38400, Loss: 0.5492292837009513\n",
      "Epoch: 63, Iteration: 40000, Loss: 0.7680969790353731\n",
      "Epoch: 63, Iteration: 41600, Loss: 0.8293096599827019\n",
      "Epoch: 63, Iteration: 43200, Loss: 0.688602632414687\n",
      "Epoch: 63, Iteration: 44800, Loss: 0.6597688138863874\n",
      "Epoch: 63, Iteration: 46400, Loss: 0.8480542371925878\n",
      "Epoch: 63, Iteration: 48000, Loss: 0.7523018935946686\n",
      "Epoch: 63, Iteration: 49600, Loss: 0.8306014641178412\n",
      "Epoch: 63, Iteration: 51200, Loss: 0.5208445891968975\n",
      "Epoch: 63, Iteration: 52800, Loss: 0.9519373875213701\n",
      "Epoch: 63, Iteration: 54400, Loss: 0.9154975994735135\n",
      "Epoch: 63, Iteration: 56000, Loss: 0.5385338217026894\n",
      "Epoch: 63, Iteration: 57600, Loss: 0.7355223279038683\n",
      "Epoch: 63, Iteration: 59200, Loss: 0.6877083217854993\n",
      "Epoch: 63, Iteration: 60800, Loss: 0.9085282533789781\n",
      "Epoch: 63, Iteration: 62400, Loss: 0.7717338992652779\n",
      "Epoch: 64, Iteration: 0, Loss: 0.5849126389281616\n",
      "Epoch: 64, Iteration: 1600, Loss: 0.6311753264784952\n",
      "Epoch: 64, Iteration: 3200, Loss: 0.6074573868346536\n",
      "Epoch: 64, Iteration: 4800, Loss: 0.6730295832909292\n",
      "Epoch: 64, Iteration: 6400, Loss: 0.7145366952770333\n",
      "Epoch: 64, Iteration: 8000, Loss: 0.6738661968066446\n",
      "Epoch: 64, Iteration: 9600, Loss: 0.6059159940986599\n",
      "Epoch: 64, Iteration: 11200, Loss: 0.7688506847011833\n",
      "Epoch: 64, Iteration: 12800, Loss: 0.7173690602676759\n",
      "Epoch: 64, Iteration: 14400, Loss: 0.6500796056329907\n",
      "Epoch: 64, Iteration: 16000, Loss: 0.7388782297716372\n",
      "Epoch: 64, Iteration: 17600, Loss: 0.6898069953968915\n",
      "Epoch: 64, Iteration: 19200, Loss: 0.6578335196726335\n",
      "Epoch: 64, Iteration: 20800, Loss: 0.774180727764262\n",
      "Epoch: 64, Iteration: 22400, Loss: 0.8147787448309383\n",
      "Epoch: 64, Iteration: 24000, Loss: 0.5723931764507264\n",
      "Epoch: 64, Iteration: 25600, Loss: 0.8480299317501908\n",
      "Epoch: 64, Iteration: 27200, Loss: 0.7519396512017998\n",
      "Epoch: 64, Iteration: 28800, Loss: 0.49344247254829743\n",
      "Epoch: 64, Iteration: 30400, Loss: 0.726250595046863\n",
      "Epoch: 64, Iteration: 32000, Loss: 0.6609015415572582\n",
      "Epoch: 64, Iteration: 33600, Loss: 0.6897087066178769\n",
      "Epoch: 64, Iteration: 35200, Loss: 0.7984513922121624\n",
      "Epoch: 64, Iteration: 36800, Loss: 0.8574780559261471\n",
      "Epoch: 64, Iteration: 38400, Loss: 0.5513973638038078\n",
      "Epoch: 64, Iteration: 40000, Loss: 0.7585768463084057\n",
      "Epoch: 64, Iteration: 41600, Loss: 0.8335504298179639\n",
      "Epoch: 64, Iteration: 43200, Loss: 0.6906931697076804\n",
      "Epoch: 64, Iteration: 44800, Loss: 0.6614106616262736\n",
      "Epoch: 64, Iteration: 46400, Loss: 0.8409463854807915\n",
      "Epoch: 64, Iteration: 48000, Loss: 0.7437956501141669\n",
      "Epoch: 64, Iteration: 49600, Loss: 0.8388904952952718\n",
      "Epoch: 64, Iteration: 51200, Loss: 0.5164768247662517\n",
      "Epoch: 64, Iteration: 52800, Loss: 0.9507878518475856\n",
      "Epoch: 64, Iteration: 54400, Loss: 0.9127161333926508\n",
      "Epoch: 64, Iteration: 56000, Loss: 0.5397553755947864\n",
      "Epoch: 64, Iteration: 57600, Loss: 0.733203139002556\n",
      "Epoch: 64, Iteration: 59200, Loss: 0.6920837583125121\n",
      "Epoch: 64, Iteration: 60800, Loss: 0.9030323530620958\n",
      "Epoch: 64, Iteration: 62400, Loss: 0.757795727789879\n",
      "Epoch: 65, Iteration: 0, Loss: 0.5834377086924396\n",
      "Epoch: 65, Iteration: 1600, Loss: 0.6381047457703121\n",
      "Epoch: 65, Iteration: 3200, Loss: 0.6143176230473073\n",
      "Epoch: 65, Iteration: 4800, Loss: 0.6712046420469983\n",
      "Epoch: 65, Iteration: 6400, Loss: 0.7135082510825156\n",
      "Epoch: 65, Iteration: 8000, Loss: 0.677387418908824\n",
      "Epoch: 65, Iteration: 9600, Loss: 0.6052080404843313\n",
      "Epoch: 65, Iteration: 11200, Loss: 0.7736868221768134\n",
      "Epoch: 65, Iteration: 12800, Loss: 0.7304803354059477\n",
      "Epoch: 65, Iteration: 14400, Loss: 0.6523318074080304\n",
      "Epoch: 65, Iteration: 16000, Loss: 0.7269199577899059\n",
      "Epoch: 65, Iteration: 17600, Loss: 0.6929348304953419\n",
      "Epoch: 65, Iteration: 19200, Loss: 0.6679718523174232\n",
      "Epoch: 65, Iteration: 20800, Loss: 0.7619282704576594\n",
      "Epoch: 65, Iteration: 22400, Loss: 0.816192038904229\n",
      "Epoch: 65, Iteration: 24000, Loss: 0.5732001411757833\n",
      "Epoch: 65, Iteration: 25600, Loss: 0.8441040938314187\n",
      "Epoch: 65, Iteration: 27200, Loss: 0.7647352611912465\n",
      "Epoch: 65, Iteration: 28800, Loss: 0.4885937239634655\n",
      "Epoch: 65, Iteration: 30400, Loss: 0.7285229253361154\n",
      "Epoch: 65, Iteration: 32000, Loss: 0.6498709646870209\n",
      "Epoch: 65, Iteration: 33600, Loss: 0.6731335058988228\n",
      "Epoch: 65, Iteration: 35200, Loss: 0.7948212151252885\n",
      "Epoch: 65, Iteration: 36800, Loss: 0.8498305977375652\n",
      "Epoch: 65, Iteration: 38400, Loss: 0.5486572470827316\n",
      "Epoch: 65, Iteration: 40000, Loss: 0.7472288537804694\n",
      "Epoch: 65, Iteration: 41600, Loss: 0.8356130863084127\n",
      "Epoch: 65, Iteration: 43200, Loss: 0.6866937220414857\n",
      "Epoch: 65, Iteration: 44800, Loss: 0.6610163508364573\n",
      "Epoch: 65, Iteration: 46400, Loss: 0.8306825383226195\n",
      "Epoch: 65, Iteration: 48000, Loss: 0.729864140198126\n",
      "Epoch: 65, Iteration: 49600, Loss: 0.8423162612442686\n",
      "Epoch: 65, Iteration: 51200, Loss: 0.512477663329346\n",
      "Epoch: 65, Iteration: 52800, Loss: 0.942364855638078\n",
      "Epoch: 65, Iteration: 54400, Loss: 0.9070027275045729\n",
      "Epoch: 65, Iteration: 56000, Loss: 0.5394704635049082\n",
      "Epoch: 65, Iteration: 57600, Loss: 0.7325713912109766\n",
      "Epoch: 65, Iteration: 59200, Loss: 0.6932268302366494\n",
      "Epoch: 65, Iteration: 60800, Loss: 0.8960176416700126\n",
      "Epoch: 65, Iteration: 62400, Loss: 0.7407273804156821\n",
      "Epoch: 66, Iteration: 0, Loss: 0.5759942013828304\n",
      "Epoch: 66, Iteration: 1600, Loss: 0.6387199427840926\n",
      "Epoch: 66, Iteration: 3200, Loss: 0.6177331992863884\n",
      "Epoch: 66, Iteration: 4800, Loss: 0.6653257610850644\n",
      "Epoch: 66, Iteration: 6400, Loss: 0.7117529154020718\n",
      "Epoch: 66, Iteration: 8000, Loss: 0.6793611162540061\n",
      "Epoch: 66, Iteration: 9600, Loss: 0.6040097207093197\n",
      "Epoch: 66, Iteration: 11200, Loss: 0.7774127069344816\n",
      "Epoch: 66, Iteration: 12800, Loss: 0.738935894966589\n",
      "Epoch: 66, Iteration: 14400, Loss: 0.6478009195003708\n",
      "Epoch: 66, Iteration: 16000, Loss: 0.7104114761910917\n",
      "Epoch: 66, Iteration: 17600, Loss: 0.6928864161778983\n",
      "Epoch: 66, Iteration: 19200, Loss: 0.6763843818054052\n",
      "Epoch: 66, Iteration: 20800, Loss: 0.7539880020704679\n",
      "Epoch: 66, Iteration: 22400, Loss: 0.814709961406741\n",
      "Epoch: 66, Iteration: 24000, Loss: 0.5724293932734902\n",
      "Epoch: 66, Iteration: 25600, Loss: 0.8377211756386971\n",
      "Epoch: 66, Iteration: 27200, Loss: 0.7753357039224529\n",
      "Epoch: 66, Iteration: 28800, Loss: 0.48238597129422645\n",
      "Epoch: 66, Iteration: 30400, Loss: 0.726715385668077\n",
      "Epoch: 66, Iteration: 32000, Loss: 0.6372827057844345\n",
      "Epoch: 66, Iteration: 33600, Loss: 0.6543380030353536\n",
      "Epoch: 66, Iteration: 35200, Loss: 0.7893482620042722\n",
      "Epoch: 66, Iteration: 36800, Loss: 0.842766461864881\n",
      "Epoch: 66, Iteration: 38400, Loss: 0.5450151921747926\n",
      "Epoch: 66, Iteration: 40000, Loss: 0.7357024568840367\n",
      "Epoch: 66, Iteration: 41600, Loss: 0.8364028043345408\n",
      "Epoch: 66, Iteration: 43200, Loss: 0.6779436610075036\n",
      "Epoch: 66, Iteration: 44800, Loss: 0.6597685352859339\n",
      "Epoch: 66, Iteration: 46400, Loss: 0.8207510639646136\n",
      "Epoch: 66, Iteration: 48000, Loss: 0.7100617882798324\n",
      "Epoch: 66, Iteration: 49600, Loss: 0.8446060808024343\n",
      "Epoch: 66, Iteration: 51200, Loss: 0.50915987650198\n",
      "Epoch: 66, Iteration: 52800, Loss: 0.9318164982856059\n",
      "Epoch: 66, Iteration: 54400, Loss: 0.9002362360315839\n",
      "Epoch: 66, Iteration: 56000, Loss: 0.5384466662156595\n",
      "Epoch: 66, Iteration: 57600, Loss: 0.7331109328000927\n",
      "Epoch: 66, Iteration: 59200, Loss: 0.6941252734546972\n",
      "Epoch: 66, Iteration: 60800, Loss: 0.8902376444964433\n",
      "Epoch: 66, Iteration: 62400, Loss: 0.7251558837294407\n",
      "Epoch: 67, Iteration: 0, Loss: 0.5664330529895559\n",
      "Epoch: 67, Iteration: 1600, Loss: 0.6346253017616981\n",
      "Epoch: 67, Iteration: 3200, Loss: 0.6203052442512007\n",
      "Epoch: 67, Iteration: 4800, Loss: 0.6580314382736768\n",
      "Epoch: 67, Iteration: 6400, Loss: 0.7112760404649014\n",
      "Epoch: 67, Iteration: 8000, Loss: 0.6811148500370228\n",
      "Epoch: 67, Iteration: 9600, Loss: 0.6056262639204312\n",
      "Epoch: 67, Iteration: 11200, Loss: 0.778904756049779\n",
      "Epoch: 67, Iteration: 12800, Loss: 0.7448627596612232\n",
      "Epoch: 67, Iteration: 14400, Loss: 0.6377254042177551\n",
      "Epoch: 67, Iteration: 16000, Loss: 0.6908684087547325\n",
      "Epoch: 67, Iteration: 17600, Loss: 0.6909583530784638\n",
      "Epoch: 67, Iteration: 19200, Loss: 0.6867597368345562\n",
      "Epoch: 67, Iteration: 20800, Loss: 0.7478881212318718\n",
      "Epoch: 67, Iteration: 22400, Loss: 0.8148991907071264\n",
      "Epoch: 67, Iteration: 24000, Loss: 0.5709942875243026\n",
      "Epoch: 67, Iteration: 25600, Loss: 0.8306744415096841\n",
      "Epoch: 67, Iteration: 27200, Loss: 0.7847740751272936\n",
      "Epoch: 67, Iteration: 28800, Loss: 0.47529201600020726\n",
      "Epoch: 67, Iteration: 30400, Loss: 0.7226202071726542\n",
      "Epoch: 67, Iteration: 32000, Loss: 0.62649181727399\n",
      "Epoch: 67, Iteration: 33600, Loss: 0.6349449954180391\n",
      "Epoch: 67, Iteration: 35200, Loss: 0.7838782711184926\n",
      "Epoch: 67, Iteration: 36800, Loss: 0.8335627051465867\n",
      "Epoch: 67, Iteration: 38400, Loss: 0.5410176574298478\n",
      "Epoch: 67, Iteration: 40000, Loss: 0.7253687292969178\n",
      "Epoch: 67, Iteration: 41600, Loss: 0.836851644212385\n",
      "Epoch: 67, Iteration: 43200, Loss: 0.6667389830034637\n",
      "Epoch: 67, Iteration: 44800, Loss: 0.6584888731919019\n",
      "Epoch: 67, Iteration: 46400, Loss: 0.8115759016670645\n",
      "Epoch: 67, Iteration: 48000, Loss: 0.6869818617229838\n",
      "Epoch: 67, Iteration: 49600, Loss: 0.8462110721977748\n",
      "Epoch: 67, Iteration: 51200, Loss: 0.5069628255694214\n",
      "Epoch: 67, Iteration: 52800, Loss: 0.9214679705957964\n",
      "Epoch: 67, Iteration: 54400, Loss: 0.8922285091083424\n",
      "Epoch: 67, Iteration: 56000, Loss: 0.5371941994640543\n",
      "Epoch: 67, Iteration: 57600, Loss: 0.7357113337600185\n",
      "Epoch: 67, Iteration: 59200, Loss: 0.6949164935011967\n",
      "Epoch: 67, Iteration: 60800, Loss: 0.8883807728260775\n",
      "Epoch: 67, Iteration: 62400, Loss: 0.7132356057095988\n",
      "Epoch: 68, Iteration: 0, Loss: 0.556338331373043\n",
      "Epoch: 68, Iteration: 1600, Loss: 0.6285183141963222\n",
      "Epoch: 68, Iteration: 3200, Loss: 0.6243610827587598\n",
      "Epoch: 68, Iteration: 4800, Loss: 0.6512163144130563\n",
      "Epoch: 68, Iteration: 6400, Loss: 0.7144850072419635\n",
      "Epoch: 68, Iteration: 8000, Loss: 0.6851318390667391\n",
      "Epoch: 68, Iteration: 9600, Loss: 0.611569434782522\n",
      "Epoch: 68, Iteration: 11200, Loss: 0.7788099330946967\n",
      "Epoch: 68, Iteration: 12800, Loss: 0.7477542918576372\n",
      "Epoch: 68, Iteration: 14400, Loss: 0.623461779712952\n",
      "Epoch: 68, Iteration: 16000, Loss: 0.6711300608824304\n",
      "Epoch: 68, Iteration: 17600, Loss: 0.6882861101630215\n",
      "Epoch: 68, Iteration: 19200, Loss: 0.700726059456587\n",
      "Epoch: 68, Iteration: 20800, Loss: 0.7415593135254431\n",
      "Epoch: 68, Iteration: 22400, Loss: 0.8199938662511173\n",
      "Epoch: 68, Iteration: 24000, Loss: 0.5686615515442194\n",
      "Epoch: 68, Iteration: 25600, Loss: 0.8241019993563422\n",
      "Epoch: 68, Iteration: 27200, Loss: 0.7927795147570198\n",
      "Epoch: 68, Iteration: 28800, Loss: 0.4678689477203268\n",
      "Epoch: 68, Iteration: 30400, Loss: 0.7175553552707554\n",
      "Epoch: 68, Iteration: 32000, Loss: 0.6182320833350607\n",
      "Epoch: 68, Iteration: 33600, Loss: 0.6160629687881494\n",
      "Epoch: 68, Iteration: 35200, Loss: 0.7791065701440467\n",
      "Epoch: 68, Iteration: 36800, Loss: 0.822527659325565\n",
      "Epoch: 68, Iteration: 38400, Loss: 0.5373555739889575\n",
      "Epoch: 68, Iteration: 40000, Loss: 0.717485816266358\n",
      "Epoch: 68, Iteration: 41600, Loss: 0.8348993890018623\n",
      "Epoch: 68, Iteration: 43200, Loss: 0.6545859993016494\n",
      "Epoch: 68, Iteration: 44800, Loss: 0.658046211605426\n",
      "Epoch: 68, Iteration: 46400, Loss: 0.8042687270697431\n",
      "Epoch: 68, Iteration: 48000, Loss: 0.6639955211255554\n",
      "Epoch: 68, Iteration: 49600, Loss: 0.84676953372674\n",
      "Epoch: 68, Iteration: 51200, Loss: 0.5049516133033463\n",
      "Epoch: 68, Iteration: 52800, Loss: 0.9120988993359224\n",
      "Epoch: 68, Iteration: 54400, Loss: 0.8812773080868179\n",
      "Epoch: 68, Iteration: 56000, Loss: 0.5351295996286038\n",
      "Epoch: 68, Iteration: 57600, Loss: 0.7392344549531596\n",
      "Epoch: 68, Iteration: 59200, Loss: 0.6922716241645748\n",
      "Epoch: 68, Iteration: 60800, Loss: 0.889022002221323\n",
      "Epoch: 68, Iteration: 62400, Loss: 0.7055851617593067\n",
      "Epoch: 69, Iteration: 0, Loss: 0.5478824128384043\n",
      "Epoch: 69, Iteration: 1600, Loss: 0.6237791772095324\n",
      "Epoch: 69, Iteration: 3200, Loss: 0.6275081311567376\n",
      "Epoch: 69, Iteration: 4800, Loss: 0.6424950416787514\n",
      "Epoch: 69, Iteration: 6400, Loss: 0.7164424743598349\n",
      "Epoch: 69, Iteration: 8000, Loss: 0.6924129695682044\n",
      "Epoch: 69, Iteration: 9600, Loss: 0.6166023869434197\n",
      "Epoch: 69, Iteration: 11200, Loss: 0.7784466024421461\n",
      "Epoch: 69, Iteration: 12800, Loss: 0.7457140675635231\n",
      "Epoch: 69, Iteration: 14400, Loss: 0.6082089052072486\n",
      "Epoch: 69, Iteration: 16000, Loss: 0.6529685751962846\n",
      "Epoch: 69, Iteration: 17600, Loss: 0.6862442735548286\n",
      "Epoch: 69, Iteration: 19200, Loss: 0.71641200930472\n",
      "Epoch: 69, Iteration: 20800, Loss: 0.7341273975926358\n",
      "Epoch: 69, Iteration: 22400, Loss: 0.8263379524116459\n",
      "Epoch: 69, Iteration: 24000, Loss: 0.564159458527568\n",
      "Epoch: 69, Iteration: 25600, Loss: 0.8169709823560231\n",
      "Epoch: 69, Iteration: 27200, Loss: 0.7986080915483963\n",
      "Epoch: 69, Iteration: 28800, Loss: 0.46075130840760387\n",
      "Epoch: 69, Iteration: 30400, Loss: 0.71271631632629\n",
      "Epoch: 69, Iteration: 32000, Loss: 0.6093846142215174\n",
      "Epoch: 69, Iteration: 33600, Loss: 0.5989243001852328\n",
      "Epoch: 69, Iteration: 35200, Loss: 0.7738341839338283\n",
      "Epoch: 69, Iteration: 36800, Loss: 0.8130575974908444\n",
      "Epoch: 69, Iteration: 38400, Loss: 0.535052292854687\n",
      "Epoch: 69, Iteration: 40000, Loss: 0.7107935705692303\n",
      "Epoch: 69, Iteration: 41600, Loss: 0.8269492007166291\n",
      "Epoch: 69, Iteration: 43200, Loss: 0.6439206909866169\n",
      "Epoch: 69, Iteration: 44800, Loss: 0.6596177762246486\n",
      "Epoch: 69, Iteration: 46400, Loss: 0.8008007475040256\n",
      "Epoch: 69, Iteration: 48000, Loss: 0.642901214178295\n",
      "Epoch: 69, Iteration: 49600, Loss: 0.8473636970159131\n",
      "Epoch: 69, Iteration: 51200, Loss: 0.4998979560664238\n",
      "Epoch: 69, Iteration: 52800, Loss: 0.9042899301556263\n",
      "Epoch: 69, Iteration: 54400, Loss: 0.8687311439234333\n",
      "Epoch: 69, Iteration: 56000, Loss: 0.5312848702842932\n",
      "Epoch: 69, Iteration: 57600, Loss: 0.7393663353176809\n",
      "Epoch: 69, Iteration: 59200, Loss: 0.6845617068614629\n",
      "Epoch: 69, Iteration: 60800, Loss: 0.8884821908201757\n",
      "Epoch: 69, Iteration: 62400, Loss: 0.7005871920396691\n",
      "Epoch: 70, Iteration: 0, Loss: 0.5416496362856076\n",
      "Epoch: 70, Iteration: 1600, Loss: 0.6194737164955981\n",
      "Epoch: 70, Iteration: 3200, Loss: 0.62645971227101\n",
      "Epoch: 70, Iteration: 4800, Loss: 0.6295654263869492\n",
      "Epoch: 70, Iteration: 6400, Loss: 0.7120414203028504\n",
      "Epoch: 70, Iteration: 8000, Loss: 0.7004577033869266\n",
      "Epoch: 70, Iteration: 9600, Loss: 0.6164548629088791\n",
      "Epoch: 70, Iteration: 11200, Loss: 0.777884597494088\n",
      "Epoch: 70, Iteration: 12800, Loss: 0.7405160937277606\n",
      "Epoch: 70, Iteration: 14400, Loss: 0.5936769857949891\n",
      "Epoch: 70, Iteration: 16000, Loss: 0.6361084563450496\n",
      "Epoch: 70, Iteration: 17600, Loss: 0.6854928792436152\n",
      "Epoch: 70, Iteration: 19200, Loss: 0.7303679120469662\n",
      "Epoch: 70, Iteration: 20800, Loss: 0.7264320249326914\n",
      "Epoch: 70, Iteration: 22400, Loss: 0.8276183578273761\n",
      "Epoch: 70, Iteration: 24000, Loss: 0.5592623515910806\n",
      "Epoch: 70, Iteration: 25600, Loss: 0.8083402534950614\n",
      "Epoch: 70, Iteration: 27200, Loss: 0.8009427012604733\n",
      "Epoch: 70, Iteration: 28800, Loss: 0.45482038314920725\n",
      "Epoch: 70, Iteration: 30400, Loss: 0.7076437359371431\n",
      "Epoch: 70, Iteration: 32000, Loss: 0.5995644438455369\n",
      "Epoch: 70, Iteration: 33600, Loss: 0.584441186867486\n",
      "Epoch: 70, Iteration: 35200, Loss: 0.7667761513311808\n",
      "Epoch: 70, Iteration: 36800, Loss: 0.8051062820525682\n",
      "Epoch: 70, Iteration: 38400, Loss: 0.5335807913371435\n",
      "Epoch: 70, Iteration: 40000, Loss: 0.7036015641991014\n",
      "Epoch: 70, Iteration: 41600, Loss: 0.8152970011118919\n",
      "Epoch: 70, Iteration: 43200, Loss: 0.6352373208098046\n",
      "Epoch: 70, Iteration: 44800, Loss: 0.6621746309310186\n",
      "Epoch: 70, Iteration: 46400, Loss: 0.7981438624967019\n",
      "Epoch: 70, Iteration: 48000, Loss: 0.6229743062437383\n",
      "Epoch: 70, Iteration: 49600, Loss: 0.8489120001086001\n",
      "Epoch: 70, Iteration: 51200, Loss: 0.4924207545694722\n",
      "Epoch: 70, Iteration: 52800, Loss: 0.8979985683602828\n",
      "Epoch: 70, Iteration: 54400, Loss: 0.85711293275981\n",
      "Epoch: 70, Iteration: 56000, Loss: 0.52675999394039\n",
      "Epoch: 70, Iteration: 57600, Loss: 0.7355320201551186\n",
      "Epoch: 70, Iteration: 59200, Loss: 0.6744844992860106\n",
      "Epoch: 70, Iteration: 60800, Loss: 0.8867138522163194\n",
      "Epoch: 70, Iteration: 62400, Loss: 0.6984574113036197\n",
      "Epoch: 71, Iteration: 0, Loss: 0.5357778151045034\n",
      "Epoch: 71, Iteration: 1600, Loss: 0.6132148910012307\n",
      "Epoch: 71, Iteration: 3200, Loss: 0.6222219401549666\n",
      "Epoch: 71, Iteration: 4800, Loss: 0.6136444885609607\n",
      "Epoch: 71, Iteration: 6400, Loss: 0.7041935643689003\n",
      "Epoch: 71, Iteration: 8000, Loss: 0.7082832637233503\n",
      "Epoch: 71, Iteration: 9600, Loss: 0.6141360414873723\n",
      "Epoch: 71, Iteration: 11200, Loss: 0.7767440916670649\n",
      "Epoch: 71, Iteration: 12800, Loss: 0.7353211389980605\n",
      "Epoch: 71, Iteration: 14400, Loss: 0.5801320251542996\n",
      "Epoch: 71, Iteration: 16000, Loss: 0.6206880203470464\n",
      "Epoch: 71, Iteration: 17600, Loss: 0.6858741423704569\n",
      "Epoch: 71, Iteration: 19200, Loss: 0.7417475113294145\n",
      "Epoch: 71, Iteration: 20800, Loss: 0.7190267942061698\n",
      "Epoch: 71, Iteration: 22400, Loss: 0.8250066504964094\n",
      "Epoch: 71, Iteration: 24000, Loss: 0.555835916386455\n",
      "Epoch: 71, Iteration: 25600, Loss: 0.7993509227797385\n",
      "Epoch: 71, Iteration: 27200, Loss: 0.800109109960058\n",
      "Epoch: 71, Iteration: 28800, Loss: 0.45015686108043784\n",
      "Epoch: 71, Iteration: 30400, Loss: 0.7022559768609336\n",
      "Epoch: 71, Iteration: 32000, Loss: 0.5902897457117986\n",
      "Epoch: 71, Iteration: 33600, Loss: 0.5724491884686986\n",
      "Epoch: 71, Iteration: 35200, Loss: 0.7586394238714792\n",
      "Epoch: 71, Iteration: 36800, Loss: 0.7978937920885307\n",
      "Epoch: 71, Iteration: 38400, Loss: 0.5329660848810625\n",
      "Epoch: 71, Iteration: 40000, Loss: 0.6970955532967815\n",
      "Epoch: 71, Iteration: 41600, Loss: 0.8025141218628529\n",
      "Epoch: 71, Iteration: 43200, Loss: 0.6277615181359129\n",
      "Epoch: 71, Iteration: 44800, Loss: 0.6648923265760618\n",
      "Epoch: 71, Iteration: 46400, Loss: 0.7943369869124499\n",
      "Epoch: 71, Iteration: 48000, Loss: 0.6044473398877646\n",
      "Epoch: 71, Iteration: 49600, Loss: 0.8513174891760852\n",
      "Epoch: 71, Iteration: 51200, Loss: 0.484468540471767\n",
      "Epoch: 71, Iteration: 52800, Loss: 0.8929932251064235\n",
      "Epoch: 71, Iteration: 54400, Loss: 0.846888509677039\n",
      "Epoch: 71, Iteration: 56000, Loss: 0.5230886064515873\n",
      "Epoch: 71, Iteration: 57600, Loss: 0.7298850203677847\n",
      "Epoch: 71, Iteration: 59200, Loss: 0.6641379252927823\n",
      "Epoch: 71, Iteration: 60800, Loss: 0.8833727808604881\n",
      "Epoch: 71, Iteration: 62400, Loss: 0.699492012081504\n",
      "Epoch: 72, Iteration: 0, Loss: 0.5303083000606821\n",
      "Epoch: 72, Iteration: 1600, Loss: 0.6054423160304729\n",
      "Epoch: 72, Iteration: 3200, Loss: 0.6159442656994039\n",
      "Epoch: 72, Iteration: 4800, Loss: 0.5957164661233199\n",
      "Epoch: 72, Iteration: 6400, Loss: 0.6955273216412263\n",
      "Epoch: 72, Iteration: 8000, Loss: 0.7162823170884243\n",
      "Epoch: 72, Iteration: 9600, Loss: 0.6118532285703515\n",
      "Epoch: 72, Iteration: 11200, Loss: 0.774779547360114\n",
      "Epoch: 72, Iteration: 12800, Loss: 0.7310328333462488\n",
      "Epoch: 72, Iteration: 14400, Loss: 0.5675130781447457\n",
      "Epoch: 72, Iteration: 16000, Loss: 0.6066528659124366\n",
      "Epoch: 72, Iteration: 17600, Loss: 0.6867864047942186\n",
      "Epoch: 72, Iteration: 19200, Loss: 0.7507282599684434\n",
      "Epoch: 72, Iteration: 20800, Loss: 0.7123717051583451\n",
      "Epoch: 72, Iteration: 22400, Loss: 0.8215476293911861\n",
      "Epoch: 72, Iteration: 24000, Loss: 0.5542612601900543\n",
      "Epoch: 72, Iteration: 25600, Loss: 0.7903157228755775\n",
      "Epoch: 72, Iteration: 27200, Loss: 0.7965397804840174\n",
      "Epoch: 72, Iteration: 28800, Loss: 0.4464765661362839\n",
      "Epoch: 72, Iteration: 30400, Loss: 0.6970664717121098\n",
      "Epoch: 72, Iteration: 32000, Loss: 0.5817254239268056\n",
      "Epoch: 72, Iteration: 33600, Loss: 0.5624833813458455\n",
      "Epoch: 72, Iteration: 35200, Loss: 0.7501226643104015\n",
      "Epoch: 72, Iteration: 36800, Loss: 0.7912284449111975\n",
      "Epoch: 72, Iteration: 38400, Loss: 0.5338190348497545\n",
      "Epoch: 72, Iteration: 40000, Loss: 0.6920909293198941\n",
      "Epoch: 72, Iteration: 41600, Loss: 0.790018678383261\n",
      "Epoch: 72, Iteration: 43200, Loss: 0.6212560333837462\n",
      "Epoch: 72, Iteration: 44800, Loss: 0.6676649975446576\n",
      "Epoch: 72, Iteration: 46400, Loss: 0.7892368092949155\n",
      "Epoch: 72, Iteration: 48000, Loss: 0.5877845382544871\n",
      "Epoch: 72, Iteration: 49600, Loss: 0.8544353063849904\n",
      "Epoch: 72, Iteration: 51200, Loss: 0.4774834703280094\n",
      "Epoch: 72, Iteration: 52800, Loss: 0.8890596364046011\n",
      "Epoch: 72, Iteration: 54400, Loss: 0.8381486749249909\n",
      "Epoch: 72, Iteration: 56000, Loss: 0.5209383406316566\n",
      "Epoch: 72, Iteration: 57600, Loss: 0.7231859601336308\n",
      "Epoch: 72, Iteration: 59200, Loss: 0.6548687946545472\n",
      "Epoch: 72, Iteration: 60800, Loss: 0.8774485122174148\n",
      "Epoch: 72, Iteration: 62400, Loss: 0.7036872157643597\n",
      "Epoch: 73, Iteration: 0, Loss: 0.525841506562227\n",
      "Epoch: 73, Iteration: 1600, Loss: 0.596589805385255\n",
      "Epoch: 73, Iteration: 3200, Loss: 0.6074811694623432\n",
      "Epoch: 73, Iteration: 4800, Loss: 0.5763453779554328\n",
      "Epoch: 73, Iteration: 6400, Loss: 0.6872702512212017\n",
      "Epoch: 73, Iteration: 8000, Loss: 0.7245352086602975\n",
      "Epoch: 73, Iteration: 9600, Loss: 0.6099682142302962\n",
      "Epoch: 73, Iteration: 11200, Loss: 0.7717778934770757\n",
      "Epoch: 73, Iteration: 12800, Loss: 0.7281978347937782\n",
      "Epoch: 73, Iteration: 14400, Loss: 0.5561546977044327\n",
      "Epoch: 73, Iteration: 16000, Loss: 0.5938783008444105\n",
      "Epoch: 73, Iteration: 17600, Loss: 0.6875558187814556\n",
      "Epoch: 73, Iteration: 19200, Loss: 0.7573199491533518\n",
      "Epoch: 73, Iteration: 20800, Loss: 0.7066068632023412\n",
      "Epoch: 73, Iteration: 22400, Loss: 0.819126843907268\n",
      "Epoch: 73, Iteration: 24000, Loss: 0.5546320499886395\n",
      "Epoch: 73, Iteration: 25600, Loss: 0.7809525274832315\n",
      "Epoch: 73, Iteration: 27200, Loss: 0.7902825338467658\n",
      "Epoch: 73, Iteration: 28800, Loss: 0.4437581776670843\n",
      "Epoch: 73, Iteration: 30400, Loss: 0.6922669448034399\n",
      "Epoch: 73, Iteration: 32000, Loss: 0.5735661026831449\n",
      "Epoch: 73, Iteration: 33600, Loss: 0.5543992449440289\n",
      "Epoch: 73, Iteration: 35200, Loss: 0.7420112538713044\n",
      "Epoch: 73, Iteration: 36800, Loss: 0.7853795504177243\n",
      "Epoch: 73, Iteration: 38400, Loss: 0.5370564880213324\n",
      "Epoch: 73, Iteration: 40000, Loss: 0.6891111891209664\n",
      "Epoch: 73, Iteration: 41600, Loss: 0.7794014586366735\n",
      "Epoch: 73, Iteration: 43200, Loss: 0.616272836444579\n",
      "Epoch: 73, Iteration: 44800, Loss: 0.6706341962549497\n",
      "Epoch: 73, Iteration: 46400, Loss: 0.7831078558440829\n",
      "Epoch: 73, Iteration: 48000, Loss: 0.5738510148615099\n",
      "Epoch: 73, Iteration: 49600, Loss: 0.8578484241554349\n",
      "Epoch: 73, Iteration: 51200, Loss: 0.4730967851408014\n",
      "Epoch: 73, Iteration: 52800, Loss: 0.8854012916779124\n",
      "Epoch: 73, Iteration: 54400, Loss: 0.8314021726276795\n",
      "Epoch: 73, Iteration: 56000, Loss: 0.5206158131790868\n",
      "Epoch: 73, Iteration: 57600, Loss: 0.7156057355676823\n",
      "Epoch: 73, Iteration: 59200, Loss: 0.6485136072198028\n",
      "Epoch: 73, Iteration: 60800, Loss: 0.8671296420482209\n",
      "Epoch: 73, Iteration: 62400, Loss: 0.7114212455311795\n",
      "Epoch: 74, Iteration: 0, Loss: 0.5227348220519662\n",
      "Epoch: 74, Iteration: 1600, Loss: 0.5867636874448414\n",
      "Epoch: 74, Iteration: 3200, Loss: 0.5959979315550344\n",
      "Epoch: 74, Iteration: 4800, Loss: 0.5560141193159611\n",
      "Epoch: 74, Iteration: 6400, Loss: 0.6809359442858897\n",
      "Epoch: 74, Iteration: 8000, Loss: 0.7326234414035137\n",
      "Epoch: 74, Iteration: 9600, Loss: 0.6083011049178675\n",
      "Epoch: 74, Iteration: 11200, Loss: 0.767571197865652\n",
      "Epoch: 74, Iteration: 12800, Loss: 0.7284281971908387\n",
      "Epoch: 74, Iteration: 14400, Loss: 0.5473560922175407\n",
      "Epoch: 74, Iteration: 16000, Loss: 0.5826647778707275\n",
      "Epoch: 74, Iteration: 17600, Loss: 0.687871405199635\n",
      "Epoch: 74, Iteration: 19200, Loss: 0.7617808690192438\n",
      "Epoch: 74, Iteration: 20800, Loss: 0.7016061091880816\n",
      "Epoch: 74, Iteration: 22400, Loss: 0.8188406330307181\n",
      "Epoch: 74, Iteration: 24000, Loss: 0.5573719279646192\n",
      "Epoch: 74, Iteration: 25600, Loss: 0.7712671392716304\n",
      "Epoch: 74, Iteration: 27200, Loss: 0.7818522847498065\n",
      "Epoch: 74, Iteration: 28800, Loss: 0.44292448643652277\n",
      "Epoch: 74, Iteration: 30400, Loss: 0.6878798616891968\n",
      "Epoch: 74, Iteration: 32000, Loss: 0.5655399552383582\n",
      "Epoch: 74, Iteration: 33600, Loss: 0.5487653828330931\n",
      "Epoch: 74, Iteration: 35200, Loss: 0.7360748602123646\n",
      "Epoch: 74, Iteration: 36800, Loss: 0.7819190107077194\n",
      "Epoch: 74, Iteration: 38400, Loss: 0.5443685205709761\n",
      "Epoch: 74, Iteration: 40000, Loss: 0.6895027523384488\n",
      "Epoch: 74, Iteration: 41600, Loss: 0.7732695634979807\n",
      "Epoch: 74, Iteration: 43200, Loss: 0.6142637334898212\n",
      "Epoch: 74, Iteration: 44800, Loss: 0.6741630976008495\n",
      "Epoch: 74, Iteration: 46400, Loss: 0.7764141527530732\n",
      "Epoch: 74, Iteration: 48000, Loss: 0.5650859841198369\n",
      "Epoch: 74, Iteration: 49600, Loss: 0.8599273112257726\n",
      "Epoch: 74, Iteration: 51200, Loss: 0.47426647397992716\n",
      "Epoch: 74, Iteration: 52800, Loss: 0.8796533099694881\n",
      "Epoch: 74, Iteration: 54400, Loss: 0.8279113509381382\n",
      "Epoch: 74, Iteration: 56000, Loss: 0.522553151661625\n",
      "Epoch: 74, Iteration: 57600, Loss: 0.7090140500734876\n",
      "Epoch: 74, Iteration: 59200, Loss: 0.6493000972869938\n",
      "Epoch: 74, Iteration: 60800, Loss: 0.8486478820014249\n",
      "Epoch: 74, Iteration: 62400, Loss: 0.7246053621442656\n",
      "Epoch: 75, Iteration: 0, Loss: 0.5217014243071583\n",
      "Epoch: 75, Iteration: 1600, Loss: 0.5777836334775401\n",
      "Epoch: 75, Iteration: 3200, Loss: 0.5805281840393228\n",
      "Epoch: 75, Iteration: 4800, Loss: 0.5362935818142267\n",
      "Epoch: 75, Iteration: 6400, Loss: 0.6808329473785459\n",
      "Epoch: 75, Iteration: 8000, Loss: 0.7379184186593262\n",
      "Epoch: 75, Iteration: 9600, Loss: 0.6079177266040768\n",
      "Epoch: 75, Iteration: 11200, Loss: 0.7626246528906692\n",
      "Epoch: 75, Iteration: 12800, Loss: 0.7355042379260529\n",
      "Epoch: 75, Iteration: 14400, Loss: 0.5441192274070121\n",
      "Epoch: 75, Iteration: 16000, Loss: 0.5746436002232244\n",
      "Epoch: 75, Iteration: 17600, Loss: 0.6893240359285642\n",
      "Epoch: 75, Iteration: 19200, Loss: 0.765096268962431\n",
      "Epoch: 75, Iteration: 20800, Loss: 0.6977004691551842\n",
      "Epoch: 75, Iteration: 22400, Loss: 0.8215733473921719\n",
      "Epoch: 75, Iteration: 24000, Loss: 0.5646230558635055\n",
      "Epoch: 75, Iteration: 25600, Loss: 0.7637221393569358\n",
      "Epoch: 75, Iteration: 27200, Loss: 0.7747342413751318\n",
      "Epoch: 75, Iteration: 28800, Loss: 0.44706780756925835\n",
      "Epoch: 75, Iteration: 30400, Loss: 0.6837926108403662\n",
      "Epoch: 75, Iteration: 32000, Loss: 0.5581576570179803\n",
      "Epoch: 75, Iteration: 33600, Loss: 0.5477177301535906\n",
      "Epoch: 75, Iteration: 35200, Loss: 0.7362871218867857\n",
      "Epoch: 75, Iteration: 36800, Loss: 0.7874239199137744\n",
      "Epoch: 75, Iteration: 38400, Loss: 0.5571715404541936\n",
      "Epoch: 75, Iteration: 40000, Loss: 0.6978814753630671\n",
      "Epoch: 75, Iteration: 41600, Loss: 0.7768318113469233\n",
      "Epoch: 75, Iteration: 43200, Loss: 0.6178861670796167\n",
      "Epoch: 75, Iteration: 44800, Loss: 0.6802314157207653\n",
      "Epoch: 75, Iteration: 46400, Loss: 0.7699310519542668\n",
      "Epoch: 75, Iteration: 48000, Loss: 0.5677857235189264\n",
      "Epoch: 75, Iteration: 49600, Loss: 0.8591660944567414\n",
      "Epoch: 75, Iteration: 51200, Loss: 0.4872889485750661\n",
      "Epoch: 75, Iteration: 52800, Loss: 0.868771346487078\n",
      "Epoch: 75, Iteration: 54400, Loss: 0.8301658247357044\n",
      "Epoch: 75, Iteration: 56000, Loss: 0.5291806224296796\n",
      "Epoch: 75, Iteration: 57600, Loss: 0.713000496981258\n",
      "Epoch: 75, Iteration: 59200, Loss: 0.6674720308214479\n",
      "Epoch: 75, Iteration: 60800, Loss: 0.8204753517468129\n",
      "Epoch: 75, Iteration: 62400, Loss: 0.744665667735252\n",
      "Epoch: 76, Iteration: 0, Loss: 0.5263855838411521\n",
      "Epoch: 76, Iteration: 1600, Loss: 0.5822631119348765\n",
      "Epoch: 76, Iteration: 3200, Loss: 0.5670215025973363\n",
      "Epoch: 76, Iteration: 4800, Loss: 0.5277446835083179\n",
      "Epoch: 76, Iteration: 6400, Loss: 0.690816707654107\n",
      "Epoch: 76, Iteration: 8000, Loss: 0.736345340467205\n",
      "Epoch: 76, Iteration: 9600, Loss: 0.6147403860405081\n",
      "Epoch: 76, Iteration: 11200, Loss: 0.7574897198360384\n",
      "Epoch: 76, Iteration: 12800, Loss: 0.7458058027354731\n",
      "Epoch: 76, Iteration: 14400, Loss: 0.5483465117177151\n",
      "Epoch: 76, Iteration: 16000, Loss: 0.5734243084172062\n",
      "Epoch: 76, Iteration: 17600, Loss: 0.7034734718813367\n",
      "Epoch: 76, Iteration: 19200, Loss: 0.7650610856306321\n",
      "Epoch: 76, Iteration: 20800, Loss: 0.7046697095581668\n",
      "Epoch: 76, Iteration: 22400, Loss: 0.8276386493745216\n",
      "Epoch: 76, Iteration: 24000, Loss: 0.5788535928206873\n",
      "Epoch: 76, Iteration: 25600, Loss: 0.7691609423696075\n",
      "Epoch: 76, Iteration: 27200, Loss: 0.7829443676665657\n",
      "Epoch: 76, Iteration: 28800, Loss: 0.45763477170618483\n",
      "Epoch: 76, Iteration: 30400, Loss: 0.6876244318853799\n",
      "Epoch: 76, Iteration: 32000, Loss: 0.5566184900912461\n",
      "Epoch: 76, Iteration: 33600, Loss: 0.5537671417565843\n",
      "Epoch: 76, Iteration: 35200, Loss: 0.7417706678282507\n",
      "Epoch: 76, Iteration: 36800, Loss: 0.8206177419982827\n",
      "Epoch: 76, Iteration: 38400, Loss: 0.5640049448047838\n",
      "Epoch: 76, Iteration: 40000, Loss: 0.7135217762046796\n",
      "Epoch: 76, Iteration: 41600, Loss: 0.7933357009215463\n",
      "Epoch: 76, Iteration: 43200, Loss: 0.620964229574562\n",
      "Epoch: 76, Iteration: 44800, Loss: 0.6888526353265783\n",
      "Epoch: 76, Iteration: 46400, Loss: 0.7684031584727271\n",
      "Epoch: 76, Iteration: 48000, Loss: 0.596872296466943\n",
      "Epoch: 76, Iteration: 49600, Loss: 0.8669891874082234\n",
      "Epoch: 76, Iteration: 51200, Loss: 0.5124381391849029\n",
      "Epoch: 76, Iteration: 52800, Loss: 0.8626744226076805\n",
      "Epoch: 76, Iteration: 54400, Loss: 0.8372131617132723\n",
      "Epoch: 76, Iteration: 56000, Loss: 0.5504641021682484\n",
      "Epoch: 76, Iteration: 57600, Loss: 0.7314086176452028\n",
      "Epoch: 76, Iteration: 59200, Loss: 0.7031501695151298\n",
      "Epoch: 76, Iteration: 60800, Loss: 0.8034172140325166\n",
      "Epoch: 76, Iteration: 62400, Loss: 0.7516985490349581\n",
      "Epoch: 77, Iteration: 0, Loss: 0.5338534329368176\n",
      "Epoch: 77, Iteration: 1600, Loss: 0.6037763163633848\n",
      "Epoch: 77, Iteration: 3200, Loss: 0.5730008910662981\n",
      "Epoch: 77, Iteration: 4800, Loss: 0.5513960100714503\n",
      "Epoch: 77, Iteration: 6400, Loss: 0.6835859654772831\n",
      "Epoch: 77, Iteration: 8000, Loss: 0.7403537032640487\n",
      "Epoch: 77, Iteration: 9600, Loss: 0.6319898479934792\n",
      "Epoch: 77, Iteration: 11200, Loss: 0.754099603522641\n",
      "Epoch: 77, Iteration: 12800, Loss: 0.7289679820735216\n",
      "Epoch: 77, Iteration: 14400, Loss: 0.5526322322012995\n",
      "Epoch: 77, Iteration: 16000, Loss: 0.5823214555506033\n",
      "Epoch: 77, Iteration: 17600, Loss: 0.7262505201141147\n",
      "Epoch: 77, Iteration: 19200, Loss: 0.7453936700895527\n",
      "Epoch: 77, Iteration: 20800, Loss: 0.7379706548228093\n",
      "Epoch: 77, Iteration: 22400, Loss: 0.8379254914624807\n",
      "Epoch: 77, Iteration: 24000, Loss: 0.5807187610387634\n",
      "Epoch: 77, Iteration: 25600, Loss: 0.7859881295090548\n",
      "Epoch: 77, Iteration: 27200, Loss: 0.7998088144095317\n",
      "Epoch: 77, Iteration: 28800, Loss: 0.46253668701834727\n",
      "Epoch: 77, Iteration: 30400, Loss: 0.7076611015389357\n",
      "Epoch: 77, Iteration: 32000, Loss: 0.5529792998132013\n",
      "Epoch: 77, Iteration: 33600, Loss: 0.5624917168245476\n",
      "Epoch: 77, Iteration: 35200, Loss: 0.7422519233132773\n",
      "Epoch: 77, Iteration: 36800, Loss: 0.8509458822144276\n",
      "Epoch: 77, Iteration: 38400, Loss: 0.5553659529192796\n",
      "Epoch: 77, Iteration: 40000, Loss: 0.7290112158778516\n",
      "Epoch: 77, Iteration: 41600, Loss: 0.80856441094267\n",
      "Epoch: 77, Iteration: 43200, Loss: 0.6118466190433669\n",
      "Epoch: 77, Iteration: 44800, Loss: 0.6804941302804169\n",
      "Epoch: 77, Iteration: 46400, Loss: 0.7664398902820702\n",
      "Epoch: 77, Iteration: 48000, Loss: 0.6362853584161905\n",
      "Epoch: 77, Iteration: 49600, Loss: 0.8859824103773564\n",
      "Epoch: 77, Iteration: 51200, Loss: 0.5319528842681756\n",
      "Epoch: 77, Iteration: 52800, Loss: 0.8607506973199514\n",
      "Epoch: 77, Iteration: 54400, Loss: 0.8309105335193363\n",
      "Epoch: 77, Iteration: 56000, Loss: 0.566316762524731\n",
      "Epoch: 77, Iteration: 57600, Loss: 0.730219026300244\n",
      "Epoch: 77, Iteration: 59200, Loss: 0.722632613096712\n",
      "Epoch: 77, Iteration: 60800, Loss: 0.8007130058226314\n",
      "Epoch: 77, Iteration: 62400, Loss: 0.7588540646467583\n",
      "Epoch: 78, Iteration: 0, Loss: 0.5371279857802765\n",
      "Epoch: 78, Iteration: 1600, Loss: 0.6139029000246387\n",
      "Epoch: 78, Iteration: 3200, Loss: 0.5723220350468132\n",
      "Epoch: 78, Iteration: 4800, Loss: 0.5681725095499746\n",
      "Epoch: 78, Iteration: 6400, Loss: 0.6827997930919727\n",
      "Epoch: 78, Iteration: 8000, Loss: 0.7564808060815211\n",
      "Epoch: 78, Iteration: 9600, Loss: 0.6453681714974355\n",
      "Epoch: 78, Iteration: 11200, Loss: 0.7596045556072193\n",
      "Epoch: 78, Iteration: 12800, Loss: 0.719627167514673\n",
      "Epoch: 78, Iteration: 14400, Loss: 0.5520901281760622\n",
      "Epoch: 78, Iteration: 16000, Loss: 0.5923274556793476\n",
      "Epoch: 78, Iteration: 17600, Loss: 0.7223734673621786\n",
      "Epoch: 78, Iteration: 19200, Loss: 0.735053959642325\n",
      "Epoch: 78, Iteration: 20800, Loss: 0.7471385517324322\n",
      "Epoch: 78, Iteration: 22400, Loss: 0.8425759146634579\n",
      "Epoch: 78, Iteration: 24000, Loss: 0.5768487443843922\n",
      "Epoch: 78, Iteration: 25600, Loss: 0.7986755158828098\n",
      "Epoch: 78, Iteration: 27200, Loss: 0.799601419046665\n",
      "Epoch: 78, Iteration: 28800, Loss: 0.4603156103566192\n",
      "Epoch: 78, Iteration: 30400, Loss: 0.7094937806691717\n",
      "Epoch: 78, Iteration: 32000, Loss: 0.5414676891159529\n",
      "Epoch: 78, Iteration: 33600, Loss: 0.5725027463028669\n",
      "Epoch: 78, Iteration: 35200, Loss: 0.7323863377554523\n",
      "Epoch: 78, Iteration: 36800, Loss: 0.853151965667728\n",
      "Epoch: 78, Iteration: 38400, Loss: 0.556700831063381\n",
      "Epoch: 78, Iteration: 40000, Loss: 0.7366949619054172\n",
      "Epoch: 78, Iteration: 41600, Loss: 0.8134509438602732\n",
      "Epoch: 78, Iteration: 43200, Loss: 0.6132054828831663\n",
      "Epoch: 78, Iteration: 44800, Loss: 0.6659424494943437\n",
      "Epoch: 78, Iteration: 46400, Loss: 0.774197329521543\n",
      "Epoch: 78, Iteration: 48000, Loss: 0.6454288567356801\n",
      "Epoch: 78, Iteration: 49600, Loss: 0.8967577749820295\n",
      "Epoch: 78, Iteration: 51200, Loss: 0.5470332720882516\n",
      "Epoch: 78, Iteration: 52800, Loss: 0.8648673601351758\n",
      "Epoch: 78, Iteration: 54400, Loss: 0.8145080073380843\n",
      "Epoch: 78, Iteration: 56000, Loss: 0.5698568191623744\n",
      "Epoch: 78, Iteration: 57600, Loss: 0.7340028723128844\n",
      "Epoch: 78, Iteration: 59200, Loss: 0.7290965023078415\n",
      "Epoch: 78, Iteration: 60800, Loss: 0.8049638879979307\n",
      "Epoch: 78, Iteration: 62400, Loss: 0.766303931556616\n",
      "Epoch: 79, Iteration: 0, Loss: 0.5404468576003462\n",
      "Epoch: 79, Iteration: 1600, Loss: 0.6276295860963228\n",
      "Epoch: 79, Iteration: 3200, Loss: 0.5678573959020201\n",
      "Epoch: 79, Iteration: 4800, Loss: 0.5717312975091493\n",
      "Epoch: 79, Iteration: 6400, Loss: 0.6778146611966631\n",
      "Epoch: 79, Iteration: 8000, Loss: 0.7765766781477684\n",
      "Epoch: 79, Iteration: 9600, Loss: 0.6522201964226069\n",
      "Epoch: 79, Iteration: 11200, Loss: 0.7577840055666356\n",
      "Epoch: 79, Iteration: 12800, Loss: 0.7186558428704094\n",
      "Epoch: 79, Iteration: 14400, Loss: 0.5466287411033238\n",
      "Epoch: 79, Iteration: 16000, Loss: 0.592665703776654\n",
      "Epoch: 79, Iteration: 17600, Loss: 0.7245555652462187\n",
      "Epoch: 79, Iteration: 19200, Loss: 0.7295572450830656\n",
      "Epoch: 79, Iteration: 20800, Loss: 0.7449998727574746\n",
      "Epoch: 79, Iteration: 22400, Loss: 0.8461274811230013\n",
      "Epoch: 79, Iteration: 24000, Loss: 0.5797950783365032\n",
      "Epoch: 79, Iteration: 25600, Loss: 0.8055073030152273\n",
      "Epoch: 79, Iteration: 27200, Loss: 0.7899774961987758\n",
      "Epoch: 79, Iteration: 28800, Loss: 0.45318055376549693\n",
      "Epoch: 79, Iteration: 30400, Loss: 0.7019169590516584\n",
      "Epoch: 79, Iteration: 32000, Loss: 0.5347783028641814\n",
      "Epoch: 79, Iteration: 33600, Loss: 0.5904370207805457\n",
      "Epoch: 79, Iteration: 35200, Loss: 0.7239429935947561\n",
      "Epoch: 79, Iteration: 36800, Loss: 0.8494108522108084\n",
      "Epoch: 79, Iteration: 38400, Loss: 0.5660628204233525\n",
      "Epoch: 79, Iteration: 40000, Loss: 0.7357059023596357\n",
      "Epoch: 79, Iteration: 41600, Loss: 0.8111542523310491\n",
      "Epoch: 79, Iteration: 43200, Loss: 0.6247972447240818\n",
      "Epoch: 79, Iteration: 44800, Loss: 0.6502620514038199\n",
      "Epoch: 79, Iteration: 46400, Loss: 0.7929660472306205\n",
      "Epoch: 79, Iteration: 48000, Loss: 0.6542401709773018\n",
      "Epoch: 79, Iteration: 49600, Loss: 0.9007295280731518\n",
      "Epoch: 79, Iteration: 51200, Loss: 0.5613102351556787\n",
      "Epoch: 79, Iteration: 52800, Loss: 0.8750463778440168\n",
      "Epoch: 79, Iteration: 54400, Loss: 0.8020934573652468\n",
      "Epoch: 79, Iteration: 56000, Loss: 0.5684807376107353\n",
      "Epoch: 79, Iteration: 57600, Loss: 0.7423592224779689\n",
      "Epoch: 79, Iteration: 59200, Loss: 0.7384578853540544\n",
      "Epoch: 79, Iteration: 60800, Loss: 0.8073099639457162\n",
      "Epoch: 79, Iteration: 62400, Loss: 0.7769849222306532\n",
      "Epoch: 80, Iteration: 0, Loss: 0.5356916317164604\n",
      "Epoch: 80, Iteration: 1600, Loss: 0.6498813105283163\n",
      "Epoch: 80, Iteration: 3200, Loss: 0.5631609757391625\n",
      "Epoch: 80, Iteration: 4800, Loss: 0.5759196449239627\n",
      "Epoch: 80, Iteration: 6400, Loss: 0.6707106654050983\n",
      "Epoch: 80, Iteration: 8000, Loss: 0.7973713075621377\n",
      "Epoch: 80, Iteration: 9600, Loss: 0.6624663951942985\n",
      "Epoch: 80, Iteration: 11200, Loss: 0.7565611074329318\n",
      "Epoch: 80, Iteration: 12800, Loss: 0.7201100096008556\n",
      "Epoch: 80, Iteration: 14400, Loss: 0.5370156352477624\n",
      "Epoch: 80, Iteration: 16000, Loss: 0.5902275130302543\n",
      "Epoch: 80, Iteration: 17600, Loss: 0.7383556370396431\n",
      "Epoch: 80, Iteration: 19200, Loss: 0.730868645722037\n",
      "Epoch: 80, Iteration: 20800, Loss: 0.7441415775427519\n",
      "Epoch: 80, Iteration: 22400, Loss: 0.8546303470844282\n",
      "Epoch: 80, Iteration: 24000, Loss: 0.591469479819972\n",
      "Epoch: 80, Iteration: 25600, Loss: 0.8097049866656134\n",
      "Epoch: 80, Iteration: 27200, Loss: 0.7784197533942594\n",
      "Epoch: 80, Iteration: 28800, Loss: 0.4446171571855906\n",
      "Epoch: 80, Iteration: 30400, Loss: 0.699304961651974\n",
      "Epoch: 80, Iteration: 32000, Loss: 0.5323535152306649\n",
      "Epoch: 80, Iteration: 33600, Loss: 0.603910340511703\n",
      "Epoch: 80, Iteration: 35200, Loss: 0.7155418587851159\n",
      "Epoch: 80, Iteration: 36800, Loss: 0.8441445524869495\n",
      "Epoch: 80, Iteration: 38400, Loss: 0.5723549435698445\n",
      "Epoch: 80, Iteration: 40000, Loss: 0.737233929545122\n",
      "Epoch: 80, Iteration: 41600, Loss: 0.8115056679169386\n",
      "Epoch: 80, Iteration: 43200, Loss: 0.6347728006009282\n",
      "Epoch: 80, Iteration: 44800, Loss: 0.6466348909370284\n",
      "Epoch: 80, Iteration: 46400, Loss: 0.8089361982202916\n",
      "Epoch: 80, Iteration: 48000, Loss: 0.6603320610727731\n",
      "Epoch: 80, Iteration: 49600, Loss: 0.9002304911251185\n",
      "Epoch: 80, Iteration: 51200, Loss: 0.5729382461264855\n",
      "Epoch: 80, Iteration: 52800, Loss: 0.889152413777797\n",
      "Epoch: 80, Iteration: 54400, Loss: 0.7896434774267158\n",
      "Epoch: 80, Iteration: 56000, Loss: 0.5724475271144873\n",
      "Epoch: 80, Iteration: 57600, Loss: 0.7481959314091194\n",
      "Epoch: 80, Iteration: 59200, Loss: 0.7427801245930787\n",
      "Epoch: 80, Iteration: 60800, Loss: 0.8050886944942507\n",
      "Epoch: 80, Iteration: 62400, Loss: 0.7866298375636401\n",
      "Epoch: 81, Iteration: 0, Loss: 0.534477896528859\n",
      "Epoch: 81, Iteration: 1600, Loss: 0.6704639014376574\n",
      "Epoch: 81, Iteration: 3200, Loss: 0.5595729828322464\n",
      "Epoch: 81, Iteration: 4800, Loss: 0.5782209781802694\n",
      "Epoch: 81, Iteration: 6400, Loss: 0.6650478266251388\n",
      "Epoch: 81, Iteration: 8000, Loss: 0.8108878454125719\n",
      "Epoch: 81, Iteration: 9600, Loss: 0.6701696378204305\n",
      "Epoch: 81, Iteration: 11200, Loss: 0.7630293782253699\n",
      "Epoch: 81, Iteration: 12800, Loss: 0.7213491758428185\n",
      "Epoch: 81, Iteration: 14400, Loss: 0.5298680045289786\n",
      "Epoch: 81, Iteration: 16000, Loss: 0.5912515173890469\n",
      "Epoch: 81, Iteration: 17600, Loss: 0.7540239161894073\n",
      "Epoch: 81, Iteration: 19200, Loss: 0.725831569556219\n",
      "Epoch: 81, Iteration: 20800, Loss: 0.744264667221833\n",
      "Epoch: 81, Iteration: 22400, Loss: 0.8588334128725063\n",
      "Epoch: 81, Iteration: 24000, Loss: 0.5952351735641587\n",
      "Epoch: 81, Iteration: 25600, Loss: 0.80733536155704\n",
      "Epoch: 81, Iteration: 27200, Loss: 0.76949423073685\n",
      "Epoch: 81, Iteration: 28800, Loss: 0.4478023248799072\n",
      "Epoch: 81, Iteration: 30400, Loss: 0.7009271950012255\n",
      "Epoch: 81, Iteration: 32000, Loss: 0.5317699842984067\n",
      "Epoch: 81, Iteration: 33600, Loss: 0.6092470286590449\n",
      "Epoch: 81, Iteration: 35200, Loss: 0.7079953116194986\n",
      "Epoch: 81, Iteration: 36800, Loss: 0.8330110206355894\n",
      "Epoch: 81, Iteration: 38400, Loss: 0.5704723610125034\n",
      "Epoch: 81, Iteration: 40000, Loss: 0.7439516794160244\n",
      "Epoch: 81, Iteration: 41600, Loss: 0.8190382987488931\n",
      "Epoch: 81, Iteration: 43200, Loss: 0.6353547395300356\n",
      "Epoch: 81, Iteration: 44800, Loss: 0.6517571771963102\n",
      "Epoch: 81, Iteration: 46400, Loss: 0.8198197581485636\n",
      "Epoch: 81, Iteration: 48000, Loss: 0.66469149490493\n",
      "Epoch: 81, Iteration: 49600, Loss: 0.8997569238974199\n",
      "Epoch: 81, Iteration: 51200, Loss: 0.5794983799804923\n",
      "Epoch: 81, Iteration: 52800, Loss: 0.9092865645904248\n",
      "Epoch: 81, Iteration: 54400, Loss: 0.7792396912932443\n",
      "Epoch: 81, Iteration: 56000, Loss: 0.579606097828858\n",
      "Epoch: 81, Iteration: 57600, Loss: 0.7486700251308622\n",
      "Epoch: 81, Iteration: 59200, Loss: 0.7437440881845998\n",
      "Epoch: 81, Iteration: 60800, Loss: 0.8025991791344188\n",
      "Epoch: 81, Iteration: 62400, Loss: 0.7887750147060564\n",
      "Epoch: 82, Iteration: 0, Loss: 0.5345925974997283\n",
      "Epoch: 82, Iteration: 1600, Loss: 0.6786674953922208\n",
      "Epoch: 82, Iteration: 3200, Loss: 0.5637443445874346\n",
      "Epoch: 82, Iteration: 4800, Loss: 0.5772282494843872\n",
      "Epoch: 82, Iteration: 6400, Loss: 0.6605238823481236\n",
      "Epoch: 82, Iteration: 8000, Loss: 0.8264281967405948\n",
      "Epoch: 82, Iteration: 9600, Loss: 0.6672132643583782\n",
      "Epoch: 82, Iteration: 11200, Loss: 0.7696364892628087\n",
      "Epoch: 82, Iteration: 12800, Loss: 0.726048397844815\n",
      "Epoch: 82, Iteration: 14400, Loss: 0.5258532187231539\n",
      "Epoch: 82, Iteration: 16000, Loss: 0.5871780185399843\n",
      "Epoch: 82, Iteration: 17600, Loss: 0.768726104757497\n",
      "Epoch: 82, Iteration: 19200, Loss: 0.7167326918117762\n",
      "Epoch: 82, Iteration: 20800, Loss: 0.7405573706344961\n",
      "Epoch: 82, Iteration: 22400, Loss: 0.8585545647906775\n",
      "Epoch: 82, Iteration: 24000, Loss: 0.5919617033178877\n",
      "Epoch: 82, Iteration: 25600, Loss: 0.8010263557285116\n",
      "Epoch: 82, Iteration: 27200, Loss: 0.7590501628130168\n",
      "Epoch: 82, Iteration: 28800, Loss: 0.4524942910406111\n",
      "Epoch: 82, Iteration: 30400, Loss: 0.6985732576742922\n",
      "Epoch: 82, Iteration: 32000, Loss: 0.5280258144062013\n",
      "Epoch: 82, Iteration: 33600, Loss: 0.6134169681423977\n",
      "Epoch: 82, Iteration: 35200, Loss: 0.6992723232555916\n",
      "Epoch: 82, Iteration: 36800, Loss: 0.8232710773170506\n",
      "Epoch: 82, Iteration: 38400, Loss: 0.568579599061259\n",
      "Epoch: 82, Iteration: 40000, Loss: 0.750288945129983\n",
      "Epoch: 82, Iteration: 41600, Loss: 0.8256016538700803\n",
      "Epoch: 82, Iteration: 43200, Loss: 0.6303916181786686\n",
      "Epoch: 82, Iteration: 44800, Loss: 0.6569360397673658\n",
      "Epoch: 82, Iteration: 46400, Loss: 0.822502397172789\n",
      "Epoch: 82, Iteration: 48000, Loss: 0.6580140742859261\n",
      "Epoch: 82, Iteration: 49600, Loss: 0.9022277218455346\n",
      "Epoch: 82, Iteration: 51200, Loss: 0.5792101249476657\n",
      "Epoch: 82, Iteration: 52800, Loss: 0.9153224156293303\n",
      "Epoch: 82, Iteration: 54400, Loss: 0.7736623021982085\n",
      "Epoch: 82, Iteration: 56000, Loss: 0.5850469052433602\n",
      "Epoch: 82, Iteration: 57600, Loss: 0.7481072985397406\n",
      "Epoch: 82, Iteration: 59200, Loss: 0.7430431470449101\n",
      "Epoch: 82, Iteration: 60800, Loss: 0.7978271540228011\n",
      "Epoch: 82, Iteration: 62400, Loss: 0.7818872517526925\n",
      "Epoch: 83, Iteration: 0, Loss: 0.5297228424742212\n",
      "Epoch: 83, Iteration: 1600, Loss: 0.6793832037030852\n",
      "Epoch: 83, Iteration: 3200, Loss: 0.5648017172858686\n",
      "Epoch: 83, Iteration: 4800, Loss: 0.5700823268107333\n",
      "Epoch: 83, Iteration: 6400, Loss: 0.6559251202485548\n",
      "Epoch: 83, Iteration: 8000, Loss: 0.8326031724371579\n",
      "Epoch: 83, Iteration: 9600, Loss: 0.6563374729048457\n",
      "Epoch: 83, Iteration: 11200, Loss: 0.7691403734584394\n",
      "Epoch: 83, Iteration: 12800, Loss: 0.726577888257103\n",
      "Epoch: 83, Iteration: 14400, Loss: 0.519510314846874\n",
      "Epoch: 83, Iteration: 16000, Loss: 0.5760511316212759\n",
      "Epoch: 83, Iteration: 17600, Loss: 0.7711023651431195\n",
      "Epoch: 83, Iteration: 19200, Loss: 0.70825181817124\n",
      "Epoch: 83, Iteration: 20800, Loss: 0.730835407275007\n",
      "Epoch: 83, Iteration: 22400, Loss: 0.8546017518731525\n",
      "Epoch: 83, Iteration: 24000, Loss: 0.589038220055766\n",
      "Epoch: 83, Iteration: 25600, Loss: 0.7923108423783064\n",
      "Epoch: 83, Iteration: 27200, Loss: 0.7450742330482729\n",
      "Epoch: 83, Iteration: 28800, Loss: 0.451978173143363\n",
      "Epoch: 83, Iteration: 30400, Loss: 0.6905102147769968\n",
      "Epoch: 83, Iteration: 32000, Loss: 0.5202088786371377\n",
      "Epoch: 83, Iteration: 33600, Loss: 0.613102456973551\n",
      "Epoch: 83, Iteration: 35200, Loss: 0.6885845808340023\n",
      "Epoch: 83, Iteration: 36800, Loss: 0.8146081983207097\n",
      "Epoch: 83, Iteration: 38400, Loss: 0.5636798667219638\n",
      "Epoch: 83, Iteration: 40000, Loss: 0.7510879718788855\n",
      "Epoch: 83, Iteration: 41600, Loss: 0.8308501837644198\n",
      "Epoch: 83, Iteration: 43200, Loss: 0.6223976631119406\n",
      "Epoch: 83, Iteration: 44800, Loss: 0.6572013387326091\n",
      "Epoch: 83, Iteration: 46400, Loss: 0.8187665917450078\n",
      "Epoch: 83, Iteration: 48000, Loss: 0.6468578914516587\n",
      "Epoch: 83, Iteration: 49600, Loss: 0.8989059753110196\n",
      "Epoch: 83, Iteration: 51200, Loss: 0.5754238960369922\n",
      "Epoch: 83, Iteration: 52800, Loss: 0.9107934040543856\n",
      "Epoch: 83, Iteration: 54400, Loss: 0.7687277259493798\n",
      "Epoch: 83, Iteration: 56000, Loss: 0.5876506004811091\n",
      "Epoch: 83, Iteration: 57600, Loss: 0.7457288705510442\n",
      "Epoch: 83, Iteration: 59200, Loss: 0.7402588077851346\n",
      "Epoch: 83, Iteration: 60800, Loss: 0.7889687009505582\n",
      "Epoch: 83, Iteration: 62400, Loss: 0.7714132661681333\n",
      "Epoch: 84, Iteration: 0, Loss: 0.5231054294216071\n",
      "Epoch: 84, Iteration: 1600, Loss: 0.6750277244847895\n",
      "Epoch: 84, Iteration: 3200, Loss: 0.5605927784302228\n",
      "Epoch: 84, Iteration: 4800, Loss: 0.5607871951481743\n",
      "Epoch: 84, Iteration: 6400, Loss: 0.6503099859872357\n",
      "Epoch: 84, Iteration: 8000, Loss: 0.8293997589993491\n",
      "Epoch: 84, Iteration: 9600, Loss: 0.6416117537116723\n",
      "Epoch: 84, Iteration: 11200, Loss: 0.767118300144822\n",
      "Epoch: 84, Iteration: 12800, Loss: 0.7241358502803611\n",
      "Epoch: 84, Iteration: 14400, Loss: 0.5115361299923921\n",
      "Epoch: 84, Iteration: 16000, Loss: 0.5620683699555269\n",
      "Epoch: 84, Iteration: 17600, Loss: 0.7644945195486996\n",
      "Epoch: 84, Iteration: 19200, Loss: 0.6988960122441271\n",
      "Epoch: 84, Iteration: 20800, Loss: 0.7193374950491354\n",
      "Epoch: 84, Iteration: 22400, Loss: 0.8484994146197633\n",
      "Epoch: 84, Iteration: 24000, Loss: 0.5866141110710976\n",
      "Epoch: 84, Iteration: 25600, Loss: 0.7821976866894849\n",
      "Epoch: 84, Iteration: 27200, Loss: 0.7304791291047282\n",
      "Epoch: 84, Iteration: 28800, Loss: 0.44923386531609943\n",
      "Epoch: 84, Iteration: 30400, Loss: 0.680028721263277\n",
      "Epoch: 84, Iteration: 32000, Loss: 0.5117009438352746\n",
      "Epoch: 84, Iteration: 33600, Loss: 0.6103136547919942\n",
      "Epoch: 84, Iteration: 35200, Loss: 0.6771311499239094\n",
      "Epoch: 84, Iteration: 36800, Loss: 0.8054760909831761\n",
      "Epoch: 84, Iteration: 38400, Loss: 0.5570494240927948\n",
      "Epoch: 84, Iteration: 40000, Loss: 0.7477730434763185\n",
      "Epoch: 84, Iteration: 41600, Loss: 0.836208086282507\n",
      "Epoch: 84, Iteration: 43200, Loss: 0.613395439557429\n",
      "Epoch: 84, Iteration: 44800, Loss: 0.6549065402340297\n",
      "Epoch: 84, Iteration: 46400, Loss: 0.8125486981471207\n",
      "Epoch: 84, Iteration: 48000, Loss: 0.635090105182645\n",
      "Epoch: 84, Iteration: 49600, Loss: 0.8916534912747562\n",
      "Epoch: 84, Iteration: 51200, Loss: 0.5717579137320898\n",
      "Epoch: 84, Iteration: 52800, Loss: 0.9039669719256647\n",
      "Epoch: 84, Iteration: 54400, Loss: 0.7646391625568918\n",
      "Epoch: 84, Iteration: 56000, Loss: 0.5873208072189191\n",
      "Epoch: 84, Iteration: 57600, Loss: 0.7430258566992789\n",
      "Epoch: 84, Iteration: 59200, Loss: 0.7368547838324067\n",
      "Epoch: 84, Iteration: 60800, Loss: 0.7771429611103192\n",
      "Epoch: 84, Iteration: 62400, Loss: 0.7600569993955528\n",
      "Epoch: 85, Iteration: 0, Loss: 0.5171360511895604\n",
      "Epoch: 85, Iteration: 1600, Loss: 0.6681948691170548\n",
      "Epoch: 85, Iteration: 3200, Loss: 0.5539665316259735\n",
      "Epoch: 85, Iteration: 4800, Loss: 0.5521066171424993\n",
      "Epoch: 85, Iteration: 6400, Loss: 0.6438266337419478\n",
      "Epoch: 85, Iteration: 8000, Loss: 0.8216954330795485\n",
      "Epoch: 85, Iteration: 9600, Loss: 0.6253802992479232\n",
      "Epoch: 85, Iteration: 11200, Loss: 0.7659994418265628\n",
      "Epoch: 85, Iteration: 12800, Loss: 0.7207212532746439\n",
      "Epoch: 85, Iteration: 14400, Loss: 0.50421180868948\n",
      "Epoch: 85, Iteration: 16000, Loss: 0.5469092781053524\n",
      "Epoch: 85, Iteration: 17600, Loss: 0.7543010640186536\n",
      "Epoch: 85, Iteration: 19200, Loss: 0.6887153326601456\n",
      "Epoch: 85, Iteration: 20800, Loss: 0.7095445170806409\n",
      "Epoch: 85, Iteration: 22400, Loss: 0.8411352386374898\n",
      "Epoch: 85, Iteration: 24000, Loss: 0.5839457081385487\n",
      "Epoch: 85, Iteration: 25600, Loss: 0.7717901398643348\n",
      "Epoch: 85, Iteration: 27200, Loss: 0.7170200753718948\n",
      "Epoch: 85, Iteration: 28800, Loss: 0.4459733431757621\n",
      "Epoch: 85, Iteration: 30400, Loss: 0.6697257959847335\n",
      "Epoch: 85, Iteration: 32000, Loss: 0.5037607618604616\n",
      "Epoch: 85, Iteration: 33600, Loss: 0.6057834758375888\n",
      "Epoch: 85, Iteration: 35200, Loss: 0.6658728210968123\n",
      "Epoch: 85, Iteration: 36800, Loss: 0.7962940991780656\n",
      "Epoch: 85, Iteration: 38400, Loss: 0.5503850850352832\n",
      "Epoch: 85, Iteration: 40000, Loss: 0.7422134678357122\n",
      "Epoch: 85, Iteration: 41600, Loss: 0.841890173070438\n",
      "Epoch: 85, Iteration: 43200, Loss: 0.6045874882656576\n",
      "Epoch: 85, Iteration: 44800, Loss: 0.6522347521507561\n",
      "Epoch: 85, Iteration: 46400, Loss: 0.8055837001138664\n",
      "Epoch: 85, Iteration: 48000, Loss: 0.6227794528874113\n",
      "Epoch: 85, Iteration: 49600, Loss: 0.8821222936349501\n",
      "Epoch: 85, Iteration: 51200, Loss: 0.5699684404342313\n",
      "Epoch: 85, Iteration: 52800, Loss: 0.8973591791075641\n",
      "Epoch: 85, Iteration: 54400, Loss: 0.7618569793636241\n",
      "Epoch: 85, Iteration: 56000, Loss: 0.5856711476665993\n",
      "Epoch: 85, Iteration: 57600, Loss: 0.740656532944338\n",
      "Epoch: 85, Iteration: 59200, Loss: 0.7336380309171293\n",
      "Epoch: 85, Iteration: 60800, Loss: 0.7629879825935029\n",
      "Epoch: 85, Iteration: 62400, Loss: 0.7495028371246264\n",
      "Epoch: 86, Iteration: 0, Loss: 0.5127137411641994\n",
      "Epoch: 86, Iteration: 1600, Loss: 0.6598233016594165\n",
      "Epoch: 86, Iteration: 3200, Loss: 0.5462585831464497\n",
      "Epoch: 86, Iteration: 4800, Loss: 0.5450773631427166\n",
      "Epoch: 86, Iteration: 6400, Loss: 0.6362420224389388\n",
      "Epoch: 86, Iteration: 8000, Loss: 0.8122994897601372\n",
      "Epoch: 86, Iteration: 9600, Loss: 0.6088052431394765\n",
      "Epoch: 86, Iteration: 11200, Loss: 0.7664244645623277\n",
      "Epoch: 86, Iteration: 12800, Loss: 0.7174804949367852\n",
      "Epoch: 86, Iteration: 14400, Loss: 0.49815855920761853\n",
      "Epoch: 86, Iteration: 16000, Loss: 0.531874325088271\n",
      "Epoch: 86, Iteration: 17600, Loss: 0.7428873245612393\n",
      "Epoch: 86, Iteration: 19200, Loss: 0.6778723250492819\n",
      "Epoch: 86, Iteration: 20800, Loss: 0.7032255539748428\n",
      "Epoch: 86, Iteration: 22400, Loss: 0.8327415395202042\n",
      "Epoch: 86, Iteration: 24000, Loss: 0.5806689194688883\n",
      "Epoch: 86, Iteration: 25600, Loss: 0.7618963851541126\n",
      "Epoch: 86, Iteration: 27200, Loss: 0.705540398947265\n",
      "Epoch: 86, Iteration: 28800, Loss: 0.44322276194752097\n",
      "Epoch: 86, Iteration: 30400, Loss: 0.6614943774321882\n",
      "Epoch: 86, Iteration: 32000, Loss: 0.4966486848055905\n",
      "Epoch: 86, Iteration: 33600, Loss: 0.5995113952837683\n",
      "Epoch: 86, Iteration: 35200, Loss: 0.655760094668694\n",
      "Epoch: 86, Iteration: 36800, Loss: 0.7872456056764736\n",
      "Epoch: 86, Iteration: 38400, Loss: 0.544358933254417\n",
      "Epoch: 86, Iteration: 40000, Loss: 0.7360924681398913\n",
      "Epoch: 86, Iteration: 41600, Loss: 0.8475797258101878\n",
      "Epoch: 86, Iteration: 43200, Loss: 0.5969366039663617\n",
      "Epoch: 86, Iteration: 44800, Loss: 0.6504434670195964\n",
      "Epoch: 86, Iteration: 46400, Loss: 0.7986990939119529\n",
      "Epoch: 86, Iteration: 48000, Loss: 0.6099671169977838\n",
      "Epoch: 86, Iteration: 49600, Loss: 0.8711766581375637\n",
      "Epoch: 86, Iteration: 51200, Loss: 0.5697970905400718\n",
      "Epoch: 86, Iteration: 52800, Loss: 0.8916914684017709\n",
      "Epoch: 86, Iteration: 54400, Loss: 0.7602181211518524\n",
      "Epoch: 86, Iteration: 56000, Loss: 0.5839808101015524\n",
      "Epoch: 86, Iteration: 57600, Loss: 0.7384589285086678\n",
      "Epoch: 86, Iteration: 59200, Loss: 0.7305745468640392\n",
      "Epoch: 86, Iteration: 60800, Loss: 0.7475172910886724\n",
      "Epoch: 86, Iteration: 62400, Loss: 0.7410275323829627\n",
      "Epoch: 87, Iteration: 0, Loss: 0.5100147356333595\n",
      "Epoch: 87, Iteration: 1600, Loss: 0.6509246485609643\n",
      "Epoch: 87, Iteration: 3200, Loss: 0.5387687689283115\n",
      "Epoch: 87, Iteration: 4800, Loss: 0.5399638188895324\n",
      "Epoch: 87, Iteration: 6400, Loss: 0.6272149771417113\n",
      "Epoch: 87, Iteration: 8000, Loss: 0.8031615564376969\n",
      "Epoch: 87, Iteration: 9600, Loss: 0.5926857911509391\n",
      "Epoch: 87, Iteration: 11200, Loss: 0.7678895527743645\n",
      "Epoch: 87, Iteration: 12800, Loss: 0.7149808456192752\n",
      "Epoch: 87, Iteration: 14400, Loss: 0.4933548184328852\n",
      "Epoch: 87, Iteration: 16000, Loss: 0.518370329078953\n",
      "Epoch: 87, Iteration: 17600, Loss: 0.7312047749529108\n",
      "Epoch: 87, Iteration: 19200, Loss: 0.6666871997797144\n",
      "Epoch: 87, Iteration: 20800, Loss: 0.7005969433238413\n",
      "Epoch: 87, Iteration: 22400, Loss: 0.8235914154807136\n",
      "Epoch: 87, Iteration: 24000, Loss: 0.5767150604961324\n",
      "Epoch: 87, Iteration: 25600, Loss: 0.7527206747678477\n",
      "Epoch: 87, Iteration: 27200, Loss: 0.6960136266430055\n",
      "Epoch: 87, Iteration: 28800, Loss: 0.44155253394072425\n",
      "Epoch: 87, Iteration: 30400, Loss: 0.6564536720338392\n",
      "Epoch: 87, Iteration: 32000, Loss: 0.4904442815638037\n",
      "Epoch: 87, Iteration: 33600, Loss: 0.5916076034478566\n",
      "Epoch: 87, Iteration: 35200, Loss: 0.6475671138025543\n",
      "Epoch: 87, Iteration: 36800, Loss: 0.7782599821097668\n",
      "Epoch: 87, Iteration: 38400, Loss: 0.5386295843430621\n",
      "Epoch: 87, Iteration: 40000, Loss: 0.7309682590098942\n",
      "Epoch: 87, Iteration: 41600, Loss: 0.8528949228676966\n",
      "Epoch: 87, Iteration: 43200, Loss: 0.5911999315753962\n",
      "Epoch: 87, Iteration: 44800, Loss: 0.649402933885318\n",
      "Epoch: 87, Iteration: 46400, Loss: 0.7923219118102858\n",
      "Epoch: 87, Iteration: 48000, Loss: 0.5975661089096821\n",
      "Epoch: 87, Iteration: 49600, Loss: 0.8596219374505722\n",
      "Epoch: 87, Iteration: 51200, Loss: 0.5699393714268506\n",
      "Epoch: 87, Iteration: 52800, Loss: 0.8864194971665196\n",
      "Epoch: 87, Iteration: 54400, Loss: 0.7585565439793338\n",
      "Epoch: 87, Iteration: 56000, Loss: 0.583255910965904\n",
      "Epoch: 87, Iteration: 57600, Loss: 0.735754141152647\n",
      "Epoch: 87, Iteration: 59200, Loss: 0.7274139208645097\n",
      "Epoch: 87, Iteration: 60800, Loss: 0.7319914511822461\n",
      "Epoch: 87, Iteration: 62400, Loss: 0.7352493958535244\n",
      "Epoch: 88, Iteration: 0, Loss: 0.5086127957828701\n",
      "Epoch: 88, Iteration: 1600, Loss: 0.6430204326774108\n",
      "Epoch: 88, Iteration: 3200, Loss: 0.532769353220828\n",
      "Epoch: 88, Iteration: 4800, Loss: 0.5364761789597996\n",
      "Epoch: 88, Iteration: 6400, Loss: 0.6169345095264247\n",
      "Epoch: 88, Iteration: 8000, Loss: 0.7949741722453455\n",
      "Epoch: 88, Iteration: 9600, Loss: 0.5775058311257916\n",
      "Epoch: 88, Iteration: 11200, Loss: 0.7693564002835487\n",
      "Epoch: 88, Iteration: 12800, Loss: 0.713459905938548\n",
      "Epoch: 88, Iteration: 14400, Loss: 0.48961286268550686\n",
      "Epoch: 88, Iteration: 16000, Loss: 0.5075114302777908\n",
      "Epoch: 88, Iteration: 17600, Loss: 0.7198559983604472\n",
      "Epoch: 88, Iteration: 19200, Loss: 0.6561466751048595\n",
      "Epoch: 88, Iteration: 20800, Loss: 0.7005947955810303\n",
      "Epoch: 88, Iteration: 22400, Loss: 0.8140138063559865\n",
      "Epoch: 88, Iteration: 24000, Loss: 0.5723654651833113\n",
      "Epoch: 88, Iteration: 25600, Loss: 0.7438671994749664\n",
      "Epoch: 88, Iteration: 27200, Loss: 0.687952557376837\n",
      "Epoch: 88, Iteration: 28800, Loss: 0.4409504442787054\n",
      "Epoch: 88, Iteration: 30400, Loss: 0.6544379877833547\n",
      "Epoch: 88, Iteration: 32000, Loss: 0.48531854637067373\n",
      "Epoch: 88, Iteration: 33600, Loss: 0.583130905538863\n",
      "Epoch: 88, Iteration: 35200, Loss: 0.6415668401010267\n",
      "Epoch: 88, Iteration: 36800, Loss: 0.7695321021368751\n",
      "Epoch: 88, Iteration: 38400, Loss: 0.5325233701548759\n",
      "Epoch: 88, Iteration: 40000, Loss: 0.7278800719663023\n",
      "Epoch: 88, Iteration: 41600, Loss: 0.8577955962815942\n",
      "Epoch: 88, Iteration: 43200, Loss: 0.5875117885084002\n",
      "Epoch: 88, Iteration: 44800, Loss: 0.6483836836815963\n",
      "Epoch: 88, Iteration: 46400, Loss: 0.7865809334306566\n",
      "Epoch: 88, Iteration: 48000, Loss: 0.5868329736946634\n",
      "Epoch: 88, Iteration: 49600, Loss: 0.8486294095833548\n",
      "Epoch: 88, Iteration: 51200, Loss: 0.5692428258056967\n",
      "Epoch: 88, Iteration: 52800, Loss: 0.8805686800373824\n",
      "Epoch: 88, Iteration: 54400, Loss: 0.7555193609799022\n",
      "Epoch: 88, Iteration: 56000, Loss: 0.5843323739168409\n",
      "Epoch: 88, Iteration: 57600, Loss: 0.7323486423741483\n",
      "Epoch: 88, Iteration: 59200, Loss: 0.7243825729497406\n",
      "Epoch: 88, Iteration: 60800, Loss: 0.7171814557057479\n",
      "Epoch: 88, Iteration: 62400, Loss: 0.7317613679336873\n",
      "Epoch: 89, Iteration: 0, Loss: 0.5077499709532756\n",
      "Epoch: 89, Iteration: 1600, Loss: 0.6374049124124875\n",
      "Epoch: 89, Iteration: 3200, Loss: 0.5286861983175022\n",
      "Epoch: 89, Iteration: 4800, Loss: 0.5342148820415269\n",
      "Epoch: 89, Iteration: 6400, Loss: 0.6064435543294227\n",
      "Epoch: 89, Iteration: 8000, Loss: 0.7871224473071177\n",
      "Epoch: 89, Iteration: 9600, Loss: 0.5635827793191857\n",
      "Epoch: 89, Iteration: 11200, Loss: 0.7699622823623415\n",
      "Epoch: 89, Iteration: 12800, Loss: 0.7131530912513915\n",
      "Epoch: 89, Iteration: 14400, Loss: 0.4863916490144389\n",
      "Epoch: 89, Iteration: 16000, Loss: 0.49990286042592214\n",
      "Epoch: 89, Iteration: 17600, Loss: 0.7096744836644816\n",
      "Epoch: 89, Iteration: 19200, Loss: 0.6475259748368188\n",
      "Epoch: 89, Iteration: 20800, Loss: 0.7018323834247614\n",
      "Epoch: 89, Iteration: 22400, Loss: 0.8045200361595758\n",
      "Epoch: 89, Iteration: 24000, Loss: 0.5682990137632644\n",
      "Epoch: 89, Iteration: 25600, Loss: 0.7348259381118258\n",
      "Epoch: 89, Iteration: 27200, Loss: 0.681073550015997\n",
      "Epoch: 89, Iteration: 28800, Loss: 0.44123286416718266\n",
      "Epoch: 89, Iteration: 30400, Loss: 0.654095794343882\n",
      "Epoch: 89, Iteration: 32000, Loss: 0.48138164328354294\n",
      "Epoch: 89, Iteration: 33600, Loss: 0.5760347188999899\n",
      "Epoch: 89, Iteration: 35200, Loss: 0.6371094368207336\n",
      "Epoch: 89, Iteration: 36800, Loss: 0.7617277961912534\n",
      "Epoch: 89, Iteration: 38400, Loss: 0.5258928729923252\n",
      "Epoch: 89, Iteration: 40000, Loss: 0.7271961053311287\n",
      "Epoch: 89, Iteration: 41600, Loss: 0.8623032377964279\n",
      "Epoch: 89, Iteration: 43200, Loss: 0.5856690436633817\n",
      "Epoch: 89, Iteration: 44800, Loss: 0.6471525215671095\n",
      "Epoch: 89, Iteration: 46400, Loss: 0.7816470503389494\n",
      "Epoch: 89, Iteration: 48000, Loss: 0.5778775743182126\n",
      "Epoch: 89, Iteration: 49600, Loss: 0.8390209378973893\n",
      "Epoch: 89, Iteration: 51200, Loss: 0.5669830377876546\n",
      "Epoch: 89, Iteration: 52800, Loss: 0.8741895756006295\n",
      "Epoch: 89, Iteration: 54400, Loss: 0.7507637702063036\n",
      "Epoch: 89, Iteration: 56000, Loss: 0.5875206336659704\n",
      "Epoch: 89, Iteration: 57600, Loss: 0.7289971931370949\n",
      "Epoch: 89, Iteration: 59200, Loss: 0.7221325342433691\n",
      "Epoch: 89, Iteration: 60800, Loss: 0.7036297026432936\n",
      "Epoch: 89, Iteration: 62400, Loss: 0.729450534980826\n",
      "Epoch: 90, Iteration: 0, Loss: 0.5068103114987171\n",
      "Epoch: 90, Iteration: 1600, Loss: 0.6348460378519372\n",
      "Epoch: 90, Iteration: 3200, Loss: 0.5259934292875998\n",
      "Epoch: 90, Iteration: 4800, Loss: 0.5328279372289515\n",
      "Epoch: 90, Iteration: 6400, Loss: 0.5970547188633968\n",
      "Epoch: 90, Iteration: 8000, Loss: 0.7786534506150619\n",
      "Epoch: 90, Iteration: 9600, Loss: 0.5515998232347552\n",
      "Epoch: 90, Iteration: 11200, Loss: 0.7692789037344601\n",
      "Epoch: 90, Iteration: 12800, Loss: 0.7141762556923799\n",
      "Epoch: 90, Iteration: 14400, Loss: 0.4828591882197716\n",
      "Epoch: 90, Iteration: 16000, Loss: 0.49551570899564046\n",
      "Epoch: 90, Iteration: 17600, Loss: 0.7015696680819699\n",
      "Epoch: 90, Iteration: 19200, Loss: 0.6409388561702778\n",
      "Epoch: 90, Iteration: 20800, Loss: 0.7036145560528955\n",
      "Epoch: 90, Iteration: 22400, Loss: 0.7960302442400456\n",
      "Epoch: 90, Iteration: 24000, Loss: 0.5654951096284762\n",
      "Epoch: 90, Iteration: 25600, Loss: 0.7256938297388018\n",
      "Epoch: 90, Iteration: 27200, Loss: 0.6754110251756831\n",
      "Epoch: 90, Iteration: 28800, Loss: 0.44241824046929873\n",
      "Epoch: 90, Iteration: 30400, Loss: 0.6540506194594236\n",
      "Epoch: 90, Iteration: 32000, Loss: 0.4785445321326824\n",
      "Epoch: 90, Iteration: 33600, Loss: 0.5719879362931575\n",
      "Epoch: 90, Iteration: 35200, Loss: 0.6328449620030825\n",
      "Epoch: 90, Iteration: 36800, Loss: 0.7560264940278416\n",
      "Epoch: 90, Iteration: 38400, Loss: 0.5192530939459397\n",
      "Epoch: 90, Iteration: 40000, Loss: 0.728745584946485\n",
      "Epoch: 90, Iteration: 41600, Loss: 0.8660872524926622\n",
      "Epoch: 90, Iteration: 43200, Loss: 0.5855048639267896\n",
      "Epoch: 90, Iteration: 44800, Loss: 0.6461684122373549\n",
      "Epoch: 90, Iteration: 46400, Loss: 0.7778857111386681\n",
      "Epoch: 90, Iteration: 48000, Loss: 0.5695259521034934\n",
      "Epoch: 90, Iteration: 49600, Loss: 0.8311378126352047\n",
      "Epoch: 90, Iteration: 51200, Loss: 0.563276625632118\n",
      "Epoch: 90, Iteration: 52800, Loss: 0.8682037138414943\n",
      "Epoch: 90, Iteration: 54400, Loss: 0.7450698215900242\n",
      "Epoch: 90, Iteration: 56000, Loss: 0.5926052226736991\n",
      "Epoch: 90, Iteration: 57600, Loss: 0.7265699068126391\n",
      "Epoch: 90, Iteration: 59200, Loss: 0.7212050621059485\n",
      "Epoch: 90, Iteration: 60800, Loss: 0.6920681236899677\n",
      "Epoch: 90, Iteration: 62400, Loss: 0.7268756880259896\n",
      "Epoch: 91, Iteration: 0, Loss: 0.5054819596102024\n",
      "Epoch: 91, Iteration: 1600, Loss: 0.6356571834257343\n",
      "Epoch: 91, Iteration: 3200, Loss: 0.5240432331154746\n",
      "Epoch: 91, Iteration: 4800, Loss: 0.5318264716119312\n",
      "Epoch: 91, Iteration: 6400, Loss: 0.5891350918491899\n",
      "Epoch: 91, Iteration: 8000, Loss: 0.76948863445878\n",
      "Epoch: 91, Iteration: 9600, Loss: 0.5423725351895656\n",
      "Epoch: 91, Iteration: 11200, Loss: 0.7677976756188043\n",
      "Epoch: 91, Iteration: 12800, Loss: 0.7163157023459388\n",
      "Epoch: 91, Iteration: 14400, Loss: 0.478443191138005\n",
      "Epoch: 91, Iteration: 16000, Loss: 0.49344015943955\n",
      "Epoch: 91, Iteration: 17600, Loss: 0.6958949891639451\n",
      "Epoch: 91, Iteration: 19200, Loss: 0.6346119798358485\n",
      "Epoch: 91, Iteration: 20800, Loss: 0.7061585412921495\n",
      "Epoch: 91, Iteration: 22400, Loss: 0.7893138695417696\n",
      "Epoch: 91, Iteration: 24000, Loss: 0.5645021761819374\n",
      "Epoch: 91, Iteration: 25600, Loss: 0.7176542475050093\n",
      "Epoch: 91, Iteration: 27200, Loss: 0.6710307051787445\n",
      "Epoch: 91, Iteration: 28800, Loss: 0.44400046266048343\n",
      "Epoch: 91, Iteration: 30400, Loss: 0.6541655325318898\n",
      "Epoch: 91, Iteration: 32000, Loss: 0.4765128444226105\n",
      "Epoch: 91, Iteration: 33600, Loss: 0.5714556694175481\n",
      "Epoch: 91, Iteration: 35200, Loss: 0.6276075653647251\n",
      "Epoch: 91, Iteration: 36800, Loss: 0.7537821058686942\n",
      "Epoch: 91, Iteration: 38400, Loss: 0.5131920039364046\n",
      "Epoch: 91, Iteration: 40000, Loss: 0.7315130776498825\n",
      "Epoch: 91, Iteration: 41600, Loss: 0.8684657062262273\n",
      "Epoch: 91, Iteration: 43200, Loss: 0.5865932177859527\n",
      "Epoch: 91, Iteration: 44800, Loss: 0.6460856785418774\n",
      "Epoch: 91, Iteration: 46400, Loss: 0.775447301880756\n",
      "Epoch: 91, Iteration: 48000, Loss: 0.5602889850348376\n",
      "Epoch: 91, Iteration: 49600, Loss: 0.8250320448109528\n",
      "Epoch: 91, Iteration: 51200, Loss: 0.5592624526101933\n",
      "Epoch: 91, Iteration: 52800, Loss: 0.8636332816787752\n",
      "Epoch: 91, Iteration: 54400, Loss: 0.7395428772039201\n",
      "Epoch: 91, Iteration: 56000, Loss: 0.5992127033414436\n",
      "Epoch: 91, Iteration: 57600, Loss: 0.7250976246174614\n",
      "Epoch: 91, Iteration: 59200, Loss: 0.7214289847676605\n",
      "Epoch: 91, Iteration: 60800, Loss: 0.6831859820571922\n",
      "Epoch: 91, Iteration: 62400, Loss: 0.722408324944249\n",
      "Epoch: 92, Iteration: 0, Loss: 0.5037036015351206\n",
      "Epoch: 92, Iteration: 1600, Loss: 0.6393376075101995\n",
      "Epoch: 92, Iteration: 3200, Loss: 0.5228062225991197\n",
      "Epoch: 92, Iteration: 4800, Loss: 0.5305149853308985\n",
      "Epoch: 92, Iteration: 6400, Loss: 0.5819872558480725\n",
      "Epoch: 92, Iteration: 8000, Loss: 0.7605792969914786\n",
      "Epoch: 92, Iteration: 9600, Loss: 0.5350765692077191\n",
      "Epoch: 92, Iteration: 11200, Loss: 0.7668830222066102\n",
      "Epoch: 92, Iteration: 12800, Loss: 0.7187153063693383\n",
      "Epoch: 92, Iteration: 14400, Loss: 0.4731341401619162\n",
      "Epoch: 92, Iteration: 16000, Loss: 0.4926662429027191\n",
      "Epoch: 92, Iteration: 17600, Loss: 0.6920499023012237\n",
      "Epoch: 92, Iteration: 19200, Loss: 0.6268138708898712\n",
      "Epoch: 92, Iteration: 20800, Loss: 0.7099612949163996\n",
      "Epoch: 92, Iteration: 22400, Loss: 0.7843774659982766\n",
      "Epoch: 92, Iteration: 24000, Loss: 0.5646538556841076\n",
      "Epoch: 92, Iteration: 25600, Loss: 0.7119038647021814\n",
      "Epoch: 92, Iteration: 27200, Loss: 0.6679996849845491\n",
      "Epoch: 92, Iteration: 28800, Loss: 0.4446165789646511\n",
      "Epoch: 92, Iteration: 30400, Loss: 0.6546713857398939\n",
      "Epoch: 92, Iteration: 32000, Loss: 0.47453649926012453\n",
      "Epoch: 92, Iteration: 33600, Loss: 0.5739496795481942\n",
      "Epoch: 92, Iteration: 35200, Loss: 0.6214582910967094\n",
      "Epoch: 92, Iteration: 36800, Loss: 0.7551424221058773\n",
      "Epoch: 92, Iteration: 38400, Loss: 0.5078356614809264\n",
      "Epoch: 92, Iteration: 40000, Loss: 0.7339046568605965\n",
      "Epoch: 92, Iteration: 41600, Loss: 0.8687225817866706\n",
      "Epoch: 92, Iteration: 43200, Loss: 0.5877816648477314\n",
      "Epoch: 92, Iteration: 44800, Loss: 0.646835649100389\n",
      "Epoch: 92, Iteration: 46400, Loss: 0.7741880809924899\n",
      "Epoch: 92, Iteration: 48000, Loss: 0.5490197281347697\n",
      "Epoch: 92, Iteration: 49600, Loss: 0.8197583275597622\n",
      "Epoch: 92, Iteration: 51200, Loss: 0.556120488133411\n",
      "Epoch: 92, Iteration: 52800, Loss: 0.8610830192868485\n",
      "Epoch: 92, Iteration: 54400, Loss: 0.7345843655173396\n",
      "Epoch: 92, Iteration: 56000, Loss: 0.6069555442968344\n",
      "Epoch: 92, Iteration: 57600, Loss: 0.7242310422924295\n",
      "Epoch: 92, Iteration: 59200, Loss: 0.721836878302712\n",
      "Epoch: 92, Iteration: 60800, Loss: 0.6773473658181995\n",
      "Epoch: 92, Iteration: 62400, Loss: 0.7158130552904289\n",
      "Epoch: 93, Iteration: 0, Loss: 0.5019410211709949\n",
      "Epoch: 93, Iteration: 1600, Loss: 0.6441785665328388\n",
      "Epoch: 93, Iteration: 3200, Loss: 0.5229113570589128\n",
      "Epoch: 93, Iteration: 4800, Loss: 0.5281981628808621\n",
      "Epoch: 93, Iteration: 6400, Loss: 0.5751613877273241\n",
      "Epoch: 93, Iteration: 8000, Loss: 0.7525483574389136\n",
      "Epoch: 93, Iteration: 9600, Loss: 0.527933955541502\n",
      "Epoch: 93, Iteration: 11200, Loss: 0.7676824941962967\n",
      "Epoch: 93, Iteration: 12800, Loss: 0.7197802821743657\n",
      "Epoch: 93, Iteration: 14400, Loss: 0.4671238854601756\n",
      "Epoch: 93, Iteration: 16000, Loss: 0.49331804294321746\n",
      "Epoch: 93, Iteration: 17600, Loss: 0.6890210094423329\n",
      "Epoch: 93, Iteration: 19200, Loss: 0.6181642891235493\n",
      "Epoch: 93, Iteration: 20800, Loss: 0.7157760888581769\n",
      "Epoch: 93, Iteration: 22400, Loss: 0.7807900035832807\n",
      "Epoch: 93, Iteration: 24000, Loss: 0.5651134144518326\n",
      "Epoch: 93, Iteration: 25600, Loss: 0.7089616640732613\n",
      "Epoch: 93, Iteration: 27200, Loss: 0.6668682451146326\n",
      "Epoch: 93, Iteration: 28800, Loss: 0.4442899474244466\n",
      "Epoch: 93, Iteration: 30400, Loss: 0.6553183236969644\n",
      "Epoch: 93, Iteration: 32000, Loss: 0.4723573612866478\n",
      "Epoch: 93, Iteration: 33600, Loss: 0.579657789121956\n",
      "Epoch: 93, Iteration: 35200, Loss: 0.615392358690868\n",
      "Epoch: 93, Iteration: 36800, Loss: 0.7593265417638777\n",
      "Epoch: 93, Iteration: 38400, Loss: 0.50342530202461\n",
      "Epoch: 93, Iteration: 40000, Loss: 0.7356699416248429\n",
      "Epoch: 93, Iteration: 41600, Loss: 0.8659669502660072\n",
      "Epoch: 93, Iteration: 43200, Loss: 0.5873025463435881\n",
      "Epoch: 93, Iteration: 44800, Loss: 0.6484630710207939\n",
      "Epoch: 93, Iteration: 46400, Loss: 0.7745621208556667\n",
      "Epoch: 93, Iteration: 48000, Loss: 0.5350004616332724\n",
      "Epoch: 93, Iteration: 49600, Loss: 0.8131365602740939\n",
      "Epoch: 93, Iteration: 51200, Loss: 0.5545636418753712\n",
      "Epoch: 93, Iteration: 52800, Loss: 0.8599026424087488\n",
      "Epoch: 93, Iteration: 54400, Loss: 0.7305207520152446\n",
      "Epoch: 93, Iteration: 56000, Loss: 0.6162151104826636\n",
      "Epoch: 93, Iteration: 57600, Loss: 0.723973227781016\n",
      "Epoch: 93, Iteration: 59200, Loss: 0.7210018125717935\n",
      "Epoch: 93, Iteration: 60800, Loss: 0.6754270941574372\n",
      "Epoch: 93, Iteration: 62400, Loss: 0.7085235155900305\n",
      "Epoch: 94, Iteration: 0, Loss: 0.5008976008066248\n",
      "Epoch: 94, Iteration: 1600, Loss: 0.6483109914373917\n",
      "Epoch: 94, Iteration: 3200, Loss: 0.525843765340452\n",
      "Epoch: 94, Iteration: 4800, Loss: 0.5242854101272718\n",
      "Epoch: 94, Iteration: 6400, Loss: 0.5691400081484691\n",
      "Epoch: 94, Iteration: 8000, Loss: 0.7454271469776396\n",
      "Epoch: 94, Iteration: 9600, Loss: 0.5215643357607198\n",
      "Epoch: 94, Iteration: 11200, Loss: 0.7715437896539753\n",
      "Epoch: 94, Iteration: 12800, Loss: 0.7180274886774947\n",
      "Epoch: 94, Iteration: 14400, Loss: 0.46113640459112837\n",
      "Epoch: 94, Iteration: 16000, Loss: 0.49666230093530833\n",
      "Epoch: 94, Iteration: 17600, Loss: 0.6879045819756127\n",
      "Epoch: 94, Iteration: 19200, Loss: 0.6107118302047229\n",
      "Epoch: 94, Iteration: 20800, Loss: 0.7266691188455201\n",
      "Epoch: 94, Iteration: 22400, Loss: 0.7779750196787113\n",
      "Epoch: 94, Iteration: 24000, Loss: 0.5653107614936078\n",
      "Epoch: 94, Iteration: 25600, Loss: 0.7097459812049787\n",
      "Epoch: 94, Iteration: 27200, Loss: 0.6696813775182862\n",
      "Epoch: 94, Iteration: 28800, Loss: 0.44481829741302037\n",
      "Epoch: 94, Iteration: 30400, Loss: 0.6583403948069435\n",
      "Epoch: 94, Iteration: 32000, Loss: 0.47242561801081306\n",
      "Epoch: 94, Iteration: 33600, Loss: 0.5906089750149441\n",
      "Epoch: 94, Iteration: 35200, Loss: 0.6108982942342203\n",
      "Epoch: 94, Iteration: 36800, Loss: 0.7663232685933741\n",
      "Epoch: 94, Iteration: 38400, Loss: 0.501297347530877\n",
      "Epoch: 94, Iteration: 40000, Loss: 0.7395503100906224\n",
      "Epoch: 94, Iteration: 41600, Loss: 0.8578019901973849\n",
      "Epoch: 94, Iteration: 43200, Loss: 0.5813915655413682\n",
      "Epoch: 94, Iteration: 44800, Loss: 0.6528401642634551\n",
      "Epoch: 94, Iteration: 46400, Loss: 0.7781409310787899\n",
      "Epoch: 94, Iteration: 48000, Loss: 0.519447487664747\n",
      "Epoch: 94, Iteration: 49600, Loss: 0.8020129129476632\n",
      "Epoch: 94, Iteration: 51200, Loss: 0.5564892281189852\n",
      "Epoch: 94, Iteration: 52800, Loss: 0.8593184630087732\n",
      "Epoch: 94, Iteration: 54400, Loss: 0.7306132174350239\n",
      "Epoch: 94, Iteration: 56000, Loss: 0.6294186864788917\n",
      "Epoch: 94, Iteration: 57600, Loss: 0.7237822066240622\n",
      "Epoch: 94, Iteration: 59200, Loss: 0.716230505180145\n",
      "Epoch: 94, Iteration: 60800, Loss: 0.6813212989261436\n",
      "Epoch: 94, Iteration: 62400, Loss: 0.7013671245855617\n",
      "Epoch: 95, Iteration: 0, Loss: 0.4986966268714892\n",
      "Epoch: 95, Iteration: 1600, Loss: 0.652353822942024\n",
      "Epoch: 95, Iteration: 3200, Loss: 0.5351152170820054\n",
      "Epoch: 95, Iteration: 4800, Loss: 0.518482438389654\n",
      "Epoch: 95, Iteration: 6400, Loss: 0.5641407973676962\n",
      "Epoch: 95, Iteration: 8000, Loss: 0.7362801528330051\n",
      "Epoch: 95, Iteration: 9600, Loss: 0.5210278794336372\n",
      "Epoch: 95, Iteration: 11200, Loss: 0.7815824064282135\n",
      "Epoch: 95, Iteration: 12800, Loss: 0.7126943940662713\n",
      "Epoch: 95, Iteration: 14400, Loss: 0.46150455195662854\n",
      "Epoch: 95, Iteration: 16000, Loss: 0.5037788645538147\n",
      "Epoch: 95, Iteration: 17600, Loss: 0.6916089628129574\n",
      "Epoch: 95, Iteration: 19200, Loss: 0.6045831348293125\n",
      "Epoch: 95, Iteration: 20800, Loss: 0.749401869722506\n",
      "Epoch: 95, Iteration: 22400, Loss: 0.7735253669917994\n",
      "Epoch: 95, Iteration: 24000, Loss: 0.5656574470003333\n",
      "Epoch: 95, Iteration: 25600, Loss: 0.7168179421875902\n",
      "Epoch: 95, Iteration: 27200, Loss: 0.6763748042181028\n",
      "Epoch: 95, Iteration: 28800, Loss: 0.44883755504884965\n",
      "Epoch: 95, Iteration: 30400, Loss: 0.6743625078440665\n",
      "Epoch: 95, Iteration: 32000, Loss: 0.4816433677372084\n",
      "Epoch: 95, Iteration: 33600, Loss: 0.6069619100288801\n",
      "Epoch: 95, Iteration: 35200, Loss: 0.6126525610106479\n",
      "Epoch: 95, Iteration: 36800, Loss: 0.7761181591585553\n",
      "Epoch: 95, Iteration: 38400, Loss: 0.5015837629162596\n",
      "Epoch: 95, Iteration: 40000, Loss: 0.7514766063306726\n",
      "Epoch: 95, Iteration: 41600, Loss: 0.852022109988861\n",
      "Epoch: 95, Iteration: 43200, Loss: 0.5704341192388631\n",
      "Epoch: 95, Iteration: 44800, Loss: 0.6603940425360456\n",
      "Epoch: 95, Iteration: 46400, Loss: 0.7834917178957069\n",
      "Epoch: 95, Iteration: 48000, Loss: 0.5106563497710628\n",
      "Epoch: 95, Iteration: 49600, Loss: 0.8007761221279431\n",
      "Epoch: 95, Iteration: 51200, Loss: 0.5636041317167131\n",
      "Epoch: 95, Iteration: 52800, Loss: 0.8601007592829628\n",
      "Epoch: 95, Iteration: 54400, Loss: 0.7365483072254289\n",
      "Epoch: 95, Iteration: 56000, Loss: 0.6387116402405627\n",
      "Epoch: 95, Iteration: 57600, Loss: 0.7181101647072294\n",
      "Epoch: 95, Iteration: 59200, Loss: 0.7090856724228226\n",
      "Epoch: 95, Iteration: 60800, Loss: 0.6899876007050336\n",
      "Epoch: 95, Iteration: 62400, Loss: 0.6913245886111283\n",
      "Epoch: 96, Iteration: 0, Loss: 0.4914614485207358\n",
      "Epoch: 96, Iteration: 1600, Loss: 0.6634639237670603\n",
      "Epoch: 96, Iteration: 3200, Loss: 0.5442080407436125\n",
      "Epoch: 96, Iteration: 4800, Loss: 0.5181941757548362\n",
      "Epoch: 96, Iteration: 6400, Loss: 0.5594334356322438\n",
      "Epoch: 96, Iteration: 8000, Loss: 0.7222139450316416\n",
      "Epoch: 96, Iteration: 9600, Loss: 0.5271681836302948\n",
      "Epoch: 96, Iteration: 11200, Loss: 0.7888339558805735\n",
      "Epoch: 96, Iteration: 12800, Loss: 0.7090365780197067\n",
      "Epoch: 96, Iteration: 14400, Loss: 0.47156575355702357\n",
      "Epoch: 96, Iteration: 16000, Loss: 0.5125609150987491\n",
      "Epoch: 96, Iteration: 17600, Loss: 0.694062821544429\n",
      "Epoch: 96, Iteration: 19200, Loss: 0.5961874897035183\n",
      "Epoch: 96, Iteration: 20800, Loss: 0.7650876377517675\n",
      "Epoch: 96, Iteration: 22400, Loss: 0.7701441164314085\n",
      "Epoch: 96, Iteration: 24000, Loss: 0.5705242974343827\n",
      "Epoch: 96, Iteration: 25600, Loss: 0.7293536982671425\n",
      "Epoch: 96, Iteration: 27200, Loss: 0.677296580421351\n",
      "Epoch: 96, Iteration: 28800, Loss: 0.4517463265668137\n",
      "Epoch: 96, Iteration: 30400, Loss: 0.6839326619731014\n",
      "Epoch: 96, Iteration: 32000, Loss: 0.4874735118370324\n",
      "Epoch: 96, Iteration: 33600, Loss: 0.6159200211267846\n",
      "Epoch: 96, Iteration: 35200, Loss: 0.6111605501854653\n",
      "Epoch: 96, Iteration: 36800, Loss: 0.785037218973762\n",
      "Epoch: 96, Iteration: 38400, Loss: 0.49876784936559687\n",
      "Epoch: 96, Iteration: 40000, Loss: 0.7579346063943562\n",
      "Epoch: 96, Iteration: 41600, Loss: 0.856864943566769\n",
      "Epoch: 96, Iteration: 43200, Loss: 0.5709226436849633\n",
      "Epoch: 96, Iteration: 44800, Loss: 0.6635214175471396\n",
      "Epoch: 96, Iteration: 46400, Loss: 0.7877471699269967\n",
      "Epoch: 96, Iteration: 48000, Loss: 0.5081064390636365\n",
      "Epoch: 96, Iteration: 49600, Loss: 0.8055459385399075\n",
      "Epoch: 96, Iteration: 51200, Loss: 0.5620470613165802\n",
      "Epoch: 96, Iteration: 52800, Loss: 0.863328164830941\n",
      "Epoch: 96, Iteration: 54400, Loss: 0.7355087308119257\n",
      "Epoch: 96, Iteration: 56000, Loss: 0.6421361633173746\n",
      "Epoch: 96, Iteration: 57600, Loss: 0.7119142037104438\n",
      "Epoch: 96, Iteration: 59200, Loss: 0.7064338673188675\n",
      "Epoch: 96, Iteration: 60800, Loss: 0.68153543385331\n",
      "Epoch: 96, Iteration: 62400, Loss: 0.677579520522848\n",
      "Epoch: 97, Iteration: 0, Loss: 0.4865912397385538\n",
      "Epoch: 97, Iteration: 1600, Loss: 0.6623984109707557\n",
      "Epoch: 97, Iteration: 3200, Loss: 0.5442423973411067\n",
      "Epoch: 97, Iteration: 4800, Loss: 0.520304432488415\n",
      "Epoch: 97, Iteration: 6400, Loss: 0.5533743106871728\n",
      "Epoch: 97, Iteration: 8000, Loss: 0.7098939530384841\n",
      "Epoch: 97, Iteration: 9600, Loss: 0.5272768067180791\n",
      "Epoch: 97, Iteration: 11200, Loss: 0.7862969126263573\n",
      "Epoch: 97, Iteration: 12800, Loss: 0.706760249866123\n",
      "Epoch: 97, Iteration: 14400, Loss: 0.4770141200576497\n",
      "Epoch: 97, Iteration: 16000, Loss: 0.5150303996257481\n",
      "Epoch: 97, Iteration: 17600, Loss: 0.6924363341912332\n",
      "Epoch: 97, Iteration: 19200, Loss: 0.5905438471678003\n",
      "Epoch: 97, Iteration: 20800, Loss: 0.7716436297193637\n",
      "Epoch: 97, Iteration: 22400, Loss: 0.770739111298092\n",
      "Epoch: 97, Iteration: 24000, Loss: 0.5770637865458985\n",
      "Epoch: 97, Iteration: 25600, Loss: 0.7323159697969839\n",
      "Epoch: 97, Iteration: 27200, Loss: 0.67335367715934\n",
      "Epoch: 97, Iteration: 28800, Loss: 0.450939129146052\n",
      "Epoch: 97, Iteration: 30400, Loss: 0.6822360187154304\n",
      "Epoch: 97, Iteration: 32000, Loss: 0.48708009922408035\n",
      "Epoch: 97, Iteration: 33600, Loss: 0.6198819142432511\n",
      "Epoch: 97, Iteration: 35200, Loss: 0.6024583470929322\n",
      "Epoch: 97, Iteration: 36800, Loss: 0.7926587379276733\n",
      "Epoch: 97, Iteration: 38400, Loss: 0.4983015480362597\n",
      "Epoch: 97, Iteration: 40000, Loss: 0.756228672979989\n",
      "Epoch: 97, Iteration: 41600, Loss: 0.8544212809804306\n",
      "Epoch: 97, Iteration: 43200, Loss: 0.5710122131981507\n",
      "Epoch: 97, Iteration: 44800, Loss: 0.6641699571679858\n",
      "Epoch: 97, Iteration: 46400, Loss: 0.7893421748266983\n",
      "Epoch: 97, Iteration: 48000, Loss: 0.5051360464456576\n",
      "Epoch: 97, Iteration: 49600, Loss: 0.8044074379167023\n",
      "Epoch: 97, Iteration: 51200, Loss: 0.5536807431107813\n",
      "Epoch: 97, Iteration: 52800, Loss: 0.8656664684360039\n",
      "Epoch: 97, Iteration: 54400, Loss: 0.7334927534040343\n",
      "Epoch: 97, Iteration: 56000, Loss: 0.6446767960431037\n",
      "Epoch: 97, Iteration: 57600, Loss: 0.7060977461914388\n",
      "Epoch: 97, Iteration: 59200, Loss: 0.7038438150561867\n",
      "Epoch: 97, Iteration: 60800, Loss: 0.666833774356347\n",
      "Epoch: 97, Iteration: 62400, Loss: 0.6648660681060828\n",
      "Epoch: 98, Iteration: 0, Loss: 0.4816582766927528\n",
      "Epoch: 98, Iteration: 1600, Loss: 0.6545599715868315\n",
      "Epoch: 98, Iteration: 3200, Loss: 0.5433550593684018\n",
      "Epoch: 98, Iteration: 4800, Loss: 0.5221658166012928\n",
      "Epoch: 98, Iteration: 6400, Loss: 0.5482800723891553\n",
      "Epoch: 98, Iteration: 8000, Loss: 0.6997707765990004\n",
      "Epoch: 98, Iteration: 9600, Loss: 0.5267410451146728\n",
      "Epoch: 98, Iteration: 11200, Loss: 0.7813381694068513\n",
      "Epoch: 98, Iteration: 12800, Loss: 0.7042179718657116\n",
      "Epoch: 98, Iteration: 14400, Loss: 0.4791870489067477\n",
      "Epoch: 98, Iteration: 16000, Loss: 0.5155836752759553\n",
      "Epoch: 98, Iteration: 17600, Loss: 0.6917257483362794\n",
      "Epoch: 98, Iteration: 19200, Loss: 0.585578509698833\n",
      "Epoch: 98, Iteration: 20800, Loss: 0.7783959442634598\n",
      "Epoch: 98, Iteration: 22400, Loss: 0.7735302236465478\n",
      "Epoch: 98, Iteration: 24000, Loss: 0.5846225734876591\n",
      "Epoch: 98, Iteration: 25600, Loss: 0.733446622097172\n",
      "Epoch: 98, Iteration: 27200, Loss: 0.668414067058686\n",
      "Epoch: 98, Iteration: 28800, Loss: 0.4489003897931201\n",
      "Epoch: 98, Iteration: 30400, Loss: 0.6800245551137316\n",
      "Epoch: 98, Iteration: 32000, Loss: 0.48666400845979507\n",
      "Epoch: 98, Iteration: 33600, Loss: 0.6222055388668482\n",
      "Epoch: 98, Iteration: 35200, Loss: 0.5934632585370354\n",
      "Epoch: 98, Iteration: 36800, Loss: 0.8005312895001969\n",
      "Epoch: 98, Iteration: 38400, Loss: 0.501324557512238\n",
      "Epoch: 98, Iteration: 40000, Loss: 0.751819647115571\n",
      "Epoch: 98, Iteration: 41600, Loss: 0.8491401263765248\n",
      "Epoch: 98, Iteration: 43200, Loss: 0.5714405408224463\n",
      "Epoch: 98, Iteration: 44800, Loss: 0.6652895425170886\n",
      "Epoch: 98, Iteration: 46400, Loss: 0.7927797160157879\n",
      "Epoch: 98, Iteration: 48000, Loss: 0.5026702172017603\n",
      "Epoch: 98, Iteration: 49600, Loss: 0.801353569013078\n",
      "Epoch: 98, Iteration: 51200, Loss: 0.5438004282026626\n",
      "Epoch: 98, Iteration: 52800, Loss: 0.8685200338694714\n",
      "Epoch: 98, Iteration: 54400, Loss: 0.7330876179396322\n",
      "Epoch: 98, Iteration: 56000, Loss: 0.645241041532166\n",
      "Epoch: 98, Iteration: 57600, Loss: 0.7003436835065528\n",
      "Epoch: 98, Iteration: 59200, Loss: 0.7012378947702173\n",
      "Epoch: 98, Iteration: 60800, Loss: 0.6516342578298786\n",
      "Epoch: 98, Iteration: 62400, Loss: 0.653888447977635\n",
      "Epoch: 99, Iteration: 0, Loss: 0.47743677676495694\n",
      "Epoch: 99, Iteration: 1600, Loss: 0.6457559096538631\n",
      "Epoch: 99, Iteration: 3200, Loss: 0.5438933389776497\n",
      "Epoch: 99, Iteration: 4800, Loss: 0.5251416182504625\n",
      "Epoch: 99, Iteration: 6400, Loss: 0.5459347647070398\n",
      "Epoch: 99, Iteration: 8000, Loss: 0.6937784401997587\n",
      "Epoch: 99, Iteration: 9600, Loss: 0.5289407971064866\n",
      "Epoch: 99, Iteration: 11200, Loss: 0.7748513852017695\n",
      "Epoch: 99, Iteration: 12800, Loss: 0.7019404999839054\n",
      "Epoch: 99, Iteration: 14400, Loss: 0.4800482466487062\n",
      "Epoch: 99, Iteration: 16000, Loss: 0.5178871000505698\n",
      "Epoch: 99, Iteration: 17600, Loss: 0.693863693750763\n",
      "Epoch: 99, Iteration: 19200, Loss: 0.5811698165060326\n",
      "Epoch: 99, Iteration: 20800, Loss: 0.7867361476380423\n",
      "Epoch: 99, Iteration: 22400, Loss: 0.7803758351915273\n",
      "Epoch: 99, Iteration: 24000, Loss: 0.5938515449419914\n",
      "Epoch: 99, Iteration: 25600, Loss: 0.7379639910151798\n",
      "Epoch: 99, Iteration: 27200, Loss: 0.6634215771444862\n",
      "Epoch: 99, Iteration: 28800, Loss: 0.4455333255124415\n",
      "Epoch: 99, Iteration: 30400, Loss: 0.6789094375868834\n",
      "Epoch: 99, Iteration: 32000, Loss: 0.48901097112238334\n",
      "Epoch: 99, Iteration: 33600, Loss: 0.6229751177324103\n",
      "Epoch: 99, Iteration: 35200, Loss: 0.5881858603385219\n",
      "Epoch: 99, Iteration: 36800, Loss: 0.8094612865262896\n",
      "Epoch: 99, Iteration: 38400, Loss: 0.5089367565674224\n",
      "Epoch: 99, Iteration: 40000, Loss: 0.7463312551793599\n",
      "Epoch: 99, Iteration: 41600, Loss: 0.8427549039607919\n",
      "Epoch: 99, Iteration: 43200, Loss: 0.5751462434776998\n",
      "Epoch: 99, Iteration: 44800, Loss: 0.6691695593581688\n",
      "Epoch: 99, Iteration: 46400, Loss: 0.8020043481743573\n",
      "Epoch: 99, Iteration: 48000, Loss: 0.5020399865872393\n",
      "Epoch: 99, Iteration: 49600, Loss: 0.7980082234314307\n",
      "Epoch: 99, Iteration: 51200, Loss: 0.5347397046416692\n",
      "Epoch: 99, Iteration: 52800, Loss: 0.8730334805936375\n",
      "Epoch: 99, Iteration: 54400, Loss: 0.7381185612199845\n",
      "Epoch: 99, Iteration: 56000, Loss: 0.6442181510366569\n",
      "Epoch: 99, Iteration: 57600, Loss: 0.6958322076478058\n",
      "Epoch: 99, Iteration: 59200, Loss: 0.700755789272747\n",
      "Epoch: 99, Iteration: 60800, Loss: 0.6363259235248651\n",
      "Epoch: 99, Iteration: 62400, Loss: 0.6468448297798758\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "    for i in range(0,train_ds_data.shape[0],64):\n",
    "\n",
    "        batch = train_ds_data[i:i+64].T\n",
    "        labels = train_ds_labels[i:i+64].astype(int)\n",
    "\n",
    "        out_a = a.forward(batch)\n",
    "        out_b = b.forward(out_a)\n",
    "        out_c = c.forward(out_b)\n",
    "        out_d = d.forward(out_c)\n",
    "\n",
    "\n",
    "        loss = np.mean(criterion.compute_loss(out_d, labels))\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch: {epoch}, Iteration: {i}, Loss: {loss}\")\n",
    "\n",
    "        grad_d = criterion.backward()\n",
    "        grad_c = d.backward(grad_d)\n",
    "        grad_b = c.backward(grad_c)\n",
    "        grad_a = b.backward(grad_b)\n",
    "        _ = a.backward(grad_a) \n",
    "\n",
    "        d.step()\n",
    "        c.step()\n",
    "        b.step()\n",
    "        a.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebab2a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "num_samples = 0\n",
    "for i in range(0,val_ds_data.shape[0],64):\n",
    "        batch = val_ds_data[i:i+64].T\n",
    "        labels = val_ds_labels[i:i+64].astype(int)\n",
    "        out_a = a.forward(batch)\n",
    "        out_b = b.forward(out_a)\n",
    "        out_c = c.forward(out_b)\n",
    "        output = d.forward(out_c)\n",
    "        output = np.argmax(output, axis= 0) \n",
    "        num_correct += (output == labels).sum()\n",
    "        num_samples += batch.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1357717a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(79.04285714285714)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(num_correct/num_samples)*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
